"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Editors","Publisher","Document Type","Publication Stage","Open Access","Source","EID"
"Gellert G.A.; Kelly S.P.; Hsiao A.L.; Herrick B.; Weis D.; Lutz J.; Stanton G.; Bonilla S.; Borgasano D.; Erich M.; Reilly C.; Johnston D.","Gellert, George A (57224718686); Kelly, Sean P (57982067900); Hsiao, Allen L (7005219722); Herrick, Brian (57195404072); Weis, Donna (57981247200); Lutz, Jeffrey (57980915800); Stanton, Glynn (57219835235); Bonilla, Santos (57981247300); Borgasano, Daniel (57981247400); Erich, Matthew (57980915900); Reilly, Claire (58362312200); Johnston, Daniel (57198644728)","57224718686; 57982067900; 7005219722; 57195404072; 57981247200; 57980915800; 57219835235; 57981247300; 57981247400; 57980915900; 58362312200; 57198644728","COVID-19 surge readiness: use cases demonstrating how hospitals leveraged digital identity access management for infection control and pandemic response","2022","BMJ Health and Care Informatics","29","1","e100680","","","","2","10.1136/bmjhci-2022-100680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142664126&doi=10.1136%2fbmjhci-2022-100680&partnerID=40&md5=0b8bda6f0a8e69ee042c8fcc0e64ca0d","Impact Demonstration, Imprivata, San Antonio, TX, United States; Department of Emergency Medicine, Harvard Medical School, Boston, MA, United States; Department of Pediatric Emergency Medicine, Yale School of Medicine and Yale New Haven Health System, New Haven, CT, United States; Department of Health Informatics, Tufts University School of Medicine, Boston, MA, United States; Department of Health Informatics, Nebraska Medicine, Omaha, NE, United States; Department of Health Informatics, New York City Health and Hospitals, New York, NY, United States; Department of Health Informatics, Yale New Haven Health System, New Haven, CT, United States; Department of Clinical Operatons, Imprivata, Lexington, MA, United States; Department of Clinical Operatons, Imprivata Uk, Uxbridge, United Kingdom","Gellert G.A., Impact Demonstration, Imprivata, San Antonio, TX, United States; Kelly S.P., Department of Emergency Medicine, Harvard Medical School, Boston, MA, United States; Hsiao A.L., Department of Pediatric Emergency Medicine, Yale School of Medicine and Yale New Haven Health System, New Haven, CT, United States; Herrick B., Department of Health Informatics, Tufts University School of Medicine, Boston, MA, United States; Weis D., Department of Health Informatics, Nebraska Medicine, Omaha, NE, United States; Lutz J., Department of Health Informatics, New York City Health and Hospitals, New York, NY, United States; Stanton G., Department of Health Informatics, Yale New Haven Health System, New Haven, CT, United States; Bonilla S., Department of Health Informatics, Yale New Haven Health System, New Haven, CT, United States; Borgasano D., Department of Clinical Operatons, Imprivata, Lexington, MA, United States; Erich M., Department of Clinical Operatons, Imprivata, Lexington, MA, United States; Reilly C., Department of Clinical Operatons, Imprivata, Lexington, MA, United States; Johnston D., Department of Clinical Operatons, Imprivata Uk, Uxbridge, United Kingdom","Background Surging volumes of patients with COVID-19 and the high infectiousness of SARS-CoV-2 challenged hospital infection control/safety, staffing, care delivery and operations as few crises have. Imperatives to ensure security of patient information, defend against cybersecurity threats and accurately identify/authenticate patients and staff were undiminished, which fostered creative use cases where hospitals leveraged identity access and management (IAM) technologies to improve infection control and minimise disruption of clinical and administrative workflows. Methods Working with a leading IAM solution provider, implementation personnel in the USA and UK identified all hospitals/health systems where an innovative use of IAM technology improved facility infection control and pandemic response management. Interviews/communications with hospital clinical informatics leaders collected information describing the use case deployed. Results Eight innovative/valuable hospital use cases are described: symptom-free attestation by clinicians at shift start; detection of clinician exposure/contact tracing; reporting of clinician temperature checks; inpatient telehealth consults in isolation units; virtual visits between isolated patients and families; touchless single sign-on authentication; secure access enabled for rapid expansion of personnel working remotely; and monitoring of temporary worker attendance. Discussion No systematic, comprehensive survey of all implemented IAM client sites was conducted, and other use cases may be undetected. A standardised reporting/information sharing vehicle is needed whereby IAM use cases aiding facility pandemic response and infection control can be disseminated. Conclusions Clinical care, infection control and facility operations were improved using IAM solutions during COVID-19. Facility end-user innovation in how IAM solutions are deployed can improve infection control/patient safety, care delivery and clinical workflows during surges of epidemic infectious diseases.  © ","Access to Information; COVID-19; Delivery of Health Care; Infectious Disease Medicine; Informatics","","BMJ Publishing Group","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142664126"
"Herrero P.; Bondia J.; Adewuyi O.; Pesl P.; El-Sharkawy M.; Reddy M.; Toumazou C.; Oliver N.; Georgiou P.","Herrero, Pau (8693403100); Bondia, Jorge (6602880910); Adewuyi, Oloruntoba (57194413485); Pesl, Peter (54891993500); El-Sharkawy, Mohamed (36445061700); Reddy, Monika (57196350191); Toumazou, Chris (56851269000); Oliver, Nick (8414954000); Georgiou, Pantelis (16301582200)","8693403100; 6602880910; 57194413485; 54891993500; 36445061700; 57196350191; 56851269000; 8414954000; 16301582200","Enhancing automatic closed-loop glucose control in type 1 diabetes with an adaptive meal bolus calculator – in silico evaluation under intra-day variability","2017","Computer Methods and Programs in Biomedicine","146","","","125","131","6","53","10.1016/j.cmpb.2017.05.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020014775&doi=10.1016%2fj.cmpb.2017.05.010&partnerID=40&md5=c654c4b0b324ed5af576ee0d554f4498","Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom; Institut Universitari d'Automàtica i Informàtica Industrial, Universitat Politècnica de València, València, Spain; Charing Cross Hospital, Imperial College Healthcare NHS Trust, London, United Kingdom","Herrero P., Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom; Bondia J., Institut Universitari d'Automàtica i Informàtica Industrial, Universitat Politècnica de València, València, Spain; Adewuyi O., Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom; Pesl P., Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom; El-Sharkawy M., Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom; Reddy M., Charing Cross Hospital, Imperial College Healthcare NHS Trust, London, United Kingdom; Toumazou C., Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom; Oliver N., Charing Cross Hospital, Imperial College Healthcare NHS Trust, London, United Kingdom; Georgiou P., Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom","Background and Objective Current prototypes of closed-loop systems for glucose control in type 1 diabetes mellitus, also referred to as artificial pancreas systems, require a pre-meal insulin bolus to compensate for delays in subcutaneous insulin absorption in order to avoid initial post-prandial hyperglycemia. Computing such a meal bolus is a challenging task due to the high intra-subject variability of insulin requirements. Most closed-loop systems compute this pre-meal insulin dose by a standard bolus calculation, as is commonly found in insulin pumps. However, the performance of these calculators is limited due to a lack of adaptiveness in front of dynamic changes in insulin requirements. Despite some initial attempts to include adaptation within these calculators, challenges remain. Methods In this paper we present a new technique to automatically adapt the meal-priming bolus within an artificial pancreas. The technique consists of using a novel adaptive bolus calculator based on Case-Based Reasoning and Run-To-Run control, within a closed-loop controller. Coordination between the adaptive bolus calculator and the controller was required to achieve the desired performance. For testing purposes, the clinically validated Imperial College Artificial Pancreas controller was employed. The proposed system was evaluated against itself but without bolus adaptation. The UVa-Padova T1DM v3.2 system was used to carry out a three-month in silico study on 11 adult and 11 adolescent virtual subjects taking into account inter-and intra-subject variability of insulin requirements and uncertainty on carbohydrate intake. Results Overall, the closed-loop controller enhanced by an adaptive bolus calculator improves glycemic control when compared to its non-adaptive counterpart. In particular, the following statistically significant improvements were found (non-adaptive vs. adaptive). Adults: mean glucose 142.2 ± 9.4 vs. 131.8 ± 4.2 mg/dl; percentage time in target [70, 180] mg/dl, 82.0 ± 7.0 vs. 89.5 ± 4.2; percentage time above target 17.7 ± 7.0 vs. 10.2 ± 4.1. Adolescents: mean glucose 158.2 ± 21.4 vs. 140.5 ± 13.0 mg/dl; percentage time in target, 65.9 ± 12.9 vs. 77.5 ± 12.2; percentage time above target, 31.7 ± 13.1 vs. 19.8 ± 10.2. Note that no increase in percentage time in hypoglycemia was observed. Conclusion Using an adaptive meal bolus calculator within a closed-loop control system has the potential to improve glycemic control in type 1 diabetes when compared to its non-adaptive counterpart. © 2017 Elsevier B.V.","Artificial pancreas; Case-based reasoning; Diabetes; Run-to-Run control","","Elsevier Ireland Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85020014775"
"Paulo S.F.; Medeiros D.; Lopes D.; Jorge J.","Paulo, Soraia F. (57195033731); Medeiros, Daniel (55428540900); Lopes, Daniel (26031571400); Jorge, Joaquim (22333907900)","57195033731; 55428540900; 26031571400; 22333907900","Controlling camera movement in VR colonography","2022","Virtual Reality","26","3","","1079","1088","9","3","10.1007/s10055-021-00620-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122566013&doi=10.1007%2fs10055-021-00620-4&partnerID=40&md5=32b77c51ceb9f94e51a482f2373c4ebf","INESC-ID Lisboa, Instituto Superior Técnico, Universidade de Lisboa, Av. Prof. Dr. Cavaco Silva, Porto Salvo, 2744-016, Portugal; University of Glasgow, Glasgow, United Kingdom","Paulo S.F., INESC-ID Lisboa, Instituto Superior Técnico, Universidade de Lisboa, Av. Prof. Dr. Cavaco Silva, Porto Salvo, 2744-016, Portugal; Medeiros D., University of Glasgow, Glasgow, United Kingdom; Lopes D., INESC-ID Lisboa, Instituto Superior Técnico, Universidade de Lisboa, Av. Prof. Dr. Cavaco Silva, Porto Salvo, 2744-016, Portugal; Jorge J., INESC-ID Lisboa, Instituto Superior Técnico, Universidade de Lisboa, Av. Prof. Dr. Cavaco Silva, Porto Salvo, 2744-016, Portugal","Immersive colonography allows medical professionals to navigate inside the intricate tubular geometries of subject-specific 3D colon images using Virtual Reality displays. Typically, camera travel is performed via Fly-Through or Fly-Over techniques that enable semi-automatic traveling through a constrained, well-defined path at user-controlled speeds. However, Fly-Through is known to limit the visibility of lesions located behind or inside haustral folds. At the same time, Fly-Over requires splitting the entire colon visualization into two specific halves. In this paper, we study the effect of immersive Fly-Through and Fly-Over techniques on lesion detection and introduce a camera travel technique that maintains a fixed camera orientation throughout the entire medial axis path. While these techniques have been studied in non-VR desktop environments, their performance is not well understood in VR setups. We performed a comparative study to ascertain which camera travel technique is more appropriate for constrained path navigation in immersive colonography and validated our conclusions with two radiologists. To this end, we asked 18 participants to navigate inside a 3D colon to find specific marks. Our results suggest that the Fly-Over technique may lead to enhanced lesion detection at the cost of higher task completion times. Nevertheless, the Fly-Through method may offer a more balanced trade-off between speed and effectiveness, whereas the fixed camera orientation technique provided seemingly inferior performance results. Our study further provides design guidelines and informs future work. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Colonography; Human-centered computing; Medical imagery; Navigation; Virtual reality","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85122566013"
"Vaughan N.; Gabrys B.","Vaughan, Neil (55345677800); Gabrys, Bogdan (7006540228)","55345677800; 7006540228","Scoring and assessment in medical VR training simulators with dynamic time series classification","2020","Engineering Applications of Artificial Intelligence","94","","103760","","","","18","10.1016/j.engappai.2020.103760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086502860&doi=10.1016%2fj.engappai.2020.103760&partnerID=40&md5=d9e9a8050262d8493d63d10da605b544","University of Exeter, Institute of Biomedical and Clinical Science, RILD Building, Barrack Road, Exeter, United Kingdom; University of Technology Sydney, Advanced Analytics Institute, 15 Broadway, Ultimo, NSW 2007, Australia","Vaughan N., University of Exeter, Institute of Biomedical and Clinical Science, RILD Building, Barrack Road, Exeter, United Kingdom; Gabrys B., University of Technology Sydney, Advanced Analytics Institute, 15 Broadway, Ultimo, NSW 2007, Australia","This research proposes and evaluates scoring and assessment methods for Virtual Reality (VR) training simulators. VR simulators capture detailed n-dimensional human motion data which is useful for performance analysis. Custom made medical haptic VR training simulators were developed and used to record data from 271 trainees of multiple clinical experience levels. DTW Multivariate Prototyping (DTW-MP) is proposed. VR data was classified as Novice, Intermediate or Expert. Accuracy of algorithms applied for time-series classification were: dynamic time warping 1-nearest neighbor (DTW-1NN) 60%, nearest centroid SoftDTW classification 77.5%, Deep Learning: ResNet 85%, FCN 75%, CNN 72.5% and MCDCNN 28.5%. Expert VR data recordings can be used for guidance of novices. Assessment feedback can help trainees to improve skills and consistency. Motion analysis can identify different techniques used by individuals. Mistakes can be detected dynamically in real-time, raising alarms to prevent injuries. © 2020 Elsevier Ltd","Classification; Medical training; Simulation; Skill assessment; Time series; Virtual reality","","Elsevier Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85086502860"
"Halabi O.; Salahuddin T.; Karkar A.G.; Alinier G.","Halabi, Osama (57203219290); Salahuddin, Tooba (57204787863); Karkar, Abdel Ghani (56237720100); Alinier, Guillaume (6506887966)","57203219290; 57204787863; 56237720100; 6506887966","Virtual reality for ambulance simulation environment","2022","Multimedia Tools and Applications","81","22","","32119","32137","18","4","10.1007/s11042-022-12980-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128034611&doi=10.1007%2fs11042-022-12980-3&partnerID=40&md5=41ce7d1761329b7acab8d71d340947d9","Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar; KINDI Center for Computing Research, Qatar University, Doha, Qatar; Hamad Medical Corporation Ambulance Service, Doha, Qatar; School of Health and Social Work, University of Hertfordshire, Hatfield, United Kingdom; Weill Cornell Medicine – Qatar, Doha, Qatar; Northumbria University, Newcastle upon Tyne, United Kingdom","Halabi O., Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar; Salahuddin T., Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar, KINDI Center for Computing Research, Qatar University, Doha, Qatar; Karkar A.G., Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar; Alinier G., Hamad Medical Corporation Ambulance Service, Doha, Qatar, School of Health and Social Work, University of Hertfordshire, Hatfield, United Kingdom, Weill Cornell Medicine – Qatar, Doha, Qatar, Northumbria University, Newcastle upon Tyne, United Kingdom","Simulations are beneficial in evaluating clinicians’ empirical competencies through practical skills, prioritizing, and decision-making as part of patient care scenarios generally run in a full-scale physical context. However, such simulations require physical space, manufacturing, and replacement of damaged or used equipment. On the other hand, virtual reality (VR) computerized simulators are comparatively modern instruments for use in practical training. VR can be employed to simulate real-world situations without the actual need for physical devices. This work presents an ambulance patient compartment VR simulation that can be used by emergency medical services (EMS) staff to customize the configuration of the ambulance patient compartment according to their preference as well as for vehicle orientation or training purposes. The proposed simulation can be used repeatedly enabling the paramedics to access equipment in a fully immersive and safe environment. The user studies have demonstrated the usability and perceived effectiveness of the proposed simulation. © 2022, The Author(s).","Ambulance design; Ambulance patient compartment; Equipment positioning; Virtual reality simulation","","Springer","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85128034611"
"Li K.; Liu C.; Zhu T.; Herrero P.; Georgiou P.","Li, Kezhi (55488020900); Liu, Chengyuan (57188640927); Zhu, Taiyu (57203244209); Herrero, Pau (8693403100); Georgiou, Pantelis (16301582200)","55488020900; 57188640927; 57203244209; 8693403100; 16301582200","GluNet: A Deep Learning Framework for Accurate Glucose Forecasting","2020","IEEE Journal of Biomedical and Health Informatics","24","2","8779644","414","423","9","101","10.1109/JBHI.2019.2931842","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079097427&doi=10.1109%2fJBHI.2019.2931842&partnerID=40&md5=0e6cdfc00ed9bdb04e7b266d1aae5a70","Department of Electronic and Electrical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom","Li K., Department of Electronic and Electrical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom; Liu C., Department of Electronic and Electrical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom; Zhu T., Department of Electronic and Electrical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom; Herrero P., Department of Electronic and Electrical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom; Georgiou P., Department of Electronic and Electrical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom","For people with Type 1 diabetes (T1D), forecasting of blood glucose (BG) can be used to effectively avoid hyperglycemia, hypoglycemia and associated complications. The latest continuous glucose monitoring (CGM) technology allows people to observe glucose in real-time. However, an accurate glucose forecast remains a challenge. In this work, we introduce GluNet, a framework that leverages on a personalized deep neural network to predict the probabilistic distribution of short-term (30-60 minutes) future CGM measurements for subjects with T1D based on their historical data including glucose measurements, meal information, insulin doses, and other factors. It adopts the latest deep learning techniques consisting of four components: data pre-processing, label transform/recover, multi-layers of dilated convolution neural network (CNN), and post-processing. The method is evaluated in-silico for both adult and adolescent subjects. The results show significant improvements over existing methods in the literature through a comprehensive comparison in terms of root mean square error (RMSE) (8.88 ± 0.77 mg/dL) with short time lag (0.83 ± 0.40 minutes) for prediction horizons (PH) = 30 mins (minutes), and RMSE (19.90 ± 3.17 mg/dL) with time lag (16.43 ± 4.07 mins) for PH = 60 mins for virtual adult subjects. In addition, GluNet is also tested on two clinical data sets. Results show that it achieves an RMSE (19.28 ± 2.76 mg/dL) with time lag (8.03 ± 4.07 mins) for PH = 30 mins and an RMSE (31.83 ± 3.49 mg/dL) with time lag (17.78 ± 8.00 mins) for PH = 60 mins. These are the best reported results for glucose forecasting when compared with other methods including the neural network for predicting glucose (NNPG), the support vector regression (SVR), the latent variable with exogenous input (LVX), and the auto regression with exogenous input (ARX) algorithm. © 2013 IEEE.","continuous glucose monitoring (CGM); Deep learning; diabetes; dilated convolutions; glucose forecasting","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85079097427"
"Urquhart L.; Petrakis K.; Hansen J.P.; Wodehouse A.; Mariani M.E.; Lauer-Schmaltz M.W.; Loudon B.","Urquhart, Lewis (57195756146); Petrakis, Konstantinos (57215678908); Hansen, John Paulin (55465667700); Wodehouse, Andrew (15073537700); Mariani, Milton Edgardo (57310342800); Lauer-Schmaltz, Martin Wolfgang (57728909400); Loudon, Brian (57218297835)","57195756146; 57215678908; 55465667700; 15073537700; 57310342800; 57728909400; 57218297835","Prototyping Approaches for Rehabilitation Devices: From Product Embodiment to Data Management","2023","Computer-Aided Design and Applications","20","S6","","145","157","12","2","10.14733/cadaps.2023.S6.145-157","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143518153&doi=10.14733%2fcadaps.2023.S6.145-157&partnerID=40&md5=b1cb76e5b86495795ed1f7dd1f9acc30","University of Strathclyde, Glasgow, United Kingdom; Technical University of Denmark, Copenhagen, Denmark; Loud1Design, Glasgow, United Kingdom","Urquhart L., University of Strathclyde, Glasgow, United Kingdom; Petrakis K., University of Strathclyde, Glasgow, United Kingdom; Hansen J.P., Technical University of Denmark, Copenhagen, Denmark; Wodehouse A., University of Strathclyde, Glasgow, United Kingdom; Mariani M.E., Technical University of Denmark, Copenhagen, Denmark; Lauer-Schmaltz M.W., Technical University of Denmark, Copenhagen, Denmark; Loudon B., Loud1Design, Glasgow, United Kingdom","This paper will present two research cases, both of which have similar objectives within upper-limb rehabilitation, which have utilized prototyping as a broad tool to explore the design solution space. Prototyping is a fundamental component of a large array of design work, with a multitude of techniques now available to designers of product embodiments and functions. PRIME-VR2 and ReHyb are two large European research projects focusing on efforts to reinvent medical rehabilitation through engagement with new technological advances to develop unique biomedical devices. PRIME-VR2 is focused on the development of a bespoke virtual reality gaming controller that can recreate therapeutic motions, while ReHyb aims to create rehabilitation aiding assistive exoskeletons. Prototyping has been a critical tool in the development of the design solutions, notably PRIME-VR2 has explored a range of novel additive manufacturing strategies such as a complex phased printing procedure and the ReHyb project has made innovative use of Lego Technic components in prototypes developed for human-robot interactions. Starting by examining the principles of prototyping within a bespoke device context, the two case studies are subsequently presented. Both are explored from the point of view of key prototyping practices and the data management and design generation tools. Lastly, the two projects are compared considering the strengths and weaknesses of both design approaches with a discussion focusing on the implications for future design projects that may have similar objectives in rehabilitative medicine. © 2023 CAD Solutions, LLC.","Bespoke devices; case studies; data management; rehabilitation","","CAD Solutions, LLC","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85143518153"
"Tadeja S.K.; Bohné T.; Godula K.; Cybulski A.; Woźniak M.M.","Tadeja, Sławomir Konrad (57209310553); Bohné, Thomas (6507819384); Godula, Kacper (58261330500); Cybulski, Artur (57216932715); Woźniak, Magdalena Maria (36560844100)","57209310553; 6507819384; 58261330500; 57216932715; 36560844100","Immersive presentations of real-world medical equipment through interactive VR environment populated with the high-fidelity 3D model of mobile MRI unit","2024","Computers and Graphics (Pergamon)","120","","103919","","","","0","10.1016/j.cag.2024.103919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190337570&doi=10.1016%2fj.cag.2024.103919&partnerID=40&md5=e7f675b6d6b19ba37b0e69d376112ebf","University of Cambridge, Cambridge, CB3 0FS, United Kingdom; Immersive sp. z o.o., Warsaw, 00-013, Poland; Medical University of Lublin, Lublin, 20-059, Poland; Eurodiagnostic Sp. z o.o., Warsaw, 02-530, Poland","Tadeja S.K., University of Cambridge, Cambridge, CB3 0FS, United Kingdom, Immersive sp. z o.o., Warsaw, 00-013, Poland, Eurodiagnostic Sp. z o.o., Warsaw, 02-530, Poland; Bohné T., University of Cambridge, Cambridge, CB3 0FS, United Kingdom; Godula K., Immersive sp. z o.o., Warsaw, 00-013, Poland; Cybulski A., Immersive sp. z o.o., Warsaw, 00-013, Poland; Woźniak M.M., Medical University of Lublin, Lublin, 20-059, Poland, Eurodiagnostic Sp. z o.o., Warsaw, 02-530, Poland","The primary goal behind the system presented in this paper is to investigate the efficacy of using virtual reality (VR) for showcasing sizable medical equipment. Specifically, we focused on a mobile magnetic resonance imaging (MRI) scanner mounted on a truck trailer. The latter is integral to the mobile MRI setup and must be presented as part of the immersive experience. Therefore, we not only have to depict the medical apparatus but also provide the means of understanding its surroundings. This is especially important to radiologists and other medical personnel to ascertain if a given mobile medical facility fulfills their needs and wants. Furthermore, despite such MRI devices being designed for mobility, their long-distance transportation can be time-consuming, troublesome and expensive. Therefore, we can observe the need for showcasing such mobile MRI units without additional cost and burden related to transportation. To achieve this, we designed an immersive environment in which the users can interact with the real-life scale 3D model of a mobile MRI. In addition, we also verified the usability and expressiveness of our system using established heuristical approaches. © 2024 The Author(s)","Immersive interface; Magnetic resonance imaging; MRI; Virtual presentation; Virtual reality; VR","","Elsevier Ltd","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85190337570"
"Dong B.; Li J.; Yang G.; Cheng X.; Gang Q.","Dong, Bin (57207453350); Li, Jianqun (57215539956); Yang, Guojie (23390965600); Cheng, Xiaochun (8703158600); Gang, Qinguo (57204846432)","57207453350; 57215539956; 23390965600; 8703158600; 57204846432","A Multi-Component Conical Spring Model of Soft Tissue in Virtual Surgery","2020","IEEE Access","8","","9160939","146093","146104","11","7","10.1109/ACCESS.2020.3014730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090291889&doi=10.1109%2fACCESS.2020.3014730&partnerID=40&md5=6ff10debb3213621680d9555b85e41f0","Affiliated Hospital of Hebei University, Hebei University, Baoding, China; Key Laboratory of Digital Medical Engineering of Hebei Province, College of Electronic and Information Engineering, Hebei University, Baoding, China; Faculty of Science and Technology, Middlesex University, London, United Kingdom; College of Civil Engineering and Architecture, Hebei University, Baoding, China","Dong B., Affiliated Hospital of Hebei University, Hebei University, Baoding, China, Key Laboratory of Digital Medical Engineering of Hebei Province, College of Electronic and Information Engineering, Hebei University, Baoding, China, Faculty of Science and Technology, Middlesex University, London, United Kingdom; Li J., Key Laboratory of Digital Medical Engineering of Hebei Province, College of Electronic and Information Engineering, Hebei University, Baoding, China; Yang G., Affiliated Hospital of Hebei University, Hebei University, Baoding, China; Cheng X., Faculty of Science and Technology, Middlesex University, London, United Kingdom; Gang Q., College of Civil Engineering and Architecture, Hebei University, Baoding, China","With the rapid development of optical system and medical robotic technology, the virtual surgery approach has achieved good progress but also faces many challenges. Physical and mechanical models of soft tissue characteristics have been a hot research topic in this field. In the present investigation, a physical model with a new multi-component conical spring is proposed, which replaces the cylindrical spring of the traditional mass-spring model. In the new model, a multi-component spring structure has been incorporated that consists of a conical spring and a linear spring in series. Based on the analysis of the nonlinear characteristics of soft tissue, the mechanical model was established to correspond better with the physical behavior. To determine the parameters for the mechanical model, the Euler method was deployed. The determination of the model parameters was achieved using physical tests. Result simulation experiments confirmed that the behavior of the new multi-component conical spring model proposed in the present paper gives results that are closer to those obtained from real-world physical tests than were data given by either the mass-conical-spring model or the mass-spring-model. Average difference, maximum difference and mean square error values were used for the evaluation. The accuracy of simulations for soft tissue virtual surgery can be improved by application of the new model developed in the present study.  © 2013 IEEE.","computer vision; conical spring; mechanical model; medical robotics; multi-component conical spring model; soft tissue modeling; Virtual reality","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85090291889"
"Vallefuoco E.; Bravaccio C.; Gison G.; Pecchia L.; Pepino A.","Vallefuoco, Ersilia (57194871725); Bravaccio, Carmela (6603209429); Gison, Giovanna (55803626000); Pecchia, Leandro (35746897300); Pepino, Alessandro (8763738900)","57194871725; 6603209429; 55803626000; 35746897300; 8763738900","Personalized Training via Serious Game to Improve Daily Living Skills in Pediatric Patients With Autism Spectrum Disorder","2022","IEEE Journal of Biomedical and Health Informatics","26","7","","3312","3322","10","13","10.1109/JBHI.2022.3155367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125734282&doi=10.1109%2fJBHI.2022.3155367&partnerID=40&md5=2ab1d90ea4725f963b57e6e6aecc8536","University of Naples Federico II, SInAPSi Centre, Naples, 80126, Italy; University of Naples Federico II, Department of Translational Medical Sciences, Naples, 80131, Italy; University of Campania Luigi Vanvitelli, Department of Mental Physical Health and Preventive Medicine, Naples, 80138, Italy; University of Warwick, School of Engineering, Coventry, CV47AL, United Kingdom; University of Naples Federico II, Department of Electrical Engineering and Information Technology, Naples, 80125, Italy","Vallefuoco E., University of Naples Federico II, SInAPSi Centre, Naples, 80126, Italy; Bravaccio C., University of Naples Federico II, Department of Translational Medical Sciences, Naples, 80131, Italy; Gison G., University of Campania Luigi Vanvitelli, Department of Mental Physical Health and Preventive Medicine, Naples, 80138, Italy; Pecchia L., University of Warwick, School of Engineering, Coventry, CV47AL, United Kingdom; Pepino A., University of Naples Federico II, Department of Electrical Engineering and Information Technology, Naples, 80125, Italy","The majority of people with Autism Spectrum Disorder (ASD) exhibit difficulties in social communication and behavior, which hinder their learning capability, amid others. Among technological solutions for people with ASD, serious games are frequently used to enhance learning of specific skills and instructional contents. However, because of heterogeneity in applications and game design, few studies have investigated their use in training daily activities. This paper presents a 3D personalized serious game we developed and validated to help ASD patients practice with shopping activities. Personalized training is paramount in people with ASD, thus several elements of this game were personalized to improve engagement and therefore the effectiveness of the virtual training. In order to assess the validity of the game, ten subjects (age 11.9, 2.7', 20% female) with ASD played ten sessions of the serious game, once per week. The participants underwent a real-life experience pre- and post-training in a real-life supermarket. Changes in daily living skills among participants were evaluated through specific tools: a form based on the International Classification of Functioning, Disability and Health for Children and Youth; and the Vineland Adaptive Behavior Scale II. Significant improvements (p < 0.05) were detected in the main skills trained with the serious game, especially in learning the shopping procedure, directing attention, and problem-solving skills. These findings suggest that personalized serious games can represent a prominent tool to enhance daily living skills, but future work should clinically validate their efficacy. © 2013 IEEE.","Autism spectrum disorder; daily living skills; human-computer interactions; Serious games","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85125734282"
"Sujar A.; Kelly G.; García M.; Vidal F.P.","Sujar, Aaron (57202589141); Kelly, Graham (57217504414); García, Marcos (57271014000); Vidal, Franck P. (56277522500)","57202589141; 57217504414; 57271014000; 56277522500","Interactive teaching environment for diagnostic radiography with real-time X-ray simulation and patient positioning","2022","International Journal of Computer Assisted Radiology and Surgery","17","1","","85","95","10","12","10.1007/s11548-021-02499-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116996217&doi=10.1007%2fs11548-021-02499-7&partnerID=40&md5=7e44b20b3a15da6ac9681c151e2e49ce","Universidad Rey Juan Carlos, Madrid, Spain; Bangor University, Bangor, United Kingdom; Shrewsbury and Telford Hospital NHS Trust, Shrewsbury, United Kingdom","Sujar A., Universidad Rey Juan Carlos, Madrid, Spain, Bangor University, Bangor, United Kingdom; Kelly G., Shrewsbury and Telford Hospital NHS Trust, Shrewsbury, United Kingdom; García M., Universidad Rey Juan Carlos, Madrid, Spain; Vidal F.P., Bangor University, Bangor, United Kingdom","Purpose: Traditional undergraduate radiographer training mixes academic lectures and clinical practice. Our goal is to bridge the current disconnection between theory and practice in a safe environment, avoiding the risk of radiation for both practitioners and patients. To this end, this research proposes a new software to teach diagnostic radiography using real-time interactive X-ray simulation and patient positioning. Methods: The proposed medical simulator is composed of three main modules. A fast and accurate character animation technique is in charge of simulating the patient positioning phase and adapts their internal anatomy accordingly. gVirtualXRay is an open-source X-ray simulation library and generates the corresponding radiographs in real time. Finally, the courseware allows going through all the diagnostic radiology steps from the patient positioning and the machine configuration to the final image enhancing. Results: A face and content validation study has been conducted; 18 radiology professionals were recruited to evaluate our software using a questionnaire. The results show that our tool is realistic in many ways (72% of the participants agreed that the simulations are visually realistic), useful (67%) and suitable (78%) for teaching X-ray radiography. Conclusions: The proposed tool allows simulating the most relevant steps of the projectional radiography procedure. The virtual patient posing system and X-ray simulation module execute at interactive rates. These features enable the lectures to show their students the results of good and bad practices in a classroom environment, avoiding radiation risk. © 2021, The Author(s).","Diagnostic radiography; Medical diagnostic imaging; Medical simulation; Training; Virtual reality; X-rays","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85116996217"
"Kengyelics S.M.; Treadgold L.A.; Davies A.G.","Kengyelics, Stephen M. (6602613511); Treadgold, Laura A. (56964472900); Davies, Andrew G. (57193933112)","6602613511; 56964472900; 57193933112","X-ray system simulation software tools for radiology and radiography education","2018","Computers in Biology and Medicine","93","","","175","183","8","15","10.1016/j.compbiomed.2017.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040035625&doi=10.1016%2fj.compbiomed.2017.12.005&partnerID=40&md5=4f68c30a9a0ac1cc8f85f68f3c9440eb","Specialist Science Education Department, Leeds Institute of Cardiovascular and Metabolic Medicine, School of Medicine, University of Leeds, Leeds, United Kingdom","Kengyelics S.M., Specialist Science Education Department, Leeds Institute of Cardiovascular and Metabolic Medicine, School of Medicine, University of Leeds, Leeds, United Kingdom; Treadgold L.A., Specialist Science Education Department, Leeds Institute of Cardiovascular and Metabolic Medicine, School of Medicine, University of Leeds, Leeds, United Kingdom; Davies A.G., Specialist Science Education Department, Leeds Institute of Cardiovascular and Metabolic Medicine, School of Medicine, University of Leeds, Leeds, United Kingdom","Objectives To develop x-ray simulation software tools to support delivery of radiological science education for a range of learning environments and audiences including individual study, lectures, and tutorials. Methods Two software tools were developed; one simulated x-ray production for a simple two dimensional radiographic system geometry comprising an x-ray source, beam filter, test object and detector. The other simulated the acquisition and display of two dimensional radiographic images of complex three dimensional objects using a ray casting algorithm through three dimensional mesh objects. Both tools were intended to be simple to use, produce results accurate enough to be useful for educational purposes, and have an acceptable simulation time on modest computer hardware. The radiographic factors and acquisition geometry could be altered in both tools via their graphical user interfaces. A comparison of radiographic contrast measurements of the simulators to a real system was performed. Results The contrast output of the simulators had excellent agreement with measured results. The software simulators were deployed to 120 computers on campus. Conclusions The software tools developed are easy-to-use, clearly demonstrate important x-ray physics and imaging principles, are accessible within a standard University setting and could be used to enhance the teaching of x-ray physics to undergraduate students. Advances in knowledge Current approaches to teaching x-ray physics in radiological science lack immediacy when linking theory with practice. This method of delivery allows students to engage with the subject in an experiential learning environment. © 2017","Education; Simulation; Virtual radiography; X-ray imaging; X-ray physics","","Elsevier Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85040035625"
"Kunz J.M.; Maloca P.; Allemann A.; Fasler D.; Soysal S.; Däster S.; Kraljević M.; Syeda G.; Weixler B.; Nebiker C.; Ochs V.; Droeser R.; Walker H.L.; Bolli M.; Müller B.; Cattin P.; Staubli S.M.","Kunz, Julia Madlaina (56312877300); Maloca, Peter (6507518152); Allemann, Andreas (57863690300); Fasler, David (22955656300); Soysal, Savas (55206915000); Däster, Silvio (37060579200); Kraljević, Marko (37261575700); Syeda, Gulbahar (58508805200); Weixler, Benjamin (56716210800); Nebiker, Christian (25922979200); Ochs, Vincent (57274053200); Droeser, Raoul (14019241800); Walker, Harriet Louise (58477794100); Bolli, Martin (6603672588); Müller, Beat (14322034300); Cattin, Philippe (6506422723); Staubli, Sebastian Manuel (57053200400)","56312877300; 6507518152; 57863690300; 22955656300; 55206915000; 37060579200; 37261575700; 58508805200; 56716210800; 25922979200; 57274053200; 14019241800; 58477794100; 6603672588; 14322034300; 6506422723; 57053200400","Assessment of resectability of pancreatic cancer using novel immersive high-performance virtual reality rendering of abdominal computed tomography and magnetic resonance imaging","2024","International Journal of Computer Assisted Radiology and Surgery","","","","","","","0","10.1007/s11548-023-03048-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182847119&doi=10.1007%2fs11548-023-03048-0&partnerID=40&md5=36f71e74d5a06f8c6922f323a5f826e0","Faculty of Medicine, University of Basel, Klingelbergstrasse 61, Basel, 4056, Switzerland; Institute of Molecular and Clinical Ophthalmology Basel (IOB), Mittlere Strasse 91, Basel, 4031, Switzerland; Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Department of Radiology St. Claraspital Basel, Kleinriehenstrasse 30, Basel, 4058, Switzerland; Department of HPB Surgery and Liver Transplantation, Royal Free Hospital, London, NHS Foundation Trust, Pond Street, London, NW3 2Q, United Kingdom; Department of General, Visceral and Vascular Sugery, Charité Campus Benjamin Franklin, Hindenburgdamm 20, Berlin, 12203, Germany; Surgical Department, Cantonal Hospital Aarau, Tellstrasse 25, Aarau, 5001, Switzerland; Department of Biomedical Engineering, University of Basel, Hegenheimermattweg 167c, Allschwil, 4123, Switzerland; Department of Ophthalmology, University of Basel, Basel, 4031, Switzerland; Moorfields Eye Hospital, NHS Foundation Trust, London, EC1V 2PD, United Kingdom; Department of Women’s Health, University College London Hospitals, London, United Kingdom","Kunz J.M., Faculty of Medicine, University of Basel, Klingelbergstrasse 61, Basel, 4056, Switzerland; Maloca P., Institute of Molecular and Clinical Ophthalmology Basel (IOB), Mittlere Strasse 91, Basel, 4031, Switzerland, Department of Ophthalmology, University of Basel, Basel, 4031, Switzerland, Moorfields Eye Hospital, NHS Foundation Trust, London, EC1V 2PD, United Kingdom; Allemann A., Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Fasler D., Department of Radiology St. Claraspital Basel, Kleinriehenstrasse 30, Basel, 4058, Switzerland; Soysal S., Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Däster S., Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Kraljević M., Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Syeda G., Department of HPB Surgery and Liver Transplantation, Royal Free Hospital, London, NHS Foundation Trust, Pond Street, London, NW3 2Q, United Kingdom; Weixler B., Department of General, Visceral and Vascular Sugery, Charité Campus Benjamin Franklin, Hindenburgdamm 20, Berlin, 12203, Germany; Nebiker C., Surgical Department, Cantonal Hospital Aarau, Tellstrasse 25, Aarau, 5001, Switzerland; Ochs V., Department of Biomedical Engineering, University of Basel, Hegenheimermattweg 167c, Allschwil, 4123, Switzerland; Droeser R., Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Walker H.L., Department of Women’s Health, University College London Hospitals, London, United Kingdom; Bolli M., Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Müller B., Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland; Cattin P., Department of Biomedical Engineering, University of Basel, Hegenheimermattweg 167c, Allschwil, 4123, Switzerland; Staubli S.M., Faculty of Medicine, University of Basel, Klingelbergstrasse 61, Basel, 4056, Switzerland, Clarunis, University Center for Gastrointestinal and Liver Diseases, Basel, 4002, Switzerland, Department of HPB Surgery and Liver Transplantation, Royal Free Hospital, London, NHS Foundation Trust, Pond Street, London, NW3 2Q, United Kingdom","Purpose: Virtual reality (VR) allows for an immersive and interactive analysis of imaging data such as computed tomography (CT) and magnetic resonance imaging (MRI). The aim of this study is to assess the comprehensibility of VR anatomy and its value in assessing resectability of pancreatic ductal adenocarcinoma (PDAC). Methods: This study assesses exposure to VR anatomy and evaluates the potential role of VR in assessing resectability of PDAC. Firstly, volumetric abdominal CT and MRI data were displayed in an immersive VR environment. Volunteering physicians were asked to identify anatomical landmarks in VR. In the second stage, experienced clinicians were asked to identify vascular involvement in a total of 12 CT and MRI scans displaying PDAC (2 resectable, 2 borderline resectable, and 2 locally advanced tumours per modality). Results were compared to 2D standard PACS viewing. Results: In VR visualisation of CT and MRI, the abdominal anatomical landmarks were recognised by all participants except the pancreas (30/34) in VR CT and the splenic (31/34) and common hepatic artery (18/34) in VR MRI, respectively. In VR CT, resectable, borderline resectable, and locally advanced PDAC were correctly identified in 22/24, 20/24 and 19/24 scans, respectively. Whereas, in VR MRI, resectable, borderline resectable, and locally advanced PDAC were correctly identified in 19/24, 19/24 and 21/24 scans, respectively. Interobserver agreement as measured by Fleiss κ was 0.7 for CT and 0.4 for MRI, respectively (p < 0.001). Scans were significantly assessed more accurately in VR CT than standard 2D PACS CT, with a median of 5.5 (IQR 4.75–6) and a median of 3 (IQR 2–3) correctly assessed out of 6 scans (p < 0.001). Conclusion: VR enhanced visualisation of abdominal CT and MRI scan data provides intuitive handling and understanding of anatomy and might allow for more accurate staging of PDAC and could thus become a valuable adjunct in PDAC resectability assessment in the future. © 2024, The Author(s).","Anatomy; Innovation; Medical training; Pancreatic cancer; Virtual reality","","Springer Science and Business Media Deutschland GmbH","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85182847119"
"Falah J.; Wedyan M.; Alfalah S.F.M.; Abu-Tarboush M.; Al-Jakheem A.; Al-Faraneh M.; Abuhammad A.; Charissis V.","Falah, Jannat (55350011200); Wedyan, Mohammad (57225269506); Alfalah, Salsabeel F. M. (55583479900); Abu-Tarboush, Muhannad (57222492538); Al-Jakheem, Ahmad (57246324400); Al-Faraneh, Muath (57246113000); Abuhammad, Areej (35483177800); Charissis, Vassilis (22733653900)","55350011200; 57225269506; 55583479900; 57222492538; 57246324400; 57246113000; 35483177800; 22733653900","Identifying the characteristics of virtual reality gamification for complex educational topics","2021","Multimodal Technologies and Interaction","5","9","53","","","","21","10.3390/mti5090053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114230196&doi=10.3390%2fmti5090053&partnerID=40&md5=5538bcd0d8298cca5d0958ad770cfc64","Department of Autonomous Systems, Faculty of Artificial Intelligence, Al Balqa Applied University, Al Salt, 19117, Jordan; King Abdullah II School of Information Technology, The University of Jordan, Amman, 11942, Jordan; Department of Pharmaceutical Sciences, School of Pharmacy, The University of Jordan, Amman, 11942, Jordan; School of Computing, Engineering and Built Environment, Glasgow Caledonian University, Glasgow, G4-0BA, United Kingdom","Falah J., Department of Autonomous Systems, Faculty of Artificial Intelligence, Al Balqa Applied University, Al Salt, 19117, Jordan; Wedyan M., Department of Autonomous Systems, Faculty of Artificial Intelligence, Al Balqa Applied University, Al Salt, 19117, Jordan; Alfalah S.F.M., King Abdullah II School of Information Technology, The University of Jordan, Amman, 11942, Jordan; Abu-Tarboush M., King Abdullah II School of Information Technology, The University of Jordan, Amman, 11942, Jordan; Al-Jakheem A., King Abdullah II School of Information Technology, The University of Jordan, Amman, 11942, Jordan; Al-Faraneh M., King Abdullah II School of Information Technology, The University of Jordan, Amman, 11942, Jordan; Abuhammad A., Department of Pharmaceutical Sciences, School of Pharmacy, The University of Jordan, Amman, 11942, Jordan; Charissis V., School of Computing, Engineering and Built Environment, Glasgow Caledonian University, Glasgow, G4-0BA, United Kingdom","Multidisciplinary topics in education pose a major challenge for traditional learning and teaching methods. Such topics can deter students from selecting particular courses or hinder their study progress. This study focused on the subject of medicinal chemistry, which is a discipline com-bining medicine and chemistry. This combination of applied and basic science creates a complex field of education that is challenging to both teach and learn. Chemical and pharmacological principles are typically presented in 2D molecular structures and, recently, 3D molecular models have been utilized to improve the visualization of chemical compounds and their chemical interactions. Contemporary studies have presented Virtual Reality (VR) as an alternative method for improving the learning and teaching of multidisciplinary specialties such as this. However, current educational efforts employing VR offer limited interactivity and a traditional teaching method previously presented in 2D. This reduces students’ interest and concentration in the taught subjects. This paper presents the development rationale of a novel VR educational application based on the evaluation of the user requirements by 405 pharmacy undergraduate students. The results informed the development and preliminary evaluation of a proposed VR serious game application, which was deployed in a real-life class environment and evaluated in contrast to traditional teaching methods by 15 students. The derived results confirmed the advantages of VR technology as a learning and teaching tool, in addition to the end-users’ willingness to adopt VR systems as a learning aid. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Distance learning; Education; Education equity; Gamification; Human-Computer Interaction; Medical pharma-cology; Virtual reality","","MDPI","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85114230196"
"Bacon W.; Holinski A.; Pujol M.; Wilmott M.; Morgan S.L.; Alibi M.; Araujo D.R.; Broadbent A.; Brooksbank C.; Lopez P.C.; Crawte D.; Gaur P.S.; Gopalasingam P.; Hancocks T.; Llinares M.L.; Matser V.; McClintock B.; Mendonca M.; Mishra A.; Nicholl R.; Pearton C.; Pomeroy E.; Rice D.","Bacon, Wendi (56419574800); Holinski, Alexandra (57219801163); Pujol, Marina (57825074400); Wilmott, Meredith (57825159900); Morgan, Sarah L. (58282559200); Alibi, Mohamed (57192175162); Araujo, Dayane Rodrigues (57883827900); Broadbent, Adam (57204110572); Brooksbank, Cath (57150825000); Lopez, Patricia Carvahal (57883828000); Crawte, Derrin (57883828100); Gaur, Prakash Singh (57218829000); Gopalasingam, Piv (57884830500); Hancocks, Thomas (56051455300); Llinares, Marta Lloret (58042132100); Matser, Vera (57200375625); McClintock, Brett (14527567900); Mendonca, Michelle (57883577700); Mishra, Ajay (57884077400); Nicholl, Rebecca (57883828200); Pearton, Charlotte (57883577800); Pomeroy, Emily (57884329100); Rice, Deborah (57884077500)","56419574800; 57219801163; 57825074400; 57825159900; 58282559200; 57192175162; 57883827900; 57204110572; 57150825000; 57883828000; 57883828100; 57218829000; 57884830500; 56051455300; 58042132100; 57200375625; 14527567900; 57883577700; 57884077400; 57883828200; 57883577800; 57884329100; 57884077500","Ten simple rules for leveraging virtual interaction to build higher-level learning into bioinformatics short courses","2022","PLoS Computational Biology","18","7","e1010220","","","","1","10.1371/journal.pcbi.1010220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135202257&doi=10.1371%2fjournal.pcbi.1010220&partnerID=40&md5=42eb7da7d3116daca04200b0b2ec46e6","School of Life, Health & Chemical Sciences, Faculty of Science, Technology, Engineering & Mathematics, The Open University, Milton Keynes, United Kingdom; European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Cambridgeshire, Hinxton, United Kingdom","Bacon W., School of Life, Health & Chemical Sciences, Faculty of Science, Technology, Engineering & Mathematics, The Open University, Milton Keynes, United Kingdom; Holinski A., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Cambridgeshire, Hinxton, United Kingdom; Pujol M., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Cambridgeshire, Hinxton, United Kingdom; Wilmott M., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Cambridgeshire, Hinxton, United Kingdom; Morgan S.L., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Cambridgeshire, Hinxton, United Kingdom; Alibi M.; Araujo D.R.; Broadbent A.; Brooksbank C.; Lopez P.C.; Crawte D.; Gaur P.S.; Gopalasingam P.; Hancocks T.; Llinares M.L.; Matser V.; McClintock B.; Mendonca M.; Mishra A.; Nicholl R.; Pearton C.; Pomeroy E.; Rice D.","[No abstract available]","","","Public Library of Science","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85135202257"
"Xia Y.; Ravikumar N.; Lassila T.; Frangi A.F.","Xia, Yan (57219626194); Ravikumar, Nishant (57190258888); Lassila, Toni (56850405700); Frangi, Alejandro F. (7005249248)","57219626194; 57190258888; 56850405700; 7005249248","Virtual high-resolution MR angiography from non-angiographic multi-contrast MRIs: synthetic vascular model populations for in-silico trials","2023","Medical Image Analysis","87","","102814","","","","1","10.1016/j.media.2023.102814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159477298&doi=10.1016%2fj.media.2023.102814&partnerID=40&md5=c4c31ce54870ac2314a558634c13f061","Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, United Kingdom; Leeds Institute for Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, United Kingdom; Medical Imaging Research Center (MIRC), Cardiovascular Science and Electronic Engineering Departments, KU Leuven, Leuven, Belgium; Alan Turing Institute, London, United Kingdom","Xia Y., Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, United Kingdom; Ravikumar N., Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, United Kingdom; Lassila T., Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, United Kingdom; Frangi A.F., Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing, University of Leeds, Leeds, United Kingdom, Leeds Institute for Cardiovascular and Metabolic Medicine (LICAMM), School of Medicine, University of Leeds, Leeds, United Kingdom, Medical Imaging Research Center (MIRC), Cardiovascular Science and Electronic Engineering Departments, KU Leuven, Leuven, Belgium, Alan Turing Institute, London, United Kingdom","Despite success on multi-contrast MR image synthesis, generating specific modalities remains challenging. Those include Magnetic Resonance Angiography (MRA) that highlights details of vascular anatomy using specialised imaging sequences for emphasising inflow effect. This work proposes an end-to-end generative adversarial network that can synthesise anatomically plausible, high-resolution 3D MRA images using commonly acquired multi-contrast MR images (e.g. T1/T2/PD-weighted MR images) for the same subject whilst preserving the continuity of vascular anatomy. A reliable technique for MRA synthesis would unleash the research potential of very few population databases with imaging modalities (such as MRA) that enable quantitative characterisation of whole-brain vasculature. Our work is motivated by the need to generate digital twins and virtual patients of cerebrovascular anatomy for in-silico studies and/or in-silico trials. We propose a dedicated generator and discriminator that leverage the shared and complementary features of multi-source images. We design a composite loss function for emphasising vascular properties by minimising the statistical difference between the feature representations of the target images and the synthesised outputs in both 3D volumetric and 2D projection domains. Experimental results show that the proposed method can synthesise high-quality MRA images and outperform the state-of-the-art generative models both qualitatively and quantitatively. The importance assessment reveals that T2 and PD-weighted images are better predictors of MRA images than T1; and PD-weighted images contribute to better visibility of small vessel branches towards the peripheral regions. In addition, the proposed approach can generalise to unseen data acquired at different imaging centres with different scanners, whilst synthesising MRAs and vascular geometries that maintain vessel continuity. The results show the potential for use of the proposed approach to generating digital twin cohorts of cerebrovascular anatomy at scale from structural MR images typically acquired in population imaging initiatives. © 2023 The Authors","Conditional generative adversarial net; Medical image synthesis; MR angiography; Multi-contrast MRI","","Elsevier B.V.","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85159477298"
"Józsa T.I.; Padmos R.M.; El-Bouri W.K.; Hoekstra A.G.; Payne S.J.","Józsa, T.I. (56419767600); Padmos, R.M. (57190497667); El-Bouri, W.K. (55941397000); Hoekstra, A.G. (7007050341); Payne, S.J. (35729165200)","56419767600; 57190497667; 55941397000; 7007050341; 35729165200","On the Sensitivity Analysis of Porous Finite Element Models for Cerebral Perfusion Estimation","2021","Annals of Biomedical Engineering","49","12","","3647","3665","18","15","10.1007/s10439-021-02808-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114818378&doi=10.1007%2fs10439-021-02808-w&partnerID=40&md5=db8db99b2d13b041e265dabf61f259a4","Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford, OX1 3PJ, United Kingdom; Computational Science Laboratory, Institute for Informatics, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands; Liverpool Centre for Cardiovascular Science, Department of Cardiovascular and Metabolic Medicine, University of Liverpool, Thomas Drive, Liverpool, L14 3PE, United Kingdom","Józsa T.I., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford, OX1 3PJ, United Kingdom; Padmos R.M., Computational Science Laboratory, Institute for Informatics, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands; El-Bouri W.K., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford, OX1 3PJ, United Kingdom, Liverpool Centre for Cardiovascular Science, Department of Cardiovascular and Metabolic Medicine, University of Liverpool, Thomas Drive, Liverpool, L14 3PE, United Kingdom; Hoekstra A.G., Computational Science Laboratory, Institute for Informatics, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands; Payne S.J., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford, OX1 3PJ, United Kingdom","Computational physiological models are promising tools to enhance the design of clinical trials and to assist in decision making. Organ-scale haemodynamic models are gaining popularity to evaluate perfusion in a virtual environment both in healthy and diseased patients. Recently, the principles of verification, validation, and uncertainty quantification of such physiological models have been laid down to ensure safe applications of engineering software in the medical device industry. The present study sets out to establish guidelines for the usage of a three-dimensional steady state porous cerebral perfusion model of the human brain following principles detailed in the verification and validation (V&V 40) standard of the American Society of Mechanical Engineers. The model relies on the finite element method and has been developed specifically to estimate how brain perfusion is altered in ischaemic stroke patients before, during, and after treatments. Simulations are compared with exact analytical solutions and a thorough sensitivity analysis is presented covering every numerical and physiological model parameter. The results suggest that such porous models can approximate blood pressure and perfusion distributions reliably even on a coarse grid with first order elements. On the other hand, higher order elements are essential to mitigate errors in volumetric blood flow rate estimation through cortical surface regions. Matching the volumetric flow rate corresponding to major cerebral arteries is identified as a validation milestone. It is found that inlet velocity boundary conditions are hard to obtain and that constant pressure inlet boundary conditions are feasible alternatives. A one-dimensional model is presented which can serve as a computationally inexpensive replacement of the three-dimensional brain model to ease parameter optimisation, sensitivity analyses and uncertainty quantification. The findings of the present study can be generalised to organ-scale porous perfusion models. The results increase the applicability of computational tools regarding treatment development for stroke and other cerebrovascular conditions. © 2021, The Author(s).","Finite element method; In silico trial; Ischaemic stroke; Organ-scale perfusion modelling; Porous brain model","","Springer","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85114818378"
"Huang C.; Zhou W.; Lan Y.; Chen F.; Hao Y.; Cheng Y.; Peng Y.","Huang, Chenxi (57196056436); Zhou, Wen (56984816000); Lan, Yisha (57202253643); Chen, Fei (57213590841); Hao, Yongtao (9634647100); Cheng, Yongqiang (56523637900); Peng, Yonghong (8349253200)","57196056436; 56984816000; 57202253643; 57213590841; 9634647100; 56523637900; 8349253200","A Novel WebVR-Based Lightweight Framework for Virtual Visualization of Blood Vasculum","2018","IEEE Access","6","","","27726","27735","9","5","10.1109/ACCESS.2018.2840494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047623092&doi=10.1109%2fACCESS.2018.2840494&partnerID=40&md5=f5d0ad40d128cf046be4a743e8002512","Department of Computer Science and Technology, Tongji University, Shanghai, 201804, China; School of Software Engineering, Tongji University, Shanghai, 200065, China; Department of Cardiology, Shanghai Tongji Hospital, Tongji University, Shanghai, 200065, China; School of Engineering and Computer Science, University of Hull, Hull, HU6 7RX, United Kingdom; Faculty of Computer Science, University of Sunderland, St Peter Campus, Sunderland, SR6 0DD, United Kingdom","Huang C., Department of Computer Science and Technology, Tongji University, Shanghai, 201804, China; Zhou W., School of Software Engineering, Tongji University, Shanghai, 200065, China; Lan Y., Department of Computer Science and Technology, Tongji University, Shanghai, 201804, China; Chen F., Department of Cardiology, Shanghai Tongji Hospital, Tongji University, Shanghai, 200065, China; Hao Y., Department of Computer Science and Technology, Tongji University, Shanghai, 201804, China; Cheng Y., School of Engineering and Computer Science, University of Hull, Hull, HU6 7RX, United Kingdom; Peng Y., Faculty of Computer Science, University of Sunderland, St Peter Campus, Sunderland, SR6 0DD, United Kingdom","With the arrival of the Web 2.0 era and the rapid development of virtual reality (VR) technology in recent years, WebVR technology has emerged as the combination of Web 2.0 and VR. Moreover, the concept of 'WebVR + medical science' is also proposed to advance medical applications. However, due to the limited storage space and low computing capability of Web browsers, it is difficult to achieve real-time rendering of large-scale medical vascular models on the Web, let alone large-scale vascular animation simulations. The framework proposed in this paper can achieve virtual display of the medical blood vasculum, including lightweight processing of the vasculum and virtual realization of blood flow. This innovative framework presents a simulation algorithm for the virtual blood path based on the Catmull-Rom spline. The mechanisms of progressive compression and online recovery of the lightweight vascular structure are further proposed. The experimental results show that our framework has a shorter browser-side response time than existing methods and achieves efficient real-time simulation. © 2013 IEEE.","aortic vascular; Catmull-Rom spline; lightweight vascular progressive compression; Web3D; WebVR","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85047623092"
"Pajaziti E.; Schievano S.; Sauvage E.; Cook A.; Capelli C.","Pajaziti, Endrit (57210072642); Schievano, Silvia (13410386200); Sauvage, Emilie (57199718533); Cook, Andrew (37078948800); Capelli, Claudio (24922737800)","57210072642; 13410386200; 57199718533; 37078948800; 24922737800","Investigating the feasibility of virtual reality (VR) for teaching cardiac morphology","2021","Electronics (Switzerland)","10","16","1889","","","","6","10.3390/electronics10161889","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112660303&doi=10.3390%2felectronics10161889&partnerID=40&md5=e34aff9bf9a631112c1fa43aa2b7b04d","Institute of Cardiovascular Science, University College London, London, WC1E 6BT, United Kingdom","Pajaziti E., Institute of Cardiovascular Science, University College London, London, WC1E 6BT, United Kingdom; Schievano S., Institute of Cardiovascular Science, University College London, London, WC1E 6BT, United Kingdom; Sauvage E., Institute of Cardiovascular Science, University College London, London, WC1E 6BT, United Kingdom; Cook A., Institute of Cardiovascular Science, University College London, London, WC1E 6BT, United Kingdom; Capelli C., Institute of Cardiovascular Science, University College London, London, WC1E 6BT, United Kingdom","Congenital heart disease (CHD) is the most common defect at birth. Effective training for clinical professionals is essential in order to provide a high standard of care for patients. Visual aids for teaching complex CHD have remained mostly unchanged in recent years, with traditional methods such as diagrams and specimens still essential for delivering educational content. Diagrams and other 2D visualisations for teaching are in most cases artistic illustrations with no direct relation to true, 3D medical data. Specimens are rare, difficult for students to access and are limited to specific institutions. Digital, patient-specific models could potentially address these problems within educational programmes. Virtual Reality (VR) can facilitate the access to digital models and enhance the educational experience. In this study, we recorded and analysed the sentiment of clinical professionals towards VR when learning about CHD. A VR application (VheaRts) containing a set of patient-specific models was developed in-house. The application was incorporated into a specialised cardiac morphology course to assess the feasibility of integrating such a tool, and to measure levels of acceptance. Attendees were clinical professionals from a diverse range of specialities. VR allowed users to interact with six different patient-derived models immersed within a 3D space. Feedback was recorded for 58 participants. The general response towards the use of VR was overwhelmingly positive, with 88% of attendees rating 4 or 5 for ’helpfulness of VR in learning CHD’ (5-points Likert scale). Additionally, 70% of participants with no prior VR experience rated 4 or 5 for ’intuitiveness and ease of use’. Our study indicates that VR has a high level of acceptance amongst clinical trainees when used as an effective aid for learning congenital heart disease. Additionally, we noted three specific use-cases where VR offered novel teaching experiences not possible with conventional methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","3D modelling; Cardiac morphology; Congenital heart disease; Education, teaching; Virtual reality","","MDPI AG","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85112660303"
"Phelan I.; Furness P.J.; Matsangidou M.; Babiker N.T.; Fehily O.; Thompson A.; Carrion-Plaza A.; Lindley S.A.","Phelan, Ivan (57063185600); Furness, Penny J (8531409900); Matsangidou, Maria (57196007400); Babiker, Nathan T. (57205177560); Fehily, Orla (57205181119); Thompson, Andrew (57199262188); Carrion-Plaza, Alicia (57205388356); Lindley, Shirley A. (57205178525)","57063185600; 8531409900; 57196007400; 57205177560; 57205181119; 57199262188; 57205388356; 57205178525","Designing effective virtual reality environments for pain management in burn-injured patients","2023","Virtual Reality","27","1","","201","215","14","8","10.1007/s10055-021-00552-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108620823&doi=10.1007%2fs10055-021-00552-z&partnerID=40&md5=ac7b8d1fc658ce5c33b6cdd8b66eed27","Centre for Culture, Media and Society, College of Social Sciences and Arts, Sheffield Hallam University, Sheffield, S1 1WB, United Kingdom; Centre for Behavioural Science and Applied Psychology (CeBSAP), College of Social Sciences and Arts, Sheffield Hallam University, Sheffield, S1 1WB, United Kingdom; Department of Psychological Services, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, S10 2JF, United Kingdom; Department of Psychology, University of Sheffield, Sheffield, S1 2LT, United Kingdom","Phelan I., Centre for Culture, Media and Society, College of Social Sciences and Arts, Sheffield Hallam University, Sheffield, S1 1WB, United Kingdom; Furness P.J., Centre for Behavioural Science and Applied Psychology (CeBSAP), College of Social Sciences and Arts, Sheffield Hallam University, Sheffield, S1 1WB, United Kingdom; Matsangidou M., Centre for Culture, Media and Society, College of Social Sciences and Arts, Sheffield Hallam University, Sheffield, S1 1WB, United Kingdom; Babiker N.T., Department of Psychological Services, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, S10 2JF, United Kingdom; Fehily O., Department of Psychological Services, Sheffield Teaching Hospitals NHS Foundation Trust, Sheffield, S10 2JF, United Kingdom; Thompson A., Department of Psychology, University of Sheffield, Sheffield, S1 2LT, United Kingdom; Carrion-Plaza A., Centre for Culture, Media and Society, College of Social Sciences and Arts, Sheffield Hallam University, Sheffield, S1 1WB, United Kingdom; Lindley S.A., Centre for Culture, Media and Society, College of Social Sciences and Arts, Sheffield Hallam University, Sheffield, S1 1WB, United Kingdom","Burn patients engage in repetitive painful therapeutic treatments, such as wound debridement, dressing changes, and other medical processes high in procedural pain. Pharmacological analgesics have been used for managing pain, but with ineffective results and negative side effects. Studies on pain management for burn patients suggested that Virtual Reality can treat procedural pain. This paper describes the process of designing, testing, and deploying a Virtual Reality system into a hospital setting. Firstly, a workshop was conducted to identify the most suitable types of Virtual Reality contents for the needs of burn-injured patients. Then, an experimental study, with 15 healthy adults, explored the analgesic impact of the Virtual Reality contents. The pain was induced through a cold pressor. Finally, we deployed the Virtual Reality system into the hospital to examine its efficiency on burn-injured inpatients. This study presents factors for the effective design and deployment of Virtual Reality for burn-injured patients residing in a hospital. Those factors refer to the use of cartoonish features and a choice of content based on each patient’s interests to increase the positive emotions and the use of interactive features, portable equipment to reduce pain and increase the feasibility of the technology in clinical settings. Finally, our results indicated that the extension of the VR use after the therapeutic session could support more effective pain treatment. Trial registration number Protocol ID: AA8434. © 2021, The Author(s).","Anxiety; Burn injuries; Interactivity; Pain; Patient-centred design; Virtual reality","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85108620823"
"Marlevi D.; Ha H.; Dillon-Murphy D.; Fernandes J.F.; Fovargue D.; Colarieti-Tosti M.; Larsson M.; Lamata P.; Figueroa C.A.; Ebbers T.; Nordsletten D.A.","Marlevi, David (57204277535); Ha, Hojin (55429354900); Dillon-Murphy, Desmond (56910277100); Fernandes, Joao F. (56511070500); Fovargue, Daniel (55826845500); Colarieti-Tosti, Massimiliano (57199353753); Larsson, Matilda (16744081600); Lamata, Pablo (12806240900); Figueroa, C. Alberto (36861762700); Ebbers, Tino (6603253440); Nordsletten, David A. (22954349100)","57204277535; 55429354900; 56910277100; 56511070500; 55826845500; 57199353753; 16744081600; 12806240900; 36861762700; 6603253440; 22954349100","Non-invasive estimation of relative pressure in turbulent flow using virtual work-energy","2020","Medical Image Analysis","60","","101627","","","","20","10.1016/j.media.2019.101627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076673140&doi=10.1016%2fj.media.2019.101627&partnerID=40&md5=cf0b8c8120ea90ccf7531e966ae8003c","Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Hälsovägen 11, 14152, Huddinge, Sweden; Department of Clinical Sciences, Karolinska Institutet, Danderyds sjukhus, Mörbygårdsvägen, Danderyd, 18288, Sweden; Department of Medical and Health Sciences and Center for Medical Image Science and Visualization (CMIV), Linköping Unversity, Linköping, SE-58185, Sweden; Department of Mechanical and Biomedical Engineering, Kangwon National University, Chuncheon, 24341, South Korea; School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, London, SE1 7EH, United Kingdom; Department of Surgery and Biomedical Engineering, University of Michigan, 2800 Plymouth Rd, 48109, Ann Arbor, MI, United States","Marlevi D., Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Hälsovägen 11, 14152, Huddinge, Sweden, Department of Clinical Sciences, Karolinska Institutet, Danderyds sjukhus, Mörbygårdsvägen, Danderyd, 18288, Sweden; Ha H., Department of Medical and Health Sciences and Center for Medical Image Science and Visualization (CMIV), Linköping Unversity, Linköping, SE-58185, Sweden, Department of Mechanical and Biomedical Engineering, Kangwon National University, Chuncheon, 24341, South Korea; Dillon-Murphy D., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, London, SE1 7EH, United Kingdom; Fernandes J.F., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, London, SE1 7EH, United Kingdom; Fovargue D., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, London, SE1 7EH, United Kingdom; Colarieti-Tosti M., Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Hälsovägen 11, 14152, Huddinge, Sweden; Larsson M., Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Hälsovägen 11, 14152, Huddinge, Sweden; Lamata P., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, London, SE1 7EH, United Kingdom; Figueroa C.A., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, London, SE1 7EH, United Kingdom, Department of Surgery and Biomedical Engineering, University of Michigan, 2800 Plymouth Rd, 48109, Ann Arbor, MI, United States; Ebbers T., Department of Medical and Health Sciences and Center for Medical Image Science and Visualization (CMIV), Linköping Unversity, Linköping, SE-58185, Sweden; Nordsletten D.A., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, London, SE1 7EH, United Kingdom, Department of Surgery and Biomedical Engineering, University of Michigan, 2800 Plymouth Rd, 48109, Ann Arbor, MI, United States","Vascular pressure differences are established risk markers for a number of cardiovascular diseases. Relative pressures are, however, often driven by turbulence-induced flow fluctuations, where conventional non-invasive methods may yield inaccurate results. Recently, we proposed a novel method for non-turbulent flows, νWERP, utilizing the concept of virtual work-energy to accurately probe relative pressure through complex branching vasculature. Here, we present an extension of this approach for turbulent flows: νWERP-t. We present a theoretical method derivation based on flow covariance, quantifying the impact of flow fluctuations on relative pressure. νWERP-t is tested on a set of in-vitro stenotic flow phantoms with data acquired by 4D flow MRI with six-directional flow encoding, as well as on a patient-specific in-silico model of an acute aortic dissection. Over all tests νWERP-t shows improved accuracy over alternative energy-based approaches, with excellent recovery of estimated relative pressures. In particular, the use of a guaranteed divergence-free virtual field improves accuracy in cases where turbulent flows skew the apparent divergence of the acquired field. With the original νWERP allowing for assessment of relative pressure into previously inaccessible vasculatures, the extended νWERP-t further enlarges the method's clinical scope, underlining its potential as a novel tool for assessing relative pressure in-vivo. © 2019","4D flow MRI; Fluid mechanics; Relative pressure; Turbulence; Turbulent energy dissipation; Virtual work-energy","","Elsevier B.V.","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85076673140"
"Gressler L.E.; Cowley T.; Velezis M.; Aryal S.; Clare D.; Kusiak J.W.; Cowley A.W.; Sedrakyan A.; Marinac-Dabic D.; Reardon M.; Schmidt L.; Feldman J.G.; DiFabio V.; Bergman S.; Simonyan V.; Yesha Y.; Vasiliu-Feltes I.; Durham J.; Steen A.I.; Woods P.; Kapos F.P.; Loyo-Berrios N.","Gressler, Laura Elisabeth (57200511566); Cowley, Terrie (35739883400); Velezis, Marti (6508214439); Aryal, Suvekshya (57257383000); Clare, Deanne (58117868200); Kusiak, John W. (57191752886); Cowley, Allen W. (57210527176); Sedrakyan, Art (55207402200); Marinac-Dabic, Danica (7801383756); Reardon, Michelle (58117868100); Schmidt, Lisa (58161097000); Feldman, Jennifer Ginsburg (58161418000); DiFabio, Vincent (6508034181); Bergman, Suzie (58161417900); Simonyan, Vahan (36800983600); Yesha, Yelena (7004127331); Vasiliu-Feltes, Ingrid (57795355600); Durham, Justin (57208414078); Steen, Andrew I. (57927524100); Woods, Phillip (57927843700); Kapos, Flavia P. (57189636897); Loyo-Berrios, Nilsa (6504809029)","57200511566; 35739883400; 6508214439; 57257383000; 58117868200; 57191752886; 57210527176; 55207402200; 7801383756; 58117868100; 58161097000; 58161418000; 6508034181; 58161417900; 36800983600; 7004127331; 57795355600; 57208414078; 57927524100; 57927843700; 57189636897; 6504809029","Building the foundation for a modern patient-partnered infrastructure to study temporomandibular disorders","2023","Frontiers in Digital Health","5","","1132446","","","","0","10.3389/fdgth.2023.1132446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161039717&doi=10.3389%2ffdgth.2023.1132446&partnerID=40&md5=32ef535a71bcc7842e642cd21195bbe4","Center for Devices and Radiological Health (CDRH), Food and Drug Administration, Silver Spring, MD, United States; Division of Pharmaceutical Evaluation and Policy, University of Arkansas for Medical Sciences, Little Rock, AR, United States; TMJ Association Milwaukee, WI, United States; Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, United States; Department of Physiology, Medical College of Wisconsin, Madison, WI, United States; Oral and Maxillofacial Surgery, University of Maryland Medical System, Baltimore, MD, United States; Dentistry on Officers Row, Vancouver, WA, United States; Embleema, Washington, DC, United States; Department of Computer Science, University of Miami, Miami, FL, United States; SofThread, Miami, FL, United States; School of Dental Sciences, Newcastle, United Kingdom; Newcastle-Upon Tyne Hospitals’ NHS Foundation Trust, Newcastle, United Kingdom; Center for Child Health, Behavior and Development, Seattle Children’s Research Institute, Seattle, WA, United States","Gressler L.E., Center for Devices and Radiological Health (CDRH), Food and Drug Administration, Silver Spring, MD, United States, Division of Pharmaceutical Evaluation and Policy, University of Arkansas for Medical Sciences, Little Rock, AR, United States; Cowley T., TMJ Association Milwaukee, WI, United States; Velezis M., Center for Devices and Radiological Health (CDRH), Food and Drug Administration, Silver Spring, MD, United States; Aryal S., Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, United States; Clare D., TMJ Association Milwaukee, WI, United States; Kusiak J.W., TMJ Association Milwaukee, WI, United States; Cowley A.W., Department of Physiology, Medical College of Wisconsin, Madison, WI, United States; Sedrakyan A., Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, United States; Marinac-Dabic D., Center for Devices and Radiological Health (CDRH), Food and Drug Administration, Silver Spring, MD, United States; Reardon M., TMJ Association Milwaukee, WI, United States; Schmidt L., TMJ Association Milwaukee, WI, United States; Feldman J.G., TMJ Association Milwaukee, WI, United States; DiFabio V., Oral and Maxillofacial Surgery, University of Maryland Medical System, Baltimore, MD, United States; Bergman S., Dentistry on Officers Row, Vancouver, WA, United States; Simonyan V., Embleema, Washington, DC, United States; Yesha Y., Department of Computer Science, University of Miami, Miami, FL, United States; Vasiliu-Feltes I., SofThread, Miami, FL, United States; Durham J., School of Dental Sciences, Newcastle, United Kingdom, Newcastle-Upon Tyne Hospitals’ NHS Foundation Trust, Newcastle, United Kingdom; Steen A.I., Center for Devices and Radiological Health (CDRH), Food and Drug Administration, Silver Spring, MD, United States; Woods P., Center for Devices and Radiological Health (CDRH), Food and Drug Administration, Silver Spring, MD, United States; Kapos F.P., Center for Child Health, Behavior and Development, Seattle Children’s Research Institute, Seattle, WA, United States; Loyo-Berrios N., Center for Devices and Radiological Health (CDRH), Food and Drug Administration, Silver Spring, MD, United States","Background: Conflicting reports from varying stakeholders related to prognosis and outcomes following placement of temporomandibular joint (TMJ) implants gave rise to the development of the TMJ Patient-Led RoundTable initiative. Following an assessment of the current availability of data, the RoundTable concluded that a strategically Coordinated Registry Network (CRN) is needed to collect and generate accessible data on temporomandibular disorder (TMD) and its care. The aim of this study was therefore to advance the clinical understanding, usage, and adoption of a core minimum dataset for TMD patients as the first foundational step toward building the CRN. Methods: Candidate data elements were extracted from existing data sources and included in a Delphi survey administered to 92 participants. Data elements receiving less than 75% consensus were dropped. A purposive multi-stakeholder sub-group triangulated the items across patient and clinician-based experience to remove redundancies or duplicate items and reduce the response burden for both patients and clinicians. To reliably collect the identified data elements, the identified core minimum data elements were defined in the context of technical implementation within High-performance Integrated Virtual Environment (HIVE) web-application framework. HIVE was integrated with CHIOS™, an innovative permissioned blockchain platform, to strengthen the provenance of data captured in the registry and drive metadata to record all registry transaction and create a robust consent network. Results: A total of 59 multi-stakeholder participants responded to the Delphi survey. The completion of the Delphi surveys followed by the application of the required group consensus threshold resulted in the selection of 397 data elements (254 for patient-generated data elements and 143 for clinician generated data elements). The infrastructure development and integration of HIVE and CHIOS™ was completed showing the maintenance of all data transaction information in blockchain, flexible recording of patient consent, data cataloging, and consent validation through smart contracts. Conclusion: The identified data elements and development of the technological platform establishes a data infrastructure that facilitates the standardization and harmonization of data as well as perform high performance analytics needed to fully leverage the captured patient-generated data, clinical evidence, and other healthcare ecosystem data within the TMJ/TMD-CRN. 2023 Gressler, Cowley, Velezis, Aryal, Clare, Kusiak, Cowley, Sedrakyan, Marinac-Dabic, Reardon, Schmidt, Feldman, Difabio, Bergman, Simonyan, Yesha, Vasiliu-Feltes, Durham, Steen, Woods, Kapos and Loyo-Berrios.","coordinated registry network; data infrastructure and integration; delphi; temporomandibular joint; temporomandibular joint disc; temporomandibular joint disorders; temporomandibular joint dysfunction syndrome","","Frontiers Media S.A.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85161039717"
"Veljanoski D.; Ng X.Y.; Hill C.S.; Jamjoom A.A.B.","Veljanoski, Damjan (57195528872); Ng, Xin Yi (59136756200); Hill, Ciaran Scott (16746373000); Jamjoom, Aimun A B (24474922900)","57195528872; 59136756200; 16746373000; 24474922900","Theory and evidence-base for a digital platform for the delivery of language tests during awake craniotomy and collaborative brain mapping","2024","BMJ Surgery, Interventions, and Health Technologies","6","1","e000234","","","","0","10.1136/bmjsit-2023-000234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193722264&doi=10.1136%2fbmjsit-2023-000234&partnerID=40&md5=778bb1e124e08cb1c85720fe74eea3dc","Southwest Neurosurgery Centre, Derriford Hospital, Plymouth, United Kingdom; Department of Medicine, Arrowe Park Hospital, Wirral, United Kingdom; Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, London, United Kingdom; Centre for Clinical Brain Sciences, The University of Edinburgh, Edinburgh, United Kingdom; Department of Neurosurgery, Barking Havering and Redbridge Hospitals Nhs Trust, Romford, United Kingdom","Veljanoski D., Southwest Neurosurgery Centre, Derriford Hospital, Plymouth, United Kingdom; Ng X.Y., Department of Medicine, Arrowe Park Hospital, Wirral, United Kingdom; Hill C.S., Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, London, United Kingdom; Jamjoom A.A.B., Centre for Clinical Brain Sciences, The University of Edinburgh, Edinburgh, United Kingdom, Department of Neurosurgery, Barking Havering and Redbridge Hospitals Nhs Trust, Romford, United Kingdom","Objectives Build the theoretical and evidence-base for a digital platform (map-OR) which delivers intraoperative language tests during awake craniotomy and facilitates collaborative sharing of brain mapping data. Design Mixed methodology study including two scoping reviews, international survey, synthesis of development guiding principles and a risk assessment using failure modes and effects analysis. Setting The two scoping reviews examined the literature published in the English language. International survey was completed by members of awake craniotomy teams from 14 countries. Main outcome measures Scoping review 1: number of technologies described for language mapping during awake craniotomy. Scoping review 2: barriers and facilitators to adopting novel technology in surgery. International survey: degree of language mapping technology penetration into clinical practice. Results A total of 12 research articles describing 6 technologies were included. The technologies required a range of hardware components including portable devices, virtual reality headsets and large integrated multiscreen stacks. The facilitators and barriers of technology adoption in surgery were extracted from 11 studies and mapped onto the 4 Unified Theory of Acceptance and Use of Technology constructs. A total of 37 awake craniotomy teams from 14 countries completed the survey. Of the responses, 20 (54.1%) delivered their language tests digitally, 10 (27.0%) delivered tests using cards and 7 (18.9%) used a combination of both. The most commonly used devices were tablet computers (67.7%; n=21) and the most common software used was Microsoft PowerPoint (60.6%; n=20). Four key risks for the proposed digital platform were identified, the highest risk being a software and internet connectivity failure during surgery. Conclusions This work represents a rigorous and structured approach to the development of a digital platform for standardized intraoperative language testing during awake craniotomy and for collaborative sharing of brain mapping data. Trial registration number Scoping review protocol registrations in OSF registries (scoping review 1: osf.io/su9xm; scoping review 2: osf.io/x4wsc).  © 2024 Seminars in Plastic Surgery","health technology; neurological devices; technology","","BMJ Publishing Group","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85193722264"
"Chatterjee K.; Buchanan A.; Cottrell K.; Hughes S.; Day T.W.; John N.W.","Chatterjee, Kausik (57209860813); Buchanan, Alastair (57211515734); Cottrell, Katy (57209712479); Hughes, Sara (57487750600); Day, Thomas W. (57189069511); John, Nigel W. (7005876140)","57209860813; 57211515734; 57209712479; 57487750600; 57189069511; 7005876140","Immersive Virtual Reality for the Cognitive Rehabilitation of Stroke Survivors","2022","IEEE Transactions on Neural Systems and Rehabilitation Engineering","30","","","719","728","9","23","10.1109/TNSRE.2022.3158731","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126277600&doi=10.1109%2fTNSRE.2022.3158731&partnerID=40&md5=f712e7ddedb42558215bbf82cce51302","Countess of Chester Hospital NHS Foundation Trust, Chester, CH2 1UL, United Kingdom; Cadscan Ltd., Chester, CH2 3AD, United Kingdom; Department of Computer Science, University of Chester, Chester, CH1 4BJ, United Kingdom","Chatterjee K., Countess of Chester Hospital NHS Foundation Trust, Chester, CH2 1UL, United Kingdom; Buchanan A., Cadscan Ltd., Chester, CH2 3AD, United Kingdom; Cottrell K., Countess of Chester Hospital NHS Foundation Trust, Chester, CH2 1UL, United Kingdom; Hughes S., Countess of Chester Hospital NHS Foundation Trust, Chester, CH2 1UL, United Kingdom; Day T.W., Department of Computer Science, University of Chester, Chester, CH1 4BJ, United Kingdom; John N.W., Department of Computer Science, University of Chester, Chester, CH1 4BJ, United Kingdom","We present the results of a double-blind phase 2b randomized control trial that used a custom built virtual reality environment for the cognitive rehabilitation of stroke survivors. A stroke causes damage to the brain and problem solving, memory and task sequencing are commonly affected. The brain can recover to some extent, however, and stroke patients have to relearn how to carry out activities of daily living. We have created an application called VIRTUE to enable such activities to be practiced using immersive virtual reality. Gamification techniques enhance the motivation of patients such as by making the level of difficulty of a task increase over time. The design and implementation of VIRTUE is described together with the results of the trial conducted within the Stroke Unit of a large hospital. We report on the safety and acceptability of VIRTUE. We have also observed particular benefits of VR treatment for stroke survivors that experienced more severe cognitive impairment, and an encouraging reduction in time spent in the hospital for all patients that received the VR treatment.  © 2001-2011 IEEE.","cognitive rehabilitation; stroke recovery; Virtual reality","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126277600"
"Sreenithya K.H.; Jade D.; Harrison M.A.; Sugumar S.","Sreenithya, K.H. (57851694200); Jade, Dhananjay (57201033746); Harrison, Michael A. (7401595128); Sugumar, Shobana (57760131900)","57851694200; 57201033746; 7401595128; 57760131900","Identification of natural inhibitor against L1 β-lactamase present in Stenotrophomonas maltophilia","2022","Journal of Molecular Modeling","28","11","342","","","","3","10.1007/s00894-022-05336-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139359212&doi=10.1007%2fs00894-022-05336-z&partnerID=40&md5=b98fc0ed507d897aff2bf1ded5600a58","Department of Genetic Engineering, School of Bioengineering, College of Engineering and Technology, SRM Institute of Science and Technology, Kattankulathur, India; School of Biomedical Sciences, University of Leeds, Leeds, LS2 9JT, United Kingdom","Sreenithya K.H., Department of Genetic Engineering, School of Bioengineering, College of Engineering and Technology, SRM Institute of Science and Technology, Kattankulathur, India; Jade D., School of Biomedical Sciences, University of Leeds, Leeds, LS2 9JT, United Kingdom; Harrison M.A., School of Biomedical Sciences, University of Leeds, Leeds, LS2 9JT, United Kingdom; Sugumar S., Department of Genetic Engineering, School of Bioengineering, College of Engineering and Technology, SRM Institute of Science and Technology, Kattankulathur, India","Antibiotic resistance is threatening the medical industry in treating microbial infections. Many organisms are acquiring antibiotic resistance because of the continuous use of the same drug. Gram-negative organisms are developing multi-drug resistance properties (MDR) due to chromosomal level changes that occurred as a part of evolution or some intrinsic factors already present in the organism. Stenotrophomonas maltophilia falls under the category of multidrug-resistant organism. WHO has also urged to evaluate the scenario and develop new strategies for making this organism susceptible to otherwise resistant antibiotics. Using novel compounds as drugs can ameliorate the issue to some extent. The β-lactamase enzyme in the bacteria is responsible for inhibiting several drugs currently being used for treatment. This enzyme can be targeted to find an inhibitor that can inhibit the enzyme activity and make the organism susceptible to β-lactam antibiotics. Plants produce several secondary metabolites for their survival in adverse environments. Several phytoconstituents have antimicrobial properties and have been used in traditional medicine for a long time. The computational technologies can be exploited to find the best compound from many compounds. Virtual screening, molecular docking, and dynamic simulation methods are followed to get the best inhibitor for L1 β-lactamase. IMPPAT database is screened, and the top hit compounds are studied for ADMET properties. Finally, four compounds are selected to set for molecular dynamics simulation. After all the computational calculations, withanolide R is found to have a better binding and forms a stable complex with the protein. This compound can act as a potent natural inhibitor for L1 β-lactamase. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Docking; L1 β-lactamase; Molecular dynamics; Virtual screening","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85139359212"
"Xing Y.; Liang Z.; Fahy C.; Shell J.; Guan K.; Liu Y.; Zhang Q.","Xing, Yongkang (57226394771); Liang, Zhanti (57226402487); Fahy, Conor (57191279549); Shell, Jethro (36678303400); Guan, Kexin (57226396004); Liu, Yuxi (57343155800); Zhang, Qian (57226397587)","57226394771; 57226402487; 57191279549; 36678303400; 57226396004; 57343155800; 57226397587","Virtual reality research: Design virtual education system for epidemic (covid-19) knowledge to public","2021","Applied Sciences (Switzerland)","11","22","10586","","","","7","10.3390/app112210586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119280003&doi=10.3390%2fapp112210586&partnerID=40&md5=9fceb606815533f6f47553b1778f0403","Center of Experimental Teaching, Guangdong University of Finance, Guangzhou, 510521, China; Department of Art Design & Creative Industry, Nanfang College, Guangzhou, 510970, China; Institute of Artificial Intelligence, De Montfort University, Leicester, LE1 9BH, United Kingdom; Canway Technology Consult Co., Ltd, Guangzhou, 510630, China; School of Internet finance and information engineering, Guangdong University of Finance, Guangzhou, 510521, China","Xing Y., Center of Experimental Teaching, Guangdong University of Finance, Guangzhou, 510521, China; Liang Z., Department of Art Design & Creative Industry, Nanfang College, Guangzhou, 510970, China; Fahy C., Institute of Artificial Intelligence, De Montfort University, Leicester, LE1 9BH, United Kingdom; Shell J., Institute of Artificial Intelligence, De Montfort University, Leicester, LE1 9BH, United Kingdom; Guan K., Canway Technology Consult Co., Ltd, Guangzhou, 510630, China; Liu Y., School of Internet finance and information engineering, Guangdong University of Finance, Guangzhou, 510521, China; Zhang Q., Department of Art Design & Creative Industry, Nanfang College, Guangzhou, 510970, China","Advances in information and communication technologies have created a range of new products and services for the well-being of society. Virtual Reality (VR) technology has shown enormous potential in educational, commercial, and medical fields. The recent COVID-19 outbreak highlights a poor global performance in communicating epidemic knowledge to the public. Considering the potential of VR, the research starts from analyzing how to use VR technology to improve public education in COVID-19. The research uses Virtual Storytelling Technology (VST) to promote enthusiasm in user participation. A Plot-based VR education system is proposed in order to provide an immersive, explorative, educational experiences. The system includes three primary modules: the Tutorial Module, the Preparation Module, and the Investigation Module. To remove any potential confusion in the user, the research aims to avoid extremely complicated medical professional content and uses interactive, entertainment methods to improve user participation. In order to evaluate the performance efficiency of the system, we conducted performance evaluations and a user study with 80 participants. Compared with traditional education, the experimental results show that the VR education system can used as an effective educational tool for epidemic (COVID-19) fundamental knowledge. The VR technology can assist government agencies and public organizations to increase public understanding of the spread the epidemic (COVID-19). © 2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/).","COVID-19; Education; Interactive design; Storyline; User interface; Virtual reality; Virtual Storytelling Technology (VST)","","MDPI","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85119280003"
"Armiger R.; Reddy M.; Oliver N.S.; Georgiou P.; Herrero P.","Armiger, Ryan (57370195100); Reddy, Monika (57196350191); Oliver, Nick S. (8414954000); Georgiou, Pantelis (16301582200); Herrero, Pau (8693403100)","57370195100; 57196350191; 8414954000; 16301582200; 8693403100","An In Silico Head-to-Head Comparison of the Do-It-Yourself Artificial Pancreas Loop and Bio-Inspired Artificial Pancreas Control Algorithms","2022","Journal of Diabetes Science and Technology","16","1","","29","39","10","3","10.1177/19322968211060074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120953406&doi=10.1177%2f19322968211060074&partnerID=40&md5=9a6e1df3e1493d5a6b85048a54bedb10","Centre for Bio-Inspired Technology, Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom; Division of Diabetes, Endocrinology & Metabolism, Department of Medicine, Faculty of Medicine, Imperial College London, London, United Kingdom","Armiger R., Centre for Bio-Inspired Technology, Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom; Reddy M., Division of Diabetes, Endocrinology & Metabolism, Department of Medicine, Faculty of Medicine, Imperial College London, London, United Kingdom; Oliver N.S., Division of Diabetes, Endocrinology & Metabolism, Department of Medicine, Faculty of Medicine, Imperial College London, London, United Kingdom; Georgiou P., Centre for Bio-Inspired Technology, Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom; Herrero P., Centre for Bio-Inspired Technology, Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom","Background: User-developed automated insulin delivery systems, also referred to as do-it-yourself artificial pancreas systems (DIY APS), are in use by people living with type 1 diabetes. In this work, we evaluate, in silico, the DIY APS Loop control algorithm and compare it head-to-head with the bio-inspired artificial pancreas (BiAP) controller for which clinical data are available. Methods: The Python version of the Loop control algorithm called PyLoopKit was employed for evaluation purposes. A Python-MATLAB interface was created to integrate PyLoopKit with the UVa-Padova simulator. Two configurations of BiAP (non-adaptive and adaptive) were evaluated. In addition, the Tandem Basal-IQ predictive low-glucose suspend was used as a baseline algorithm. Two scenarios with different levels of variability were used to challenge the algorithms on the adult (n = 10) and adolescent (n = 10) virtual cohorts of the simulator. Results: Both BiAP and Loop improve, or maintain, glycemic control when compared with Basal-IQ. Under the scenario with lower variability, BiAP and Loop perform relatively similarly. However, BiAP, and in particular its adaptive configuration, outperformed Loop in the scenario with higher variability by increasing the percentage time in glucose target range 70-180 mg/dL (BiAP-Adaptive vs Loop vs Basal-IQ) (adults: 89.9% ± 3.2%* vs 79.5% ± 5.3%* vs 67.9% ± 8.3%; adolescents: 74.6 ± 9.5%* vs 53.0% ± 7.7% vs 55.4% ± 12.0%, where * indicates the significance of P <.05 calculated in sequential order) while maintaining the percentage time below range (adults: 0.89% ± 0.37% vs 1.72% ± 1.26% vs 3.41 ± 1.92%; adolescents: 2.87% ± 2.77% vs 4.90% ± 1.92% vs 4.17% ± 2.74%). Conclusions: Both Loop and BiAP algorithms are safe and improve glycemic control when compared, in silico, with Basal-IQ. However, BiAP appears significantly more robust to real-world challenges by outperforming Loop and Basal-IQ in the more challenging scenario. © 2021 Diabetes Technology Society.","artificial pancreas; automatic insulin delivery; bio-inspired technology; do-it-yourself; in silico trials; type 1 diabetes","","SAGE Publications Inc.","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85120953406"
"Currie J.; Bond R.R.; McCullagh P.; Black P.; Finlay D.D.; Gallagher S.; Kearney P.; Peace A.; Stoyanov D.; Bicknell C.D.; Leslie S.; Gallagher A.G.","Currie, Jonathan (57188878557); Bond, Raymond R. (36019802200); McCullagh, Paul (35566862700); Black, Pauline (8308703200); Finlay, Dewar D. (8977626000); Gallagher, Stephen (7103270356); Kearney, Peter (36004465400); Peace, Aaron (25655320100); Stoyanov, Danail (57203105770); Bicknell, Colin D. (6701649965); Leslie, Stephen (57202677736); Gallagher, Anthony G. (7101915089)","57188878557; 36019802200; 35566862700; 8308703200; 8977626000; 7103270356; 36004465400; 25655320100; 57203105770; 6701649965; 57202677736; 7101915089","Wearable technology-based metrics for predicting operator performance during cardiac catheterisation","2019","International Journal of Computer Assisted Radiology and Surgery","14","4","","645","657","12","7","10.1007/s11548-019-01918-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061330038&doi=10.1007%2fs11548-019-01918-0&partnerID=40&md5=e1a8a1515a7483310887157aefb2ee11","School of Computing, Jordanstown Campus, Ulster University, Shore Road, Newtownabbey, BT37 0QB, United Kingdom; School of Nursing, Magee Campus, Ulster University, Londonderry, BT48 7JL, United Kingdom; School of Engineering, Jordanstown Campus, Ulster University, Londonderry, BT48 7JL, United Kingdom; School of Psychology, Coleraine Campus, Ulster University, Cromore Road, Coleraine, BT52 1SA, United Kingdom; Application of Science to Simulation Based Education and Research on Training (ASSERT) Centre, University College Cork, Cork, Ireland; Clinical Translational Research and Innovation Centre (C-TRIC), Londonderry, United Kingdom; University College London, London, United Kingdom; Imperial College London, London, United Kingdom; NHS Highland, NHS Scotland, Edinburgh, United Kingdom","Currie J., School of Computing, Jordanstown Campus, Ulster University, Shore Road, Newtownabbey, BT37 0QB, United Kingdom; Bond R.R., School of Computing, Jordanstown Campus, Ulster University, Shore Road, Newtownabbey, BT37 0QB, United Kingdom; McCullagh P., School of Computing, Jordanstown Campus, Ulster University, Shore Road, Newtownabbey, BT37 0QB, United Kingdom; Black P., School of Nursing, Magee Campus, Ulster University, Londonderry, BT48 7JL, United Kingdom; Finlay D.D., School of Engineering, Jordanstown Campus, Ulster University, Londonderry, BT48 7JL, United Kingdom; Gallagher S., School of Psychology, Coleraine Campus, Ulster University, Cromore Road, Coleraine, BT52 1SA, United Kingdom; Kearney P., Application of Science to Simulation Based Education and Research on Training (ASSERT) Centre, University College Cork, Cork, Ireland; Peace A., Clinical Translational Research and Innovation Centre (C-TRIC), Londonderry, United Kingdom; Stoyanov D., University College London, London, United Kingdom; Bicknell C.D., Imperial College London, London, United Kingdom; Leslie S., NHS Highland, NHS Scotland, Edinburgh, United Kingdom; Gallagher A.G., Application of Science to Simulation Based Education and Research on Training (ASSERT) Centre, University College Cork, Cork, Ireland","Introduction: Unobtrusive metrics that can auto-assess performance during clinical procedures are of value. Three approaches to deriving wearable technology-based metrics are explored: (1) eye tracking, (2) psychophysiological measurements [e.g. electrodermal activity (EDA)] and (3) arm and hand movement via accelerometry. We also measure attentional capacity by tasking the operator with an additional task to track an unrelated object during the procedure. Methods: Two aspects of performance are measured: (1) using eye gaze and psychophysiology metrics and (2) measuring attentional capacity via an additional unrelated task (to monitor a visual stimulus/playing cards). The aim was to identify metrics that can be used to automatically discriminate between levels of performance or at least between novices and experts. The study was conducted using two groups: (1) novice operators and (2) expert operators. Both groups made two attempts at a coronary angiography procedure using a full-physics virtual reality simulator. Participants wore eye tracking glasses and an E4 wearable wristband. Areas of interest were defined to track visual attention on display screens, including: (1) X-ray, (2) vital signs, (3) instruments and (4) the stimulus screen (for measuring attentional capacity). Results: Experts provided greater dwell time (63% vs 42%, p = 0.03) and fixations (50% vs 34%, p = 0.04) on display screens. They also provided greater dwell time (11% vs 5%, p = 0.006) and fixations (9% vs 4%, p = 0.007) when selecting instruments. The experts’ performance for tracking the unrelated object during the visual stimulus task negatively correlated with total errors (r = − 0.95, p = 0.0009). Experts also had a higher standard deviation of EDA (2.52 µS vs 0.89 µS, p = 0.04). Conclusions: Eye tracking metrics may help discriminate between a novice and expert operator, by showing that experts maintain greater visual attention on the display screens. In addition, the visual stimulus study shows that an unrelated task can measure attentional capacity. Trial registration This work is registered through clinicaltrials.gov, a service of the U.S. National Health Institute, and is identified by the trial reference: NCT02928796. © 2019, The Author(s).","Attentional capacity; Eye tracking; Simulation-based training; Surgical simulation; Wearable technology","","Springer Verlag","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85061330038"
"Matthews T.; Tian F.; Dolby T.","Matthews, Tj (57275028000); Tian, Feng (56895556000); Dolby, Tom (57218483487)","57275028000; 56895556000; 57218483487","Interaction design for paediatric emergency VR training","2020","Virtual Reality and Intelligent Hardware","2","4","","330","344","14","9","10.1016/j.vrih.2020.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115851597&doi=10.1016%2fj.vrih.2020.07.006&partnerID=40&md5=bfcd20bc82751624123cf1017860da83","Centre for Digital Entertainment, Bournemouth University, United Kingdom; Faculty of Science & Technology, Bournemouth University, United Kingdom; Head of Simulations, AiSolve, United Kingdom","Matthews T., Centre for Digital Entertainment, Bournemouth University, United Kingdom; Tian F., Faculty of Science & Technology, Bournemouth University, United Kingdom; Dolby T., Head of Simulations, AiSolve, United Kingdom","Background: Virtual reality (VR) in healthcare training has increased adoption and support, but efforts are still required to mitigate usability concerns. Methods: This study conducted a usability study of an in-use emergency medicine VR training application, available on commercially available VR hardware and with a standard interaction design. Nine users without prior VR experience but with relevant medical expertise completed two simulation scenarios for a total of 18 recorded sessions. They completed NASA Task Load Index and System Usability Scale questionnaires after each session, and their performance was recorded for the tracking of user errors. Results and Conclusion: s Our results showed a medium (and potentially optimal) Workload and an above average System Usability Score. There was significant improvement in several factors between users' first and second sessions, notably increased Performance evaluation. User errors with the strongest correlation to usability were not directly tied to interaction design, however, but to a limited 'possibility space'. Suggestions for closing this 'gulf of execution' were presented, including 'voice control' and 'hand-tracking', which are only feasible for this commercial product now with the availability of the Oculus Quest headset. Moreover, wider implications for VR medical training were outlined, and potential next steps towards a standardized design identified. © 2019 Beijing Zhongke Journal Publishing Co. Ltd","Human-Centred design; Interaction design; Medical training; Virtual reality","","KeAi Communications Co.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85115851597"
"Sarraju A.; Seninger C.; Parameswaran V.; Petlura C.; Bazouzi T.; Josan K.; Grewal U.; Viethen T.; Mundl H.; Luithle J.; Basobas L.; Touros A.; Senior M.J.T.; De Lombaert K.; Mahaffey K.W.; Turakhia M.P.; Dash R.","Sarraju, Ashish (55489162000); Seninger, Clark (57768445100); Parameswaran, Vijaya (57265908100); Petlura, Christina (55905027300); Bazouzi, Tamara (57768205000); Josan, Kiranbir (22985081300); Grewal, Upinder (57768445200); Viethen, Thomas (54685363100); Mundl, Hardi (6504569255); Luithle, Joachim (57767961400); Basobas, Leonard (57718412800); Touros, Alexis (57196030538); Senior, Michael J. T. (57348699800); De Lombaert, Koen (57768445300); Mahaffey, Kenneth W. (57203051418); Turakhia, Mintu P. (57203051265); Dash, Rajesh (35591426500)","55489162000; 57768445100; 57265908100; 55905027300; 57768205000; 22985081300; 57768445200; 54685363100; 6504569255; 57767961400; 57718412800; 57196030538; 57348699800; 57768445300; 57203051418; 57203051265; 35591426500","Pandemic-proof recruitment and engagement in a fully decentralized trial in atrial fibrillation patients (DeTAP)","2022","npj Digital Medicine","5","1","80","","","","9","10.1038/s41746-022-00622-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132979339&doi=10.1038%2fs41746-022-00622-9&partnerID=40&md5=df6099c090e29e0714db0326f650149d","Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States; Center for Digital Health, Stanford University School of Medicine, Palo Alto, CA, United States; Stanford Center for Clinical Research (SCCR), Palo Alto, CA, United States; Bayer AG, Wuppertal, Germany; Huma Therapeutics Ltd, London, United Kingdom; Yuzu Labs PBC, San Jose, CA, United States; VA Palo Alto Health Care System, Palo Alto, CA, United States","Sarraju A., Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States, Center for Digital Health, Stanford University School of Medicine, Palo Alto, CA, United States; Seninger C., Center for Digital Health, Stanford University School of Medicine, Palo Alto, CA, United States; Parameswaran V., Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States; Petlura C., Stanford Center for Clinical Research (SCCR), Palo Alto, CA, United States; Bazouzi T., Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States; Josan K., Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States; Grewal U., Bayer AG, Wuppertal, Germany; Viethen T., Bayer AG, Wuppertal, Germany; Mundl H., Bayer AG, Wuppertal, Germany; Luithle J., Bayer AG, Wuppertal, Germany; Basobas L., Stanford Center for Clinical Research (SCCR), Palo Alto, CA, United States; Touros A., Stanford Center for Clinical Research (SCCR), Palo Alto, CA, United States; Senior M.J.T., Huma Therapeutics Ltd, London, United Kingdom; De Lombaert K., Yuzu Labs PBC, San Jose, CA, United States; Mahaffey K.W., Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States, Stanford Center for Clinical Research (SCCR), Palo Alto, CA, United States; Turakhia M.P., Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States, Center for Digital Health, Stanford University School of Medicine, Palo Alto, CA, United States, VA Palo Alto Health Care System, Palo Alto, CA, United States; Dash R., Division of Cardiovascular Medicine & Cardiovascular Institute, Stanford University School of Medicine, Palo Alto, CA, United States","The Coronavirus Disease 2019 (COVID-19) pandemic curtailed clinical trial activity. Decentralized clinical trials (DCTs) can expand trial access and reduce exposure risk but their feasibility remains uncertain. We evaluated DCT feasibility for atrial fibrillation (AF) patients on oral anticoagulation (OAC). DeTAP (Decentralized Trial in Afib Patients, NCT04471623) was a 6-month, single-arm, 100% virtual study of 100 AF patients on OAC aged >55 years, recruited traditionally and through social media. Participants enrolled and participated virtually using a mobile application and remote blood pressure (BP) and six-lead electrocardiogram (ECG) sensors. Four engagement-based primary endpoints included changes in pre- versus end-of-study OAC adherence (OACA), and % completion of televisits, surveys, and ECG and BP measurements. Secondary endpoints included survey-based nuisance bleeding and patient feedback. 100 subjects (mean age 70 years, 44% women, 90% White) were recruited in 28 days (traditional: 6 pts; social media: 94 pts in 12 days with >300 waitlisted). Study engagement was high: 91% televisits, 85% surveys, and 99% ECG and 99% BP measurement completion. OACA was unchanged at 6 months (baseline: 97 ± 9%, 6 months: 96 ± 15%, p = 0.39). In patients with low baseline OACA (<90%), there was significant 6-month improvement (85 ± 16% to 96 ± 6%, p < 0.01). 86% of respondents (69/80) expressed willingness to continue in a longer trial. The DeTAP study demonstrated rapid recruitment, high engagement, and physiologic reporting via the integration of digital technologies and dedicated study coordination. These findings may inform DCT designs for future cardiovascular trials. © 2022, The Author(s).","","","Nature Research","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85132979339"
"Molnar A.; Weerakkody V.","Molnar, Andreea (34771810700); Weerakkody, Vishanth (16029961500)","34771810700; 16029961500","Clinicians' view of tele-glaucoma","2016","Health Policy and Technology","5","2","","123","130","7","3","10.1016/j.hlpt.2016.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959422411&doi=10.1016%2fj.hlpt.2016.02.001&partnerID=40&md5=9b2ff0dbcce9d574b454af43f374db07","University of Portsmouth, United Kingdom; Brunel University, United Kingdom","Molnar A., University of Portsmouth, United Kingdom; Weerakkody V., Brunel University, United Kingdom","Although recent advancements in technology have led to major transformations in healthcare services, the use of tele-monitoring in patient care is yet an emerging occurrence. This study examines factors that affect the adoption of video based remote treatment of senior patients in a tele-glaucoma project in a large hospital in Greece. Several themes emerge from the study encapsulating technical, usability, process, institutional, ethics and privacy, clinicians' behaviour and patients' demography related factors. The findings of the study showed that while the benefits of tele-monitoring service adoption were of foremost importance for doctors, usability and connectivity for enabling remote services was critical for its success. © 2016.","Europe; Eye; Glaucoma; Tele-glaucoma; Tele-monitoring","","Elsevier B.V.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84959422411"
"Dimitrakakis E.; Aylmore H.; Lindenroth L.; Dwyer G.; Carmichael J.; Khan D.Z.; Dorward N.L.; Marcus H.J.; Stoyanov D.","Dimitrakakis, Emmanouil (57202293545); Aylmore, Holly (57223913749); Lindenroth, Lukas (56741222700); Dwyer, George (56742945400); Carmichael, Joshua (57480170600); Khan, Danyal Z. (57188871574); Dorward, Neil L. (6701868395); Marcus, Hani J. (16643089500); Stoyanov, Danail (57203105770)","57202293545; 57223913749; 56741222700; 56742945400; 57480170600; 57188871574; 6701868395; 16643089500; 57203105770","Robotic Handle Prototypes for Endoscopic Endonasal Skull Base Surgery: Pre-clinical Randomised Controlled Trial of Performance and Ergonomics","2022","Annals of Biomedical Engineering","50","5","","549","563","14","10","10.1007/s10439-022-02942-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125919951&doi=10.1007%2fs10439-022-02942-z&partnerID=40&md5=12c6a20acf64660e0292f152dd0fb331","Wellcome/EPSRC Centre for Surgical and Interventional Sciences (WEISS), University College London (UCL), Charles Bell House, 43-45 Foley Street, London, W1W 7EJ, United Kingdom; Queen Square Institute of Neurology, University College London (UCL), London, United Kingdom; National Hospital for Neurology and Neurosurgery, London, United Kingdom","Dimitrakakis E., Wellcome/EPSRC Centre for Surgical and Interventional Sciences (WEISS), University College London (UCL), Charles Bell House, 43-45 Foley Street, London, W1W 7EJ, United Kingdom; Aylmore H., Queen Square Institute of Neurology, University College London (UCL), London, United Kingdom; Lindenroth L., Wellcome/EPSRC Centre for Surgical and Interventional Sciences (WEISS), University College London (UCL), Charles Bell House, 43-45 Foley Street, London, W1W 7EJ, United Kingdom; Dwyer G., Wellcome/EPSRC Centre for Surgical and Interventional Sciences (WEISS), University College London (UCL), Charles Bell House, 43-45 Foley Street, London, W1W 7EJ, United Kingdom; Carmichael J., Queen Square Institute of Neurology, University College London (UCL), London, United Kingdom; Khan D.Z., Wellcome/EPSRC Centre for Surgical and Interventional Sciences (WEISS), University College London (UCL), Charles Bell House, 43-45 Foley Street, London, W1W 7EJ, United Kingdom, National Hospital for Neurology and Neurosurgery, London, United Kingdom; Dorward N.L., National Hospital for Neurology and Neurosurgery, London, United Kingdom; Marcus H.J., Wellcome/EPSRC Centre for Surgical and Interventional Sciences (WEISS), University College London (UCL), Charles Bell House, 43-45 Foley Street, London, W1W 7EJ, United Kingdom, National Hospital for Neurology and Neurosurgery, London, United Kingdom; Stoyanov D., Wellcome/EPSRC Centre for Surgical and Interventional Sciences (WEISS), University College London (UCL), Charles Bell House, 43-45 Foley Street, London, W1W 7EJ, United Kingdom","Endoscopic endonasal skull base surgery is a promising alternative to transcranial approaches. However, standard instruments lack articulation, and thus, could benefit from robotic technologies. The aim of this study was to develop an ergonomic handle for a handheld robotic instrument intended to enhance this procedure. Two different prototypes were developed based on ergonomic guidelines within the literature. The first is a forearm-mounted handle that maps the surgeon’s wrist degrees-of-freedom to that of the robotic end-effector; the second is a joystick-and-trigger handle with a rotating body that places the joystick to the position most comfortable for the surgeon. These handles were incorporated into a custom-designed surgical virtual simulator and were assessed for their performance and ergonomics when compared with a standard neurosurgical grasper. The virtual task was performed by nine novices with all three devices as part of a randomised crossover user-study. Their performance and ergonomics were evaluated both subjectively by themselves and objectively by a validated observational checklist. Both handles outperformed the standard instrument with the rotating joystick-body handle offering the most substantial improvement in terms of balance between performance and ergonomics. Thus, it is deemed the more suitable device to drive instrumentation for endoscopic endonasal skull base surgery. © 2022, The Author(s).","Endoscopic endonasal skull base surgery; Handheld robotics; Medical robotics; Robotic-assisted minimally invasive neurosurgery; Surgical ergonomics","","Springer","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85125919951"
"Hamilton D.; McKechnie J.; Edgerton E.; Wilson C.","Hamilton, D. (57225712380); McKechnie, J. (35573878700); Edgerton, E. (7004472122); Wilson, C. (56465278800)","57225712380; 35573878700; 7004472122; 56465278800","Immersive virtual reality as a pedagogical tool in education: a systematic literature review of quantitative learning outcomes and experimental design","2021","Journal of Computers in Education","8","1","","1","32","31","375","10.1007/s40692-020-00169-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087757106&doi=10.1007%2fs40692-020-00169-2&partnerID=40&md5=b4cd69b6ddd20761d52886c79f1ede8b","Division of Psychology, School of Education & Social Sciences, University of the West of Scotland, Paisley, United Kingdom","Hamilton D., Division of Psychology, School of Education & Social Sciences, University of the West of Scotland, Paisley, United Kingdom; McKechnie J., Division of Psychology, School of Education & Social Sciences, University of the West of Scotland, Paisley, United Kingdom; Edgerton E., Division of Psychology, School of Education & Social Sciences, University of the West of Scotland, Paisley, United Kingdom; Wilson C., Division of Psychology, School of Education & Social Sciences, University of the West of Scotland, Paisley, United Kingdom","The adoption of immersive virtual reality (I-VR) as a pedagogical method in education has challenged the conceptual definition of what constitutes a learning environment. High fidelity graphics and immersive content using head-mounted-displays (HMD) have allowed students to explore complex subjects in a way that traditional teaching methods cannot. Despite this, research focusing on learning outcomes, intervention characteristics, and assessment measures associated with I-VR use has been sparse. To explore this, the current systematic review examined experimental studies published since 2013, where quantitative learning outcomes using HMD based I-VR were compared with less immersive pedagogical methods such as desktop computers and slideshows. A literature search yielded 29 publications that were deemed suitable for inclusion. Included papers were quality assessed using the Medical Education Research Study Quality Instrument (MERSQI). Most studies found a significant advantage of utilising I-VR in education, whilst a smaller number found no significant differences in attainment level regardless of whether I-VR or non-immersive methods were utilised. Only two studies found clear detrimental effects of using I-VR. However, most studies used short interventions, did not examine information retention, and were focused mainly on the teaching of scientific topics such as biology or physics. In addition, the MERSQI showed that the methods used to evaluate learning outcomes are often inadequate and this may affect the interpretation of I-VR’s utility. The review highlights that a rigorous methodological approach through the identification of appropriate assessment measures, intervention characteristics, and learning outcomes is essential to understanding the potential of I-VR as a pedagogical method. © 2020, The Author(s).","Education; Head mounted displays; Learning; Simulations; Virtual reality","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85087757106"
"Drydakis N.","Drydakis, Nick (26022336500)","26022336500","Mobile applications aiming to facilitate immigrants’ societal integration and overall level of integration, health and mental health. Does artificial intelligence enhance outcomes?","2021","Computers in Human Behavior","117","","106661","","","","18","10.1016/j.chb.2020.106661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098090687&doi=10.1016%2fj.chb.2020.106661&partnerID=40&md5=39662dcade201822116b6a0f205d0e5b","Centre for Pluralist Economics, School of Economics and International Business, Faculty of Business and Law, Anglia Ruskin University, East Road, Cambridge, CB1 1PT, United Kingdom; University of Cambridge, Pembroke College, Cambridge, United Kingdom; University of Cambridge, Centre for Science and Policy, Cambridge, United Kingdom; Institute for the Study of Labor, Bonn, Germany; Global Labor Organization, Essen, Germany","Drydakis N., Centre for Pluralist Economics, School of Economics and International Business, Faculty of Business and Law, Anglia Ruskin University, East Road, Cambridge, CB1 1PT, United Kingdom, University of Cambridge, Pembroke College, Cambridge, United Kingdom, University of Cambridge, Centre for Science and Policy, Cambridge, United Kingdom, Institute for the Study of Labor, Bonn, Germany, Global Labor Organization, Essen, Germany","Using panel data on immigrant populations from European, Asian and African countries the study estimates positive associations between the number of mobile applications in use aiming to facilitate immigrants' societal integration (m-Integration) and increased level of integration (Ethnosizer), good overall health (EQ-VAS) and mental health (CESD-20). It is estimated that the patterns are gender sensitive. In addition, it is found that m-Integration applications in relation to translation and voice assistants, public services, and medical services provide the highest returns on immigrants' level of integration, health/mental health status. For instance, translation and voice assistant applications are associated with a 4% increase in integration and a 0.8% increase in good overall health. Moreover, m-Integration applications aided by artificial intelligence (AI) are associated with increased health/mental health and integration levels among immigrants. We indicate that AI by providing customized search results, peer reviewed e-learning, professional coaching on pronunciation, real-time translations, and virtual communication for finding possible explanations for health conditions might bring better quality services facilitating immigrants' needs. This is the first known study to introduce the term ‘m-Integration’, quantify associations between applications, health/mental health and integration for immigrants, and assess AI's role in enhancing the aforementioned outcomes. © 2020 Elsevier Ltd","Artificial intelligence; Health; Immigrants; Integration; m-Health; m-Integration; Mental health; Mobile applications; Refugees","","Elsevier Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85098090687"
"Lalitharatne T.D.; Tan Y.; He L.; Leong F.; Van Zalk N.; De Lusignan S.; Iida F.; Nanayakkara T.","Lalitharatne, Thilina Dulantha (55603415400); Tan, Yongxuan (57220901205); He, Liang (57204667456); Leong, Florence (57191408860); Van Zalk, Nejra (37111741300); De Lusignan, Simon (7003334937); Iida, Fumiya (55087022900); Nanayakkara, Thrishantha (6508336274)","55603415400; 57220901205; 57204667456; 57191408860; 37111741300; 7003334937; 55087022900; 6508336274","MorphFace: A Hybrid Morphable Face for a Robopatient","2021","IEEE Robotics and Automation Letters","6","2","9312407","643","650","7","7","10.1109/LRA.2020.3048670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099104906&doi=10.1109%2fLRA.2020.3048670&partnerID=40&md5=6f1763ccd08264f49cde84711a160d6c","Dyson School of Design Engineering, Imperial College London, London, SW7 1AL, United Kingdom; Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, OX2 6GG, United Kingdom; Department of Engineering, University of Cambridge, Cambridge, CB2 1PZ, United Kingdom","Lalitharatne T.D., Dyson School of Design Engineering, Imperial College London, London, SW7 1AL, United Kingdom; Tan Y., Dyson School of Design Engineering, Imperial College London, London, SW7 1AL, United Kingdom; He L., Dyson School of Design Engineering, Imperial College London, London, SW7 1AL, United Kingdom; Leong F., Dyson School of Design Engineering, Imperial College London, London, SW7 1AL, United Kingdom; Van Zalk N., Dyson School of Design Engineering, Imperial College London, London, SW7 1AL, United Kingdom; De Lusignan S., Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, OX2 6GG, United Kingdom; Iida F., Department of Engineering, University of Cambridge, Cambridge, CB2 1PZ, United Kingdom; Nanayakkara T., Dyson School of Design Engineering, Imperial College London, London, SW7 1AL, United Kingdom","Physicians use pain expressions shown in a patient's face to regulate their palpation methods during physical examination. Training to interpret patients' facial expressions with different genders and ethnicities still remains a challenge, taking novices a long time to learn through experience. This letter presents MorphFace: a controllable 3D physical-virtual hybrid face to represent pain expressions of patients from different ethnicity-gender backgrounds. It is also an intermediate step to expose trainee physicians to the gender and ethnic diversity of patients. We extracted four principal components from the Chicago Face Database to design a four degrees of freedom (DoF) physical face controlled via tendons to span ∼85% of facial variations among gender and ethnicity. Details such as skin colour, skin texture, and facial expressions are synthesized by a virtual model and projected onto the 3D physical face via a front-mounted LED projector to obtain a hybrid controllable patient face simulator. A user study revealed that certain differences in ethnicity between the observer and the MorphFace lead to different perceived pain intensity for the same pain level rendered by the MorphFace. This highlights the value of having MorphFace as a controllable hybrid simulator to quantify perceptual differences during physician training.  © 2016 IEEE.","Gesture; medical robots and systems; modeling and simulating humans; posture and facial expressions","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85099104906"
"Rivas J.J.; Orihuela-Espina F.; Palafox L.; Bianchi-Berthouze N.; Lara M.D.C.; Hernandez-Franco J.; Sucar L.E.","Rivas, Jesus Joel (56519318700); Orihuela-Espina, Felipe (22986331300); Palafox, Lorena (55650784000); Bianchi-Berthouze, Nadia (6602671345); Lara, Maria Del Carmen (57200752728); Hernandez-Franco, Jorge (15020479500); Sucar, Luis Enrique (8312922300)","56519318700; 22986331300; 55650784000; 6602671345; 57200752728; 15020479500; 8312922300","Unobtrusive Inference of Affective States in Virtual Rehabilitation from Upper Limb Motions: A Feasibility Study","2020","IEEE Transactions on Affective Computing","11","3","8295248","470","481","11","11","10.1109/TAFFC.2018.2808295","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042387034&doi=10.1109%2fTAFFC.2018.2808295&partnerID=40&md5=f16b44fe8e8acbd8323333ae603be3f4","Department of Computer Science, Instituto Nacional de Astrofísica, Óptica y Electrónica, Puebla, 72840, Mexico; Instituto Nacional de Neurologiá y Neurocirugiá, Mexico City, 14269, Mexico; UCL Interaction Centre, University College of London, London, WC1E 6BT, United Kingdom; Benémerita Universidad Autónoma de Puebla, Puebla, 72240, Mexico; Computer Science Department, Science and Technology Faculty, Universidad de Carabobo, Valencia, 2005, Venezuela","Rivas J.J., Department of Computer Science, Instituto Nacional de Astrofísica, Óptica y Electrónica, Puebla, 72840, Mexico, Computer Science Department, Science and Technology Faculty, Universidad de Carabobo, Valencia, 2005, Venezuela; Orihuela-Espina F., Department of Computer Science, Instituto Nacional de Astrofísica, Óptica y Electrónica, Puebla, 72840, Mexico; Palafox L., Instituto Nacional de Neurologiá y Neurocirugiá, Mexico City, 14269, Mexico; Bianchi-Berthouze N., UCL Interaction Centre, University College of London, London, WC1E 6BT, United Kingdom; Lara M.D.C., Benémerita Universidad Autónoma de Puebla, Puebla, 72240, Mexico; Hernandez-Franco J., Instituto Nacional de Neurologiá y Neurocirugiá, Mexico City, 14269, Mexico; Sucar L.E., Department of Computer Science, Instituto Nacional de Astrofísica, Óptica y Electrónica, Puebla, 72840, Mexico","Virtual rehabilitation environments may afford greater patient personalization if they could harness the patient's affective state. Four states: Anxiety, pain, engagement and tiredness (either physical or psychological), were hypothesized to be inferable from observable metrics of hand location and gripping strength-relevant for rehabilitation. Contributions are; (a) multiresolution classifier built from Semi-Naïve Bayesian classifiers, and (b) establishing predictive relations for the considered states from the motor proxies capitalizing on the proposed classifier with recognition levels sufficient for exploitation. 3D hand locations and gripping strength streams were recorded from 5 post-stroke patients whilst undergoing motor rehabilitation therapy administered through virtual rehabilitation along 10 sessions over 4 weeks. Features from the streams characterized the motor dynamics, while spontaneous manifestations of the states were labelled from concomitant videos by experts for supervised classification. The new classifier was compared against baseline support vector machine (SVM) and random forest (RF) with all three exhibiting comparable performances. Inference of the aforementioned states departing from chosen motor surrogates appears feasible, expediting increased personalization of virtual motor neurorehabilitation therapies. © 2018 IEEE.","Affective issues in user interaction; fingers pressure; hand movements; posture; rehabilitation; semi-Naïve Bayesian classifier; stroke","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85042387034"
"Al-Fadhili Y.Q.I.; Chung P.W.H.; Li B.; Bowman R.","Al-Fadhili, Yahya Qasim I. (57195713434); Chung, Paul W. H. (55558432400); Li, Baihua (55750048200); Bowman, Richard (12797538000)","57195713434; 55558432400; 55750048200; 12797538000","3D Simulation of Navigation Problem of People with Cerebral Visual Impairment","2018","Advances in Intelligent Systems and Computing","650","","","265","275","10","3","10.1007/978-3-319-66939-7_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029580051&doi=10.1007%2f978-3-319-66939-7_23&partnerID=40&md5=362cfe4c16833057553154b5f6afa0eb","Computer Science Department, College of Education, Mosul University, Mosul, Iraq; Computer Department, School of Science, Loughborough University, Loughborough, United Kingdom; Great Ormond Street Hospital, London, United Kingdom","Al-Fadhili Y.Q.I., Computer Science Department, College of Education, Mosul University, Mosul, Iraq; Chung P.W.H., Computer Department, School of Science, Loughborough University, Loughborough, United Kingdom; Li B., Computer Department, School of Science, Loughborough University, Loughborough, United Kingdom; Bowman R., Great Ormond Street Hospital, London, United Kingdom","Cerebral Visual Impairment (CVI) is a medical area that concerns the study of the effect of brain damages on the visual field (VF). People with CVI have difficulties in their mobility and they have behaviours that others find hard to understand due to their visual impairment. A branch of Artificial Intelligence (AI) is the simulation of behaviour by building computational models that help to explain how people solve problems or why they behave in a certain way. This paper describes a novel computational system that simulates the navigation problem that is faced by people with CVI. This will help relatives, friends, and ophthalmologists of CVI patients understand more about their difficulties in navigating their everyday environment. The navigation simulation system is implemented using the Unity3D game engine. Virtual scenes of different living environment are also created using the Unity modelling software. The vision of the avatar in the virtual environment is implemented using a camera provided by the 3D game engine. Filters that mimic visual defects are created automatically and placed in front of the visual field of the avatar. The filters are based on the visual field charts of individual patients. Algorithms for navigation based on the limited vision have also been developed to demonstrate navigation problems because of the visual defects. The results showed different actions for the navigation behaviours according to the patients’ vision, and the navigations differ from patient to another according to their different defects. © 2018, Springer International Publishing AG.","AI based modeling and navigation; Cerebral Visual Impairment; Imitation; Vision impairment simulation","Schockaert S.; Zhang Q.; Chao F.","Springer Verlag","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85029580051"
"Sadare O.; Melvin T.; Harvey H.; Vollebregt E.; Gilbert S.","Sadare, Olamide (58086130900); Melvin, Tom (57209235135); Harvey, Hugh (57222262250); Vollebregt, Erik (37035351200); Gilbert, Stephen (16833743700)","58086130900; 57209235135; 57222262250; 37035351200; 16833743700","Can Apple and Google continue as health app gatekeepers as well as distributors and developers?","2023","npj Digital Medicine","6","1","8","","","","5","10.1038/s41746-023-00754-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147191322&doi=10.1038%2fs41746-023-00754-6&partnerID=40&md5=2982dfd2277a7d1fd4a0fe3507d6cc61","Else Kröner Fresenius Center for Digital Health, Technische Universität Dresden, Dresden, Germany; School of Medicine, Trinity College, University of Dublin, Dublin, Ireland; Hardian Health, Haywards Heath, United Kingdom; Axon Lawyers, Amsterdam, Netherlands","Sadare O., Else Kröner Fresenius Center for Digital Health, Technische Universität Dresden, Dresden, Germany; Melvin T., School of Medicine, Trinity College, University of Dublin, Dublin, Ireland; Harvey H., Hardian Health, Haywards Heath, United Kingdom; Vollebregt E., Axon Lawyers, Amsterdam, Netherlands; Gilbert S., Else Kröner Fresenius Center for Digital Health, Technische Universität Dresden, Dresden, Germany","Mobile apps are the primary means by which consumers access digital health and wellness software, with delivery dominated by the ‘Apple App Store’ and the ‘Google Play Store’. Through these virtual storefronts Apple and Google act as the distributor (and sometimes, importer) of many thousands of health and wellness apps into the EU, some of which have a medical purpose. As a result of changes to EU law which came into effect in May 2021, they must now ensure that apps are compliant with medical devices regulation and to inform authorities of serious incidents arising from their use. The extent to which these new rules are being complied with in practice is uneven, and in some areas unclear. In light of EU legislation related to competition, which came into effect in November 2022, it is also unclear how conflicts of interest can be managed between Apple and Google’s roles as gateway duopoly importers and distributors whilst also developers of their own competitive health products. Finally, with the proposed European health data space regulation, wellness apps will be voluntarily registered and labelled in a fashion more like medical devices than consumer software. We explore the implications of these new regulations and propose future models that could resolve the apparent conflicts. All stakeholders would benefit from improved app store models to sustainably evolve safer, better, and fairer provision of digital health applications in the EU. As EU legislation comes into force it could serve as a template for other regions globally. © 2023, The Author(s).","","","Nature Research","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85147191322"
"Gutiérrez-Fernández A.; Fernández-Llamas C.; Vázquez-Casares A.M.; Mauriz E.; Riego-del-Castillo V.; John N.W.","Gutiérrez-Fernández, Alexis (57210195724); Fernández-Llamas, Camino (57194729907); Vázquez-Casares, Ana M. (16444962500); Mauriz, Elba (12142115700); Riego-del-Castillo, Virginia (57211181208); John, Nigel W. (7005876140)","57210195724; 57194729907; 16444962500; 12142115700; 57211181208; 7005876140","Immersive haptic simulation for training nurses in emergency medical procedures: Evaluation of the needle decompression procedure: HMD and haptics versus mannequin","2024","Visual Computer","","","","","","","0","10.1007/s00371-023-03227-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182995387&doi=10.1007%2fs00371-023-03227-9&partnerID=40&md5=354c516f02ec8d75ed98edeb552d4f03","School of Industrial, Computer and Aeroespace Engineering, University of León, León, Spain; Faculty of Health Sciences, University of León, León, Spain; Medical Graphics Laboratory, University of Chester, Chester, United Kingdom","Gutiérrez-Fernández A., School of Industrial, Computer and Aeroespace Engineering, University of León, León, Spain; Fernández-Llamas C., School of Industrial, Computer and Aeroespace Engineering, University of León, León, Spain; Vázquez-Casares A.M., Faculty of Health Sciences, University of León, León, Spain; Mauriz E., Faculty of Health Sciences, University of León, León, Spain; Riego-del-Castillo V., School of Industrial, Computer and Aeroespace Engineering, University of León, León, Spain; John N.W., Medical Graphics Laboratory, University of Chester, Chester, United Kingdom","The use of haptic simulation for emergency procedures in nursing training presents a viable, versatile and affordable alternative to traditional mannequin environments. In this paper, an evaluation is performed in a virtual environment with a head-mounted display and haptic devices, and also with a mannequin. We focus on a chest decompression, a life-saving invasive procedure used for trauma-associated cardiopulmonary resuscitation (and other causes) that every emergency physician and/or nurse needs to master. Participants’ heart rate and blood pressure were monitored to measure their stress level. In addition, the NASA Task Load Index questionnaire was used. The results show the approved usability of the VR environment and that it provides a higher level of immersion compared to the mannequin, with no statistically significant difference in terms of cognitive load, although the use of VR is perceived as a more difficult task. We can conclude that the use of haptic-enabled virtual reality simulators has the potential to provide an experience as stressful as the real one while training in a safe and controlled environment. © 2024, The Author(s).","Haptic device; Human–computer interaction; Medical skills training; Virtual reality","","Springer Science and Business Media Deutschland GmbH","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85182995387"
"Mikolajewski D.; Bryniarska A.; Wilczek P.M.; Myslicka M.; Sudol A.; Tenczynski D.; Kostro M.; Rekawek D.; Tichy R.; Gasz R.; Pelc M.; Zygarlicki J.; Koziol M.; Martinek R.; Vilimkova R.K.; Vilimek D.; Kawala-Sterniuk A.","Mikolajewski, Dariusz (36996644200); Bryniarska, Anna (55913254800); Wilczek, Piotr Michal (28268133000); Myslicka, Maria (58917329000); Sudol, Adam (57191478047); Tenczynski, Dominik (58983665500); Kostro, Michal (58983665600); Rekawek, Dominika (58984324700); Tichy, Rafal (58984157300); Gasz, Rafal (54791033300); Pelc, Mariusz (9335890000); Zygarlicki, Jaroslaw (26032464400); Koziol, Michal (57191410237); Martinek, Radek (36537543900); Vilimkova, Radana Kahankova (58983995000); Vilimek, Dominik (57210376435); Kawala-Sterniuk, Aleksandra (57215665281)","36996644200; 55913254800; 28268133000; 58917329000; 57191478047; 58983665500; 58983665600; 58984324700; 58984157300; 54791033300; 9335890000; 26032464400; 57191410237; 36537543900; 58983995000; 57210376435; 57215665281","THE MOST CURRENT SOLUTIONS USING VIRTUAL-REALITY-BASED METHODS IN CARDIAC SURGERY – A SURVEY","2024","Computer Science","25","1","","107","128","21","0","10.7494/csci.2024.25.1.5633","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190240343&doi=10.7494%2fcsci.2024.25.1.5633&partnerID=40&md5=31faf52c653aee073b33d099a8605a0c","Kazimierz Wielki University in Bydgoszcz, Institute of Computer Science, Kopernika 1, Bydgoszcz, 85-074, Poland; Medical University in Lublin, Neuropsychological Research Unit, 2nd Clinic of the Psychiatry and Psychiatric Rehabilitation, Gluska 1, Lublin, 20-439, Poland; Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland; The President Stanislaw Wojciechowski Calisia University, Faculty of Health Sciences, Nowy Swiat 4, Kalisz, 62-800, Poland; Prof. Zbigniew Religa Foundation for Cardiac Surgery Development, Wolnosci 345a, Zabrze, 41-800, Poland; Medical Algorithms Sp. z o. o., Aleja Legionow 4, Bytom, 41-902, Poland; Wroclaw Medical University, Faculty of Medicine, J. Mikulicza-Radeckiego 5, Wroclaw, 50-345, Poland; University of Opole, Faculty of Natural Sciences and Technology, Kardynala Kominka 6, 6a, Opole, 45-032, Poland; University of Greenwich, School of Computing and Mathematical Sciences, Old Royal Naval College, Park Row, London, SE10 9LS, United Kingdom; 0VSB-Technical University Ostrava, Department of Cybernetics and Biomedical Engineering – FEECS, 17. listopadu 2172/15, Ostrava–Poruba, 708 00, Czech Republic","Mikolajewski D., Kazimierz Wielki University in Bydgoszcz, Institute of Computer Science, Kopernika 1, Bydgoszcz, 85-074, Poland, Medical University in Lublin, Neuropsychological Research Unit, 2nd Clinic of the Psychiatry and Psychiatric Rehabilitation, Gluska 1, Lublin, 20-439, Poland; Bryniarska A., Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland; Wilczek P.M., The President Stanislaw Wojciechowski Calisia University, Faculty of Health Sciences, Nowy Swiat 4, Kalisz, 62-800, Poland, Prof. Zbigniew Religa Foundation for Cardiac Surgery Development, Wolnosci 345a, Zabrze, 41-800, Poland, Medical Algorithms Sp. z o. o., Aleja Legionow 4, Bytom, 41-902, Poland; Myslicka M., Wroclaw Medical University, Faculty of Medicine, J. Mikulicza-Radeckiego 5, Wroclaw, 50-345, Poland; Sudol A., University of Opole, Faculty of Natural Sciences and Technology, Kardynala Kominka 6, 6a, Opole, 45-032, Poland; Tenczynski D., University of Opole, Faculty of Natural Sciences and Technology, Kardynala Kominka 6, 6a, Opole, 45-032, Poland; Kostro M., University of Opole, Faculty of Natural Sciences and Technology, Kardynala Kominka 6, 6a, Opole, 45-032, Poland; Rekawek D., University of Opole, Faculty of Natural Sciences and Technology, Kardynala Kominka 6, 6a, Opole, 45-032, Poland; Tichy R., University of Opole, Faculty of Natural Sciences and Technology, Kardynala Kominka 6, 6a, Opole, 45-032, Poland; Gasz R., Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland; Pelc M., University of Opole, Faculty of Natural Sciences and Technology, Kardynala Kominka 6, 6a, Opole, 45-032, Poland, University of Greenwich, School of Computing and Mathematical Sciences, Old Royal Naval College, Park Row, London, SE10 9LS, United Kingdom; Zygarlicki J., Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland; Koziol M., Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland; Martinek R., Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland, 0VSB-Technical University Ostrava, Department of Cybernetics and Biomedical Engineering – FEECS, 17. listopadu 2172/15, Ostrava–Poruba, 708 00, Czech Republic; Vilimkova R.K., Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland, 0VSB-Technical University Ostrava, Department of Cybernetics and Biomedical Engineering – FEECS, 17. listopadu 2172/15, Ostrava–Poruba, 708 00, Czech Republic; Vilimek D., 0VSB-Technical University Ostrava, Department of Cybernetics and Biomedical Engineering – FEECS, 17. listopadu 2172/15, Ostrava–Poruba, 708 00, Czech Republic; Kawala-Sterniuk A., Opole University of Technology, Faculty of Electrical Engineering, Automatic Control and Informatics, Proszkowska 76, Opole, 45-758, Poland","There is a widespread belief that VR technologies can provide controlled, multisensory, interactive 3D stimulus environments that engage patients in interventions and measure, record and motivate required human performance. In order to investigate state-of-the-art and associated occupations we provided a careful review of 6 leading medical and technical bibliometric databases. Despite the apparent popularity of the topic of VR use in cardiac surgery, only 47 articles published between 2002 and 2022 met the inclusion criteria. Based on them, VR-based solutions in cardiac surgery are useful both, for medical specialists and for the patients themselves. The new lifestyle required from cardiac surgery patients is easier to implement thanks to VR-based educational and motivational tools. However, it is necessary to develop the above-mentioned tools and compare their effectiveness with Augmented Reality (AR). For the aforementioned reasons, interdisciplinary collaboration between scientists, clinicians and engineers is necessary. © 2024 Author(s). This is an open access publication, which can be used, distributed and reproduced in any medium according to the Creative Commons CC-BY 4.0 License.","cardiac surgery; clinical applications; image processing; surgical training; virtual reality","","AGH University of Science and Technology Press","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85190240343"
"Peach T.W.; Ricci D.; Ventikos Y.","Peach, T.W. (56305052900); Ricci, D. (35446148600); Ventikos, Y. (6603704133)","56305052900; 35446148600; 6603704133","A Virtual Comparison of the eCLIPs Device and Conventional Flow-Diverters as Treatment for Cerebral Bifurcation Aneurysms","2019","Cardiovascular Engineering and Technology","10","3","","508","519","11","20","10.1007/s13239-019-00424-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069663391&doi=10.1007%2fs13239-019-00424-3&partnerID=40&md5=eaf41a40d26ec2e740f4014cd051a64b","Department of Mechanical Engineering, University College London, Torrington Place, London, WC1E 7JE, United Kingdom; eVasc Neurovascular, 107-1099 8th Avenue West, Vancouver, V6H 1C3, BC, Canada; Division of Cardiology, University of British Columbia, Vancouver, BC, Canada","Peach T.W., Department of Mechanical Engineering, University College London, Torrington Place, London, WC1E 7JE, United Kingdom; Ricci D., eVasc Neurovascular, 107-1099 8th Avenue West, Vancouver, V6H 1C3, BC, Canada, Division of Cardiology, University of British Columbia, Vancouver, BC, Canada; Ventikos Y., Department of Mechanical Engineering, University College London, Torrington Place, London, WC1E 7JE, United Kingdom","Purpose: Effective, consistent, and complication-free treatment of cerebral bifurcation aneurysms remains elusive despite a pressing need, with the majority of lesions presenting in such locations. Current treatment options focus either on aneurysm coil retention, supported by a stent-like device positioned in the parent vessel lumen, or intrasaccular devices that disrupt flow within the aneurysm dome. A third alternative, i.e., the use of conventional (intraluminal) flow-diverters to treat such bifurcation aneurysms raises the problem that at least one daughter vessel needs to be jailed in such a deployment. The eCLIPs is a stent-like device that offers the possibility of flow-diversion at the aneurysm neck, without the drawbacks of daughter vessel occlusion or those of intrasaccular deployment. Methods: In this study the eCLIPs device was virtually deployed in five cerebral bifurcation aneurysms and compared with a conventional tubular flow-diverter device. Computational fluid dynamics (CFD) simulations of the aneurysm haemodynamic environment pre- and post-implantation were conducted, and focussed on metrics associated with successful aneurysm occlusion. Absolute and relative reductions in aneurysm inflow rate (Q) and time-averaged wall shear stress (TAWSS) were recorded. Results: The eCLIPs device was found to perform in a similar qualitative fashion to tubular flow-diverters, with overall reduction of metrics being somewhat more modest however, when compared to such devices. Aneurysm inflow reduction and TAWSS reduction were typically 10–20% lower for the eCLIPs, when compared to a generic flow diverter (FDBRAIDED) similar to devices currently in clinical use. The eCLIPs was less effective at diffusing inflow jets and at reducing the overall velocity of the flow, when compared to these devices. This result is likely due to the larger device pore size in the eCLIPs. Notably, it was found that the eCLIPs provided approximately equal resistance to flow entering and exiting the aneurysm, which was not true for the FDBRAIDED device, where high-speed concentrations of outflow were seen at the aneurysm neck along with local TAWSS elevation. The clinical implications of such behaviour are not examined in detail here but could be significant. Conclusions: Our findings indicate that the eCLIPs device acts as a flow-diverter for bifurcation aneurysms, with somewhat diminished occlusion properties comparing to tubular flow diverters but without the jailing and diminished flow evident in a daughter vessel associated with use of conventional devices. © 2019, The Author(s).","Bifurcation aneurysm; Cerebral aneurysm; Flow-diverter; Medical device; Stent","","Springer New York LLC","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85069663391"
"Abad A.C.; Reid D.; Ranasinghe A.","Abad, Alexander Co (56770808500); Reid, David (19934745600); Ranasinghe, Anuradha (56028738000)","56770808500; 19934745600; 56028738000","A Novel Untethered Hand Wearable with Fine-Grained Cutaneous Haptic Feedback","2022","Sensors","22","5","1924","","","","5","10.3390/s22051924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126490211&doi=10.3390%2fs22051924&partnerID=40&md5=4989929c282174561a0c9f30a38c4b64","Faculty of Science, School of Mathematics, Computer Science, and Engineering, Liverpool Hope University, Liverpool, L16 9JD, United Kingdom; Department of Electronics and Computer Engineering, De La Salle University, 2401 Taft Avenue, Manila, 0922, Philippines","Abad A.C., Faculty of Science, School of Mathematics, Computer Science, and Engineering, Liverpool Hope University, Liverpool, L16 9JD, United Kingdom, Department of Electronics and Computer Engineering, De La Salle University, 2401 Taft Avenue, Manila, 0922, Philippines; Reid D., Faculty of Science, School of Mathematics, Computer Science, and Engineering, Liverpool Hope University, Liverpool, L16 9JD, United Kingdom; Ranasinghe A., Faculty of Science, School of Mathematics, Computer Science, and Engineering, Liverpool Hope University, Liverpool, L16 9JD, United Kingdom","During open surgery, a surgeon relies not only on the detailed view of the organ being operated upon and on being able to feel the fine details of this organ but also heavily relies on the combination of these two senses. In laparoscopic surgery, haptic feedback provides surgeons information on interaction forces between instrument and tissue. There have been many studies to mimic the haptic feedback in laparoscopic-related telerobotics studies to date. However, cutaneous feedback is mostly restricted or limited in haptic feedback-based minimally invasive studies. We argue that fine-grained information is needed in laparoscopic surgeries to study the details of the instrument’s end and can convey via cutaneous feedback. We propose an exoskeleton haptic hand wearable which consists of five 4 × 4 miniaturized fingertip actuators, 80 in total, to convey cutaneous feedback. The wearable is described as modular, lightweight, Bluetooth, and WiFi-enabled, and has a maximum power consumption of 830 mW. Software is developed to demonstrate rapid tactile actuation of edges; this allows the user to feel the contours in cutaneous feedback. Moreover, to demonstrate the idea as an object displayed on a flat monitor, initial tests were carried out in 2D. In the second phase, the wearable exoskeleton glove is then further developed to feel 3D virtual objects by using a virtual reality (VR) headset demonstrated by a VR environment. Two-dimensional and 3D objects were tested by our novel untethered haptic hand wearable. Our results show that untethered humans understand actuation in cutaneous feedback just in a single tapping with 92.22% accuracy. Our wearable has an average latency of 46.5 ms, which is much less than the 600 ms tolerable delay acceptable by a surgeon in teleoperation. Therefore, we suggest our untethered hand wearable to enhance multimodal perception in minimally invasive surgeries to naturally feel the immediate environments of the instruments. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Cutaneous feedback; Haptic devices; Medical training; Teleoperation; Virtual reality; Wearable devices","","MDPI","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85126490211"
"Iwendi C.","Iwendi, Celestine (54420169700)","54420169700","Innovative augmented and virtual reality applications for disease diagnosis based on integrated genetic algorithms","2023","International Journal of Cognitive Computing in Engineering","4","","","266","276","10","5","10.1016/j.ijcce.2023.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166625885&doi=10.1016%2fj.ijcce.2023.07.004&partnerID=40&md5=7fe117d3cc41d5ea42147523c7b061c4","School of Creative technologies, University of Bolton, United Kingdom","Iwendi C., School of Creative technologies, University of Bolton, United Kingdom","In this comprehensive paper the method of detecting various diseases within short period of time using Audio Reality/ Virtual Reality (AR/VR) techniques is proposed. For proper functioning of AR/VR models in medical applications three distinct algorithms such Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO) is integrated where the entire operation is performed with respect to search space. Moreover, the detection process in AR/VR models depends on several factors where minimum error functions must be ensured. Hence in the integrated technique both Absolute Errors (AE) and Time Errors (TE) are measured and compared with existing methods. As the performance of detection is greatly improved with search space the fitness function of each algorithm is observed and it is considered as maximization objective in the proposed method. Furthermore, the complexity of AR/VR models in real time detection process is detected and it is realistic that high complex detections are converted to simple detections. In the comparative analysis of three algorithms ACO proves to be much better as errors are minimized with maximization of fitness function. © 2023","Ant colony optimization (ACO); Audio reality; Genetic algorithm (GA); Particle swarm optimization (PSO); Virtual reality","","KeAi Communications Co.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85166625885"
"Prendinger H.; Alvarez N.; Sanchez-Ruiz A.; Cavazza M.; Catarino J.; Oliveira J.; Prada R.; Fujimoto S.; Shigematsu M.","Prendinger, Helmut (6701628836); Alvarez, Nahum (55441230700); Sanchez-Ruiz, Antonio (22981832900); Cavazza, Marc (7007101480); Catarino, João (57917987800); Oliveira, João (57212951102); Prada, Rui (6603926477); Fujimoto, Shuji (7402186843); Shigematsu, Mika (23968093000)","6701628836; 55441230700; 22981832900; 7007101480; 57917987800; 57212951102; 6603926477; 7402186843; 23968093000","Intelligent biohazard training based on real-time task recognition","2016","ACM Transactions on Interactive Intelligent Systems","6","3","21","","","","5","10.1145/2883617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989807484&doi=10.1145%2f2883617&partnerID=40&md5=b7ec6957b9956cfdb009c6004449bb8e","National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo, 101-8430, Japan; INESC-ID, Taguspark - Edif'icio IST, Avenida Professor Cavaco Silva, Porto Salvo, 2744-016, Portugal; Universidad Complutense de Madrid, Madrid, 28040, Spain; School of Engineering and Digital Arts, University of Kent, Canterbury, CT2 7NT, United Kingdom; Faculty of Medical Sciences, Kyushu University, 3-1-1 Maidashi, Higashi-ku, Fukuoka, 812-8582, Japan; National Institute of Infectious Diseases, Toyama 1-23-1, Shinjuku-ku, Tokyo, 162-8640, Japan","Prendinger H., National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo, 101-8430, Japan; Alvarez N., National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo, 101-8430, Japan; Sanchez-Ruiz A., Universidad Complutense de Madrid, Madrid, 28040, Spain; Cavazza M., School of Engineering and Digital Arts, University of Kent, Canterbury, CT2 7NT, United Kingdom; Catarino J., INESC-ID, Taguspark - Edif'icio IST, Avenida Professor Cavaco Silva, Porto Salvo, 2744-016, Portugal; Oliveira J., INESC-ID, Taguspark - Edif'icio IST, Avenida Professor Cavaco Silva, Porto Salvo, 2744-016, Portugal; Prada R., INESC-ID, Taguspark - Edif'icio IST, Avenida Professor Cavaco Silva, Porto Salvo, 2744-016, Portugal; Fujimoto S., Faculty of Medical Sciences, Kyushu University, 3-1-1 Maidashi, Higashi-ku, Fukuoka, 812-8582, Japan; Shigematsu M., National Institute of Infectious Diseases, Toyama 1-23-1, Shinjuku-ku, Tokyo, 162-8640, Japan","Virtual environments offer an ideal setting to develop intelligent training applications. Yet, their ability to support complex procedures depends on the appropriate integration of knowledge-based techniques and natural interaction. In this article, we describe the implementation of an intelligent rehearsal system for biohazard laboratory procedures, based on the real-time instantiation of task models from the trainee's actions A virtual biohazard laboratory has been recreated using the Unity3D engine, in which users interact with laboratory objects using keyboard/mouse input or hand gestures through a Kinect device. Realistic behavior for objects is supported by the implementation of a relevant subset of common sense and physics knowledge. User interaction with objects leads to the recognition of specific actions, which are used to progressively instantiate a task-based representation of biohazard procedures. The dynamics of this instantiation process supports trainee evaluation as well as real-time assistance. This system is designed primarily as a rehearsa system providing real-time advice and supporting user performance evaluation. We provide detailed examples illustrating error detection and recovery, and results from on-site testing with students from the Faculty of Medical Sciences at Kyushu University. In the study, we investigate the usability aspect by comparing interaction with mouse and Kinect devices and the effect of real-time task recognition on recovery time after user mistakes.","Bio-safety risk management; Training application; Virtual worlds","","Association for Computing Machinery","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-84989807484"
"Maloca P.M.; de Carvalho J.E.R.; Heeren T.; Hasler P.W.; Mushtaq F.; Mon-Williams M.; Scholl H.P.N.; Balaskas K.; Egan C.; Tufail A.; Witthauer L.; Cattin P.C.","Maloca, Peter M. (6507518152); de Carvalho, J. Emanuel Ramos (57205895491); Heeren, Tjebo (55555386500); Hasler, Pascal W. (18037277400); Mushtaq, Faisal (56999078200); Mon-Williams, Mark (7006287402); Scholl, Hendrik P. N. (7006706337); Balaskas, Konstantinos (35221042600); Egan, Catherine (8101026700); Tufail, Adnan (15924308700); Witthauer, Lilian (45162074100); Cattin, Philippe C. (6506422723)","6507518152; 57205895491; 55555386500; 18037277400; 56999078200; 7006287402; 7006706337; 35221042600; 8101026700; 15924308700; 45162074100; 6506422723","High-performance virtual reality volume rendering of original optical coherence tomography point-cloud data enhanced with real-time ray casting","2018","Translational Vision Science and Technology","7","4","2","","","11","28","10.1167/tvst.7.4.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050500300&doi=10.1167%2ftvst.7.4.2&partnerID=40&md5=7650eb44f22a83ece4f78db4d3ec0df1","OCTlab, Department of Ophthalmology, University Hospital Basel, Basel, Switzerland; Moorfields Eye Hospital, London, United Kingdom; School of Psychology, University of Leeds, Leeds, West Yorkshire, United Kingdom; Centre for Immersive Technologies, University of Leeds, Leeds, West Yorkshire, United Kingdom; Bradford Institute for Health Research, Bradford, United Kingdom; National Centre for Vision, University of Southeast Norway, Kongsberg, Norway; Institute of Molecular and Clinical Ophthalmology Basel (IOB), Basel, Switzerland; Department of Ophthalmology, University of Basel, Basel, Switzerland; Wilmer Eye Institute, Johns Hopkins University, Baltimore, MD, United States; Moorfields Ophthalmic Reading Centre, London, United Kingdom; Center for Medical Image Analysis & Navigation, University Basel, Switzerland","Maloca P.M., OCTlab, Department of Ophthalmology, University Hospital Basel, Basel, Switzerland, Moorfields Eye Hospital, London, United Kingdom, Department of Ophthalmology, University of Basel, Basel, Switzerland; de Carvalho J.E.R., Moorfields Eye Hospital, London, United Kingdom; Heeren T., Moorfields Eye Hospital, London, United Kingdom; Hasler P.W., OCTlab, Department of Ophthalmology, University Hospital Basel, Basel, Switzerland, Department of Ophthalmology, University of Basel, Basel, Switzerland; Mushtaq F., School of Psychology, University of Leeds, Leeds, West Yorkshire, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, West Yorkshire, United Kingdom; Mon-Williams M., School of Psychology, University of Leeds, Leeds, West Yorkshire, United Kingdom, Bradford Institute for Health Research, Bradford, United Kingdom, National Centre for Vision, University of Southeast Norway, Kongsberg, Norway; Scholl H.P.N., Institute of Molecular and Clinical Ophthalmology Basel (IOB), Basel, Switzerland, Department of Ophthalmology, University of Basel, Basel, Switzerland, Wilmer Eye Institute, Johns Hopkins University, Baltimore, MD, United States; Balaskas K., Moorfields Eye Hospital, London, United Kingdom, Moorfields Ophthalmic Reading Centre, London, United Kingdom; Egan C., Moorfields Eye Hospital, London, United Kingdom; Tufail A., Moorfields Eye Hospital, London, United Kingdom; Witthauer L., Center for Medical Image Analysis & Navigation, University Basel, Switzerland; Cattin P.C., Center for Medical Image Analysis & Navigation, University Basel, Switzerland","Purpose: Feasibility testing of a novel volume renders technology to display optical coherence tomography data (OCT) in a virtual reality (VR) environment. Methods: A VR program was written in C++/OpenGL to import and display volumetric OCT data in real time with 180 frames per second using a high-end computer and a tethered head-mounted display. Following exposure, participants completed a Simulator Sickness Questionnaire (SSQ) to assess for nausea, disorientation, and oculomotor disturbances. A user evaluation study of this software was conducted to explore the potential utility of this application. Results: Fifty-seven subjects completed the user testing (34 males and 23 females). Mean age was 48.5 years (range, 21–77 years). Mean acquired work experience of the 35 ophthalmologists (61.40%) included in the group was 15.46 years (range, 1–37 years). Twenty-nine participants were VR-naïve. The SSQ showed a mean total score of 5.8 (SD = 9.44) indicating that the system was well tolerated and produced minimal side effects. No difference was reported between VR-naïve participants and experienced users. Overall, immersed subjects reported an enjoyable VR-OCT presence effect. Conclusions: A usable and satisfying VR imaging technique was developed to display and interact with original OCT data. Translational Relevance: An advanced high-end VR image display method was successfully developed to provide new views and interactions in an ultra high-speed projected digital scenery using point-cloud OCT data. This represents the next generation of OCT image display technology and a new tool for patient engagement, medical education, professional training, and telecommunications. © 2018 The Authors.","Mesh; Ophthalmology; Optical coherence tomography; Point cloud data; Polygon; Ray casting; Virtual reality; Volume rendering","","Association for Research in Vision and Ophthalmology Inc.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85050500300"
"Meena Y.K.; Cecotti H.; Wong-Lin K.; Dutta A.; Prasad G.","Meena, Yogesh Kumar (57212351704); Cecotti, Hubert (8838569700); Wong-Lin, Kongfatt (26532134800); Dutta, Ashish (57190397627); Prasad, Girijesh (55812562500)","57212351704; 8838569700; 26532134800; 57190397627; 55812562500","Toward Optimization of Gaze-Controlled Human-Computer Interaction: Application to Hindi Virtual Keyboard for Stroke Patients","2018","IEEE Transactions on Neural Systems and Rehabilitation Engineering","26","4","","911","922","11","32","10.1109/TNSRE.2018.2814826","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043448774&doi=10.1109%2fTNSRE.2018.2814826&partnerID=40&md5=483f7b45222d5e94dc55457154577fdd","Intelligent Systems Research Centre, School of Computing and Intelligent Systems, Ulster University, Derry, Londonderry, BT48 7JL, United Kingdom; Department of Computer Science, College of Science and Mathematics, California State University at Fresno, Fresno, 93740, CA, United States; Centre for Mechatronics, IIT Kanpur, Kanpur, 208016, India","Meena Y.K., Intelligent Systems Research Centre, School of Computing and Intelligent Systems, Ulster University, Derry, Londonderry, BT48 7JL, United Kingdom; Cecotti H., Department of Computer Science, College of Science and Mathematics, California State University at Fresno, Fresno, 93740, CA, United States; Wong-Lin K., Intelligent Systems Research Centre, School of Computing and Intelligent Systems, Ulster University, Derry, Londonderry, BT48 7JL, United Kingdom; Dutta A., Centre for Mechatronics, IIT Kanpur, Kanpur, 208016, India; Prasad G., Intelligent Systems Research Centre, School of Computing and Intelligent Systems, Ulster University, Derry, Londonderry, BT48 7JL, United Kingdom","Virtual keyboard applications and alternative communication devices provide new means of communication to assist disabled people. To date, virtual keyboard optimization schemes based on script-specific information, along with multimodal input access facility, are limited. In this paper, we propose a novel method for optimizing the position of the displayed items for gaze-controlled tree-based menu selection systems by considering a combination of letter frequency and command selection time. The optimized graphical user interface layout has been designed for a Hindi language virtual keyboard based on a menu wherein 10 commands provide access to type 88 different characters, along with additional text editing commands. The system can be controlled in two different modes: eye-tracking alone and eye-tracking with an access soft-switch. Five different keyboard layouts have been presented and evaluated with ten healthy participants. Furthermore, the two best performing keyboard layouts have been evaluated with eye-tracking alone on ten stroke patients. The overall performance analysis demonstrated significantly superior typing performance, high usability (87% SUS score), and low workload (NASA TLX with 17 scores) for the letter frequency and time-based organization with script specific arrangement design. This paper represents the first optimized gaze-controlled Hindi virtual keyboard, which can be extended to other languages. © 2001-2011 IEEE.","Gaze tracking; graphical user interfaces; human computer interaction; optimization methods; performance evaluation","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85043448774"
"Pedersen R.L.; Picinali L.; Kajs N.; Patou F.","Pedersen, Rasmus Lundby (58485646300); Picinali, Lorenzo (34873422000); Kajs, Nynne (58486490300); Patou, François (57118358400)","58485646300; 34873422000; 58486490300; 57118358400","Virtual-Reality-Based Research in Hearing Science: A Platforming Approach","2023","AES: Journal of the Audio Engineering Society","71","6","","374","389","15","1","10.17743/jaes.2022.0083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164738104&doi=10.17743%2fjaes.2022.0083&partnerID=40&md5=a231adb543c7af9ec084a9503f5288d0","Oticon Medical, Research and Technology, Smørum, Denmark; Dyson School of Design Engineering, Imperial College London, United Kingdom","Pedersen R.L., Oticon Medical, Research and Technology, Smørum, Denmark; Picinali L., Dyson School of Design Engineering, Imperial College London, United Kingdom; Kajs N., Oticon Medical, Research and Technology, Smørum, Denmark; Patou F., Oticon Medical, Research and Technology, Smørum, Denmark","The lack of ecological validity in clinical assessment, as well as the challenge of investigating multimodal sensory processing, remain key challenges in hearing science. Virtual Reality (VR) can support hearing research in these domains by combining experimental control with situational realism. However, the development of VR-based experiments is traditionally highly resource demanding, which places a significant entry barrier for basic and clinical researchers looking to embrace VR as the research tool of choice. The Oticon Medical Virtual Reality (OMVR) experiment platform fast-tracks the creation or adaptation of hearing research experiment templates to be used to explore areas such as binaural spatial hearing, multimodal sensory integration, cognitive hearing behavioral strategies, auditory-visual training, etc. In this paper, the OMVR’s functionalities, architecture, and key elements of implementation are presented, important performance indicators are characterized, and a use-case perceptual evaluation is presented. © 2023 Audio Engineering Society. All rights reserved.","","","Audio Engineering Society","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85164738104"
"Massimi L.; Suaris T.; Hagen C.K.; Endrizzi M.; Munro P.R.T.; Havariyoun G.; Sam Hawker P.M.; Smit B.; Astolfo A.; Larkin O.J.; Waltham R.M.; Shah Z.; Duffy S.W.; Nelan R.L.; Peel A.; Louise Jones J.; Haig I.G.; Bate D.; Olivo A.","Massimi, Lorenzo (57202103494); Suaris, Tamara (55250225000); Hagen, Charlotte K. (55508570900); Endrizzi, Marco (35067989100); Munro, Peter R. T. (7102012051); Havariyoun, Glafkos (57190167318); Sam Hawker, P.M. (57759570700); Smit, Bennie (57209655445); Astolfo, Alberto (55985279700); Larkin, Oliver J. (25643167100); Waltham, Richard M. (57209660307); Shah, Zoheb (57209172784); Duffy, Stephen W. (35942266800); Nelan, Rachel L. (57196032647); Peel, Anthony (57209659888); Louise Jones, J. (56016708500); Haig, Ian G. (56024784800); Bate, David (56814761900); Olivo, Alessandro (7004072469)","57202103494; 55250225000; 55508570900; 35067989100; 7102012051; 57190167318; 57759570700; 57209655445; 55985279700; 25643167100; 57209660307; 57209172784; 35942266800; 57196032647; 57209659888; 56016708500; 56024784800; 56814761900; 7004072469","Volumetric High-Resolution X-Ray Phase-Contrast Virtual Histology of Breast Specimens With a Compact Laboratory System","2022","IEEE Transactions on Medical Imaging","41","5","","1188","1195","7","16","10.1109/TMI.2021.3137964","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122069772&doi=10.1109%2fTMI.2021.3137964&partnerID=40&md5=e2bc4ac034c0fbb819a344c23d81eb39","University College London, Department Of Medical Physics And Biomedical Engineering, London, WC1E 6BT, United Kingdom; St. Bartholomew's Hospital, Barts Health Nhs Trust, West Smithfields, London, E1 1BB, United Kingdom; Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Queen Mary University Of London, Barts And The London School Of Medicine And Dentistry, London, E1 4NS, United Kingdom","Massimi L., University College London, Department Of Medical Physics And Biomedical Engineering, London, WC1E 6BT, United Kingdom; Suaris T., St. Bartholomew's Hospital, Barts Health Nhs Trust, West Smithfields, London, E1 1BB, United Kingdom; Hagen C.K., University College London, Department Of Medical Physics And Biomedical Engineering, London, WC1E 6BT, United Kingdom; Endrizzi M., University College London, Department Of Medical Physics And Biomedical Engineering, London, WC1E 6BT, United Kingdom; Munro P.R.T., University College London, Department Of Medical Physics And Biomedical Engineering, London, WC1E 6BT, United Kingdom; Havariyoun G., University College London, Department Of Medical Physics And Biomedical Engineering, London, WC1E 6BT, United Kingdom; Sam Hawker P.M., Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Smit B., Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Astolfo A., Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Larkin O.J., Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Waltham R.M., Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Shah Z., Queen Mary University Of London, Barts And The London School Of Medicine And Dentistry, London, E1 4NS, United Kingdom; Duffy S.W., Queen Mary University Of London, Barts And The London School Of Medicine And Dentistry, London, E1 4NS, United Kingdom; Nelan R.L., Queen Mary University Of London, Barts And The London School Of Medicine And Dentistry, London, E1 4NS, United Kingdom; Peel A., St. Bartholomew's Hospital, Barts Health Nhs Trust, West Smithfields, London, E1 1BB, United Kingdom; Louise Jones J., St. Bartholomew's Hospital, Barts Health Nhs Trust, West Smithfields, London, E1 1BB, United Kingdom; Haig I.G., Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Bate D., Tring Business Centre, Tring Nikon X-Tek Systems, Hertfordshire, HP23 4JX, United Kingdom; Olivo A., University College London, Department Of Medical Physics And Biomedical Engineering, London, WC1E 6BT, United Kingdom","The assessment of margin involvement is a fundamental task in breast conserving surgery to prevent recurrences and reoperations. It is usually performed through histology, which makes the process time consuming and can prevent the complete volumetric analysis of large specimens. X-ray phase contrast tomography combines high resolution, sufficient penetration depth and high soft tissue contrast, and can therefore provide a potential solution to this problem. In this work, we used a high-resolution implementation of the edge illumination X-ray phase contrast tomography based on 'pixel-skipping' X-ray masks and sample dithering, to provide high definition virtual slices of breast specimens. The scanner was originally designed for intra-operative applications in which short scanning times were prioritised over spatial resolution; however, thanks to the versatility of edge illumination, high-resolution capabilities can be obtained with the same system simply by swapping X-ray masks without this imposing a reduction in the available field of view. This makes possible an improved visibility of fine tissue strands, enabling a direct comparison of selected CT slices with histology, and providing a tool to identify suspect features in large specimens before slicing. Combined with our previous results on fast specimen scanning, this works paves the way for the design of a multi-resolution EI scanner providing intra-operative capabilities as well as serving as a digital pathology system.  © 1982-2012 IEEE.","Breast conserving surgery; Multi-resolution imaging; X-ray phase contrast","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85122069772"
"Vickers D.; Salorio-Corbetto M.; Driver S.; Rocca C.; Levtov Y.; Sum K.; Parmar B.; Dritsakis G.; Albanell Flores J.; Jiang D.; Mahon M.; Early F.; Van Zalk N.; Picinali L.","Vickers, Deborah (7006164240); Salorio-Corbetto, Marina (56621436100); Driver, Sandra (36468296300); Rocca, Christine (54880029400); Levtov, Yuli (57225291746); Sum, Kevin (57472962800); Parmar, Bhavisha (57223686656); Dritsakis, Giorgos (56548957100); Albanell Flores, Jordi (57725200800); Jiang, Dan (7401574526); Mahon, Merle (8726278400); Early, Frances (57189273118); Van Zalk, Nejra (37111741300); Picinali, Lorenzo (34873422000)","7006164240; 56621436100; 36468296300; 54880029400; 57225291746; 57472962800; 57223686656; 56548957100; 57725200800; 7401574526; 8726278400; 57189273118; 37111741300; 34873422000","Involving Children and Teenagers With Bilateral Cochlear Implants in the Design of the BEARS (Both EARS) Virtual Reality Training Suite Improves Personalization","2021","Frontiers in Digital Health","3","","759723","","","","10","10.3389/fdgth.2021.759723","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131235680&doi=10.3389%2ffdgth.2021.759723&partnerID=40&md5=0232c9e7eea959c39f10e75550ce0dcf","Sound Laboratory, Cambridge Hearing Group, Clinical Neurosciences, University of Cambridge, Cambridge, United Kingdom; St Thomas' Hearing Implant Centre, Guys and St Thomas' NHS Foundation Trust, London, United Kingdom; Reactify Music, London, United Kingdom; Audio Experience Design, Dyson School of Design Engineering, Imperial College London, London, United Kingdom; Psychology and Language Sciences, Faculty of Brain Sciences, University College London, London, United Kingdom; Department of Respiratory Medicine, Cambridge University Hospital NHS Foundation Trust, Cambridge, United Kingdom; Design Psychology Lab, Dyson School of Design Engineering, Imperial College London, London, United Kingdom","Vickers D., Sound Laboratory, Cambridge Hearing Group, Clinical Neurosciences, University of Cambridge, Cambridge, United Kingdom; Salorio-Corbetto M., Sound Laboratory, Cambridge Hearing Group, Clinical Neurosciences, University of Cambridge, Cambridge, United Kingdom; Driver S., St Thomas' Hearing Implant Centre, Guys and St Thomas' NHS Foundation Trust, London, United Kingdom; Rocca C., St Thomas' Hearing Implant Centre, Guys and St Thomas' NHS Foundation Trust, London, United Kingdom; Levtov Y., Reactify Music, London, United Kingdom; Sum K., Audio Experience Design, Dyson School of Design Engineering, Imperial College London, London, United Kingdom; Parmar B., Sound Laboratory, Cambridge Hearing Group, Clinical Neurosciences, University of Cambridge, Cambridge, United Kingdom; Dritsakis G., Sound Laboratory, Cambridge Hearing Group, Clinical Neurosciences, University of Cambridge, Cambridge, United Kingdom; Albanell Flores J., Audio Experience Design, Dyson School of Design Engineering, Imperial College London, London, United Kingdom; Jiang D., St Thomas' Hearing Implant Centre, Guys and St Thomas' NHS Foundation Trust, London, United Kingdom; Mahon M., Psychology and Language Sciences, Faculty of Brain Sciences, University College London, London, United Kingdom; Early F., Department of Respiratory Medicine, Cambridge University Hospital NHS Foundation Trust, Cambridge, United Kingdom; Van Zalk N., Design Psychology Lab, Dyson School of Design Engineering, Imperial College London, London, United Kingdom; Picinali L., Audio Experience Design, Dyson School of Design Engineering, Imperial College London, London, United Kingdom","Older children and teenagers with bilateral cochlear implants often have poor spatial hearing because they cannot fuse sounds from the two ears. This deficit jeopardizes speech and language development, education, and social well-being. The lack of protocols for fitting bilateral cochlear implants and resources for spatial-hearing training contribute to these difficulties. Spatial hearing develops with bilateral experience. A large body of research demonstrates that sound localisation can improve with training, underpinned by plasticity-driven changes in the auditory pathways. Generalizing training to non-trained auditory skills is best achieved by using a multi-modal (audio-visual) implementation and multi-domain training tasks (localisation, speech-in-noise, and spatial music). The goal of this work was to develop a package of virtual-reality games (BEARS, Both EARS) to train spatial hearing in young people (8–16 years) with bilateral cochlear implants using an action-research protocol. The action research protocol used formalized cycles for participants to trial aspects of the BEARS suite, reflect on their experiences, and in turn inform changes in the game implementations. This participatory design used the stakeholder participants as co-creators. The cycles for each of the three domains (localisation, spatial speech-in-noise, and spatial music) were customized to focus on the elements that the stakeholder participants considered important. The participants agreed that the final games were appropriate and ready to be used by patients. The main areas of modification were: the variety of immersive scenarios to cover age range and interests, the number of levels of complexity to ensure small improvements were measurable, feedback, and reward schemes to ensure positive reinforcement, and an additional implementation on an iPad for those who had difficulties with the headsets due to age or balance issues. The effectiveness of the BEARS training suite will be evaluated in a large-scale clinical trial to determine if using the games lead to improvements in speech-in-noise, quality of life, perceived benefit, and cost utility. Such interventions allow patients to take control of their own management reducing the reliance on outpatient-based rehabilitation. For young people, a virtual-reality implementation is more engaging than traditional rehabilitation methods, and the participatory design used here has ensured that the BEARS games are relevant. Copyright © 2021 Vickers, Salorio-Corbetto, Driver, Rocca, Levtov, Sum, Parmar, Dritsakis, Albanell Flores, Jiang, Mahon, Early, Van Zalk and Picinali.","action research; bilateral; children; cochlear implant; participatory design; spatial hearing; training; virtual reality","","Frontiers Media SA","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85131235680"
"Morbidi F.; Devigne L.; Teodorescu C.S.; Fraudet B.; Leblong E.; Carlson T.; Babel M.; Caron G.; Delmas S.; Pasteau F.; Vailland G.; Gouranton V.; Guegan S.; Le Breton R.; Ragot N.","Morbidi, Fabio (16175741400); Devigne, Louise (57192422678); Teodorescu, Catalin Stefan (57220394025); Fraudet, Bastien (57188806683); Leblong, Emilie (55014460700); Carlson, Tom (56295883500); Babel, Marie (6701728589); Caron, Guillaume (35104609500); Delmas, Sarah (57222705729); Pasteau, Francois (35192186700); Vailland, Guillaume (57210641984); Gouranton, Valerie (6506588443); Guegan, Sylvain (12645414600); Le Breton, Ronan (51261265300); Ragot, Nicolas (57200906311)","16175741400; 57192422678; 57220394025; 57188806683; 55014460700; 56295883500; 6701728589; 35104609500; 57222705729; 35192186700; 57210641984; 6506588443; 12645414600; 51261265300; 57200906311","Assistive Robotic Technologies for Next-Generation Smart Wheelchairs: Codesign and Modularity to Improve Users' Quality of Life","2023","IEEE Robotics and Automation Magazine","30","1","","24","35","11","7","10.1109/MRA.2022.3178965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133752831&doi=10.1109%2fMRA.2022.3178965&partnerID=40&md5=507d94743bfd5ad3309cf5c2ae14b26c","University of Picardie Jules Verne, Modeling, Information, and Systems Laboratory, Amiens, 80039, France; Institut de Recherche en Informatique et Systèmes Aléatoires, Inria Rennes, Institut National des Sciences Appliquées de Rennes, Rainbow/Hybrid Teams, Rennes, 35700, France; University College London, Aspire Create, London, WC1E 6BT, United Kingdom; Royal National Orthopedic Hospital, London, HA7 4LP, United Kingdom; Pôle Saint-Hélier, Rennes, 35000, France; Ctr. Natl. de la Rech. Scientifique-National Institute of Advanced Industrial Science and Technology, Joint Robotics Laboratory, Tsukuba, 305-8560, Japan; University of Rennes, Institut National des Sciences Appliquées de Rennes, Laboratoire de Génie Civil et Génie Mécanique, Rennes, 35000, France; École Supérieure d'Ingénieurs en Génie Électrique, Institut de Recherche en Systèmes Électroniques Embarqués, Rouen, 76801, France","Morbidi F., University of Picardie Jules Verne, Modeling, Information, and Systems Laboratory, Amiens, 80039, France; Devigne L., Institut de Recherche en Informatique et Systèmes Aléatoires, Inria Rennes, Institut National des Sciences Appliquées de Rennes, Rainbow/Hybrid Teams, Rennes, 35700, France; Teodorescu C.S., University College London, Aspire Create, London, WC1E 6BT, United Kingdom, Royal National Orthopedic Hospital, London, HA7 4LP, United Kingdom; Fraudet B., Pôle Saint-Hélier, Rennes, 35000, France; Leblong E., Pôle Saint-Hélier, Rennes, 35000, France; Carlson T., University College London, Aspire Create, London, WC1E 6BT, United Kingdom, Royal National Orthopedic Hospital, London, HA7 4LP, United Kingdom; Babel M., University College London, Aspire Create, London, WC1E 6BT, United Kingdom; Caron G., University of Picardie Jules Verne, Modeling, Information, and Systems Laboratory, Amiens, 80039, France, Ctr. Natl. de la Rech. Scientifique-National Institute of Advanced Industrial Science and Technology, Joint Robotics Laboratory, Tsukuba, 305-8560, Japan; Delmas S., University of Picardie Jules Verne, Modeling, Information, and Systems Laboratory, Amiens, 80039, France; Pasteau F., University College London, Aspire Create, London, WC1E 6BT, United Kingdom; Vailland G., University College London, Aspire Create, London, WC1E 6BT, United Kingdom; Gouranton V., University College London, Aspire Create, London, WC1E 6BT, United Kingdom; Guegan S., University of Rennes, Institut National des Sciences Appliquées de Rennes, Laboratoire de Génie Civil et Génie Mécanique, Rennes, 35000, France; Le Breton R., University of Rennes, Institut National des Sciences Appliquées de Rennes, Laboratoire de Génie Civil et Génie Mécanique, Rennes, 35000, France; Ragot N., École Supérieure d'Ingénieurs en Génie Électrique, Institut de Recherche en Systèmes Électroniques Embarqués, Rouen, 76801, France","This article describes the robotic assistive technologies developed for users of electrically powered wheelchairs, within the framework of the European Union's Interreg ADAPT (Assistive Devices for Empowering Disabled People Through Robotic Technologies) project. In particular, special attention is devoted to the integration of advanced sensing modalities and the design of new shared control algorithms. In response to the clinical needs identified by our medical partners, two novel smart wheelchairs with complementary capabilities and a virtual reality (VR)-based wheelchair simulator have been developed. These systems have been validated via extensive experimental campaigns in France and the United Kingdom. © 1994-2011 IEEE.","","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85133752831"
"Górriz J.M.; Álvarez-Illán I.; Álvarez-Marquina A.; Arco J.E.; Atzmueller M.; Ballarini F.; Barakova E.; Bologna G.; Bonomini P.; Castellanos-Dominguez G.; Castillo-Barnes D.; Cho S.B.; Contreras R.; Cuadra J.M.; Domínguez E.; Domínguez-Mateos F.; Duro R.J.; Elizondo D.; Fernández-Caballero A.; Fernandez-Jover E.; Formoso M.A.; Gallego-Molina N.J.; Gamazo J.; González J.G.; Garcia-Rodriguez J.; Garre C.; Garrigós J.; Gómez-Rodellar A.; Gómez-Vilda P.; Graña M.; Guerrero-Rodriguez B.; Hendrikse S.C.F.; Jimenez-Mesa C.; Jodra-Chuan M.; Julian V.; Kotz G.; Kutt K.; Leming M.; de Lope J.; Macas B.; Marrero-Aguiar V.; Martinez J.J.; Martinez-Murcia F.J.; Martínez-Tomás R.; Mekyska J.; Nalepa G.J.; Novais P.; Orellana D.; Ortiz A.; Palacios-Alonso D.; Palma J.; Pereira A.; Pinacho-Davidson P.; Pinninghoff M.A.; Ponticorvo M.; Psarrou A.; Ramírez J.; Rincón M.; Rodellar-Biarge V.; Rodríguez-Rodríguez I.; Roelofsma P.H.M.P.; Santos J.; Salas-Gonzalez D.; Salcedo-Lagos P.; Segovia F.; Shoeibi A.; Silva M.; Simic D.; Suckling J.; Treur J.; Tsanas A.; Varela R.; Wang S.H.; Wang W.; Zhang Y.D.; Zhu H.; Zhu Z.; Ferrández-Vicente J.M.","Górriz, J.M. (7004736801); Álvarez-Illán, I. (58194965600); Álvarez-Marquina, A. (57211415379); Arco, J.E. (56461250900); Atzmueller, M. (10240403500); Ballarini, F. (58583880500); Barakova, E. (35614959800); Bologna, G. (7005522450); Bonomini, P. (6504634622); Castellanos-Dominguez, G. (25640642900); Castillo-Barnes, D. (57194785841); Cho, S.B. (7404884741); Contreras, R. (36466122600); Cuadra, J.M. (22949732800); Domínguez, E. (7103240379); Domínguez-Mateos, F. (57194827808); Duro, R.J. (7003592275); Elizondo, D. (6701557179); Fernández-Caballero, A. (6602230534); Fernandez-Jover, E. (23389210100); Formoso, M.A. (57220166971); Gallego-Molina, N.J. (57223766712); Gamazo, J. (57746011400); González, J. García (59094477600); Garcia-Rodriguez, J. (35872525800); Garre, C. (27867745700); Garrigós, J. (56407096900); Gómez-Rodellar, A. (57195322173); Gómez-Vilda, P. (6507800333); Graña, M. (7005388617); Guerrero-Rodriguez, B. (57746009700); Hendrikse, S.C.F. (57441687000); Jimenez-Mesa, C. (57212404681); Jodra-Chuan, M. (36903684100); Julian, V. (6602206677); Kotz, G. (55336272400); Kutt, K. (56208581800); Leming, M. (57203919652); de Lope, J. (55888684400); Macas, B. (58194939900); Marrero-Aguiar, V. (6504313281); Martinez, J.J. (35371781800); Martinez-Murcia, F.J. (55062058300); Martínez-Tomás, R. (55887969100); Mekyska, J. (35746344400); Nalepa, G.J. (55879229400); Novais, P. (8248071100); Orellana, D. (57219593272); Ortiz, A. (18434650900); Palacios-Alonso, D. (55887595400); Palma, J. (8714509100); Pereira, A. (58991065400); Pinacho-Davidson, P. (56242157800); Pinninghoff, M.A. (55667120700); Ponticorvo, M. (23006109400); Psarrou, A. (6603307034); Ramírez, J. (57191694395); Rincón, M. (57208825323); Rodellar-Biarge, V. (6603995438); Rodríguez-Rodríguez, I. (57196450973); Roelofsma, P.H.M.P. (6506958574); Santos, J. (56461552700); Salas-Gonzalez, D. (23101090600); Salcedo-Lagos, P. (56732895200); Segovia, F. (26424738700); Shoeibi, A. (57193554372); Silva, M. (57221746249); Simic, D. (35590678200); Suckling, J. (7004124496); Treur, J. (7006431708); Tsanas, A. (25930622500); Varela, R. (7006361569); Wang, S.H. (36544650700); Wang, W. (57237142600); Zhang, Y.D. (35786830100); Zhu, H. (57219777095); Zhu, Z. (57222179388); Ferrández-Vicente, J.M. (57226220661)","7004736801; 58194965600; 57211415379; 56461250900; 10240403500; 58583880500; 35614959800; 7005522450; 6504634622; 25640642900; 57194785841; 7404884741; 36466122600; 22949732800; 7103240379; 57194827808; 7003592275; 6701557179; 6602230534; 23389210100; 57220166971; 57223766712; 57746011400; 59094477600; 35872525800; 27867745700; 56407096900; 57195322173; 6507800333; 7005388617; 57746009700; 57441687000; 57212404681; 36903684100; 6602206677; 55336272400; 56208581800; 57203919652; 55888684400; 58194939900; 6504313281; 35371781800; 55062058300; 55887969100; 35746344400; 55879229400; 8248071100; 57219593272; 18434650900; 55887595400; 8714509100; 58991065400; 56242157800; 55667120700; 23006109400; 6603307034; 57191694395; 57208825323; 6603995438; 57196450973; 6506958574; 56461552700; 23101090600; 56732895200; 26424738700; 57193554372; 57221746249; 35590678200; 7004124496; 7006431708; 25930622500; 7006361569; 36544650700; 57237142600; 35786830100; 57219777095; 57222179388; 57226220661","Computational approaches to Explainable Artificial Intelligence: Advances in theory, applications and trends","2023","Information Fusion","100","","101945","","","","15","10.1016/j.inffus.2023.101945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166914338&doi=10.1016%2fj.inffus.2023.101945&partnerID=40&md5=a3a4fa082936e04744d376af77301df3","SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain; Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Department of Psychiatry, University of Cambridge, Cambridge, United Kingdom; Department of Communications Engineering, University of Malaga, Malaga, Spain; School of Computing and Mathematical Sciences, University of Leicester, Leicester, United Kingdom; Semantic Information Systems Group, Osnabrück University, Osnabrück, Germany; German Research Center for AI (DFKI), Osnabrück, Germany; Department of Electronics, Computer Technology and Projects, Universidad Politécnica de Cartagena, Cartagena, Spain; Valencian Research Institute for AI (VRAIN), Universitat Politècnica de València, València, Spain; Jagiellonian Human-Centered AI Laboratory (JAHCAI) and Institute of Applied Computer Science, Jagiellonian University, Kraków, Poland; Department of Information and Communication Engineering, University of Murcia, Murcia, Spain; Centre for Information and Communications Technology Research (CITIC), Department of Computer Science and Information Technologies, University of A Coruña, A Coruña, Spain; Department of Computer Science, University of Oviedo, Oviedo, Spain; Instituto Argentino de Matemática Alberto Calderón y Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina; Instituto Tecnológico de Buenos Aires (ITBA), Buenos Aires, Argentina; Eindhoven University of Technology, Eindhoven, 5612 AZ, Netherlands; Department of Computer Science, University of Malaga, Malaga, Spain; De Montfort University, Leicester, United Kingdom; Department of Computer Science, Faculty of Engineering, Universidad de Concepción, Concepción, Chile; Neurocognition and Emotion Research Unit, Albacete Research Institute of Informatics, University of Castilla-La Mancha, Albacete, Spain; Department of Educational Informatics, Universidad de Concepción, Concepción, Chile; Department of AI, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Department of Humanistic Studies, University of Naples Federico II, Napoli, Italy; Escuela Técnica Superior de Ingeniería Informática, Universidad Rey Juan Carlos, Campus de Móstoles, Móstoles, Madrid, 28933, Spain; Neuromorphic Speech Processing Lab, Center for Biomedical Technology, Universidad Politécnica de Madrid, Campus de Montegancedo, Pozuelo de Alarcón, Madrid, 28223, Spain; Biomedical Research Networking Center in Mental Health, Instituto de Salud Carlos III, Madrid, 28016, Spain; Usher Institute, Faculty of Medicine, University of Edinburgh, Edinburgh, United Kingdom; Instituto de Bioingeniería, Universidad Miguel Hernández, Elche, Alicante, Spain; Department of Computers Technology, University of Alicante, Alicante, Spain; Central University of Ecuador, Quito, Ecuador; Instituto de Ingeniería Biomédica, Fac. de Ingeniería, Universidad de Buenos Aires, Buenos Aires, Argentina; Department of Telecommunications, Brno University of Technology, Brno, 61600, Czech Republic; Department of Personality, Assessment and Clinical Psychology, Faculty of Education, Complutense University of Madrid, Madrid, 28040, Spain; Asociación Nuevo Horizonte, Las Rozas de Madrid, 28231, Spain; ALGORITMI Research Centre/LASI, University of Minho, Braga, Portugal; Facultad de Filología, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Facultad de Energía, Universidad Nacional de Loja, Loja, Ecuador; Computer Science and Communications Research Centre, School of Technology and Management, Polytechnic Institute of Leiria, Leiria, Portugal; University of Westminster, London, United Kingdom; Signal Processing and Recognition Group, Universidad Nacional de Colombia, Manizales, 170003, Colombia; University of Applied Sciences and Arts of Western Switzerland, Geneva, Switzerland; Department of CCIA, University of the Basque Country (UPV/EHU), Spain; Department of AI, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Madrid, 28660, Spain; Universidad Mayor de San Andrés, La Paz, Bolivia; University of Novi Sad, Novi Sad, 21102, Serbia; Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; Department of Computer Science, Yonsei University, Seoul, South Korea; Vrije Universiteit Amsterdam, Department of Clinical Psychology, Amsterdam, Netherlands; Vrije Universiteit Amsterdam, Department of Computer Science, Amsterdam, Netherlands; Erasmus MC, Rotterdam, Netherlands","Górriz J.M., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain, Department of Psychiatry, University of Cambridge, Cambridge, United Kingdom; Álvarez-Illán I., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Álvarez-Marquina A., Neuromorphic Speech Processing Lab, Center for Biomedical Technology, Universidad Politécnica de Madrid, Campus de Montegancedo, Pozuelo de Alarcón, Madrid, 28223, Spain; Arco J.E., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain, Department of Communications Engineering, University of Malaga, Malaga, Spain; Atzmueller M., Semantic Information Systems Group, Osnabrück University, Osnabrück, Germany, German Research Center for AI (DFKI), Osnabrück, Germany; Ballarini F., Instituto Tecnológico de Buenos Aires (ITBA), Buenos Aires, Argentina; Barakova E., Eindhoven University of Technology, Eindhoven, 5612 AZ, Netherlands; Bologna G., University of Applied Sciences and Arts of Western Switzerland, Geneva, Switzerland; Bonomini P., Department of Electronics, Computer Technology and Projects, Universidad Politécnica de Cartagena, Cartagena, Spain, Instituto Argentino de Matemática Alberto Calderón y Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina, Instituto Tecnológico de Buenos Aires (ITBA), Buenos Aires, Argentina, Instituto de Ingeniería Biomédica, Fac. de Ingeniería, Universidad de Buenos Aires, Buenos Aires, Argentina; Castellanos-Dominguez G., Signal Processing and Recognition Group, Universidad Nacional de Colombia, Manizales, 170003, Colombia; Castillo-Barnes D., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain, Department of Communications Engineering, University of Malaga, Malaga, Spain; Cho S.B., Department of Computer Science, Yonsei University, Seoul, South Korea; Contreras R., Department of Computer Science, Faculty of Engineering, Universidad de Concepción, Concepción, Chile; Cuadra J.M., Department of AI, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Domínguez E., Department of Computer Science, University of Malaga, Malaga, Spain; Domínguez-Mateos F., Escuela Técnica Superior de Ingeniería Informática, Universidad Rey Juan Carlos, Campus de Móstoles, Móstoles, Madrid, 28933, Spain; Duro R.J., Centre for Information and Communications Technology Research (CITIC), Department of Computer Science and Information Technologies, University of A Coruña, A Coruña, Spain; Elizondo D., De Montfort University, Leicester, United Kingdom; Fernández-Caballero A., Neurocognition and Emotion Research Unit, Albacete Research Institute of Informatics, University of Castilla-La Mancha, Albacete, Spain, Biomedical Research Networking Center in Mental Health, Instituto de Salud Carlos III, Madrid, 28016, Spain; Fernandez-Jover E., Instituto de Bioingeniería, Universidad Miguel Hernández, Elche, Alicante, Spain; Formoso M.A., Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain, Department of Communications Engineering, University of Malaga, Malaga, Spain; Gallego-Molina N.J., Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain, Department of Communications Engineering, University of Malaga, Malaga, Spain; Gamazo J., Department of AI, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; González J.G., Department of Computer Science, University of Malaga, Malaga, Spain; Garcia-Rodriguez J., Department of Computers Technology, University of Alicante, Alicante, Spain; Garre C., Escuela Técnica Superior de Ingeniería Informática, Universidad Rey Juan Carlos, Campus de Móstoles, Móstoles, Madrid, 28933, Spain; Garrigós J., Department of Electronics, Computer Technology and Projects, Universidad Politécnica de Cartagena, Cartagena, Spain; Gómez-Rodellar A., Neuromorphic Speech Processing Lab, Center for Biomedical Technology, Universidad Politécnica de Madrid, Campus de Montegancedo, Pozuelo de Alarcón, Madrid, 28223, Spain, Usher Institute, Faculty of Medicine, University of Edinburgh, Edinburgh, United Kingdom; Gómez-Vilda P., Escuela Técnica Superior de Ingeniería Informática, Universidad Rey Juan Carlos, Campus de Móstoles, Móstoles, Madrid, 28933, Spain, Neuromorphic Speech Processing Lab, Center for Biomedical Technology, Universidad Politécnica de Madrid, Campus de Montegancedo, Pozuelo de Alarcón, Madrid, 28223, Spain; Graña M., Department of CCIA, University of the Basque Country (UPV/EHU), Spain; Guerrero-Rodriguez B., Central University of Ecuador, Quito, Ecuador; Hendrikse S.C.F., Vrije Universiteit Amsterdam, Department of Clinical Psychology, Amsterdam, Netherlands; Jimenez-Mesa C., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Jodra-Chuan M., Department of Personality, Assessment and Clinical Psychology, Faculty of Education, Complutense University of Madrid, Madrid, 28040, Spain, Asociación Nuevo Horizonte, Las Rozas de Madrid, 28231, Spain; Julian V., Valencian Research Institute for AI (VRAIN), Universitat Politècnica de València, València, Spain; Kotz G., Department of Educational Informatics, Universidad de Concepción, Concepción, Chile; Kutt K., Jagiellonian Human-Centered AI Laboratory (JAHCAI) and Institute of Applied Computer Science, Jagiellonian University, Kraków, Poland; Leming M., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; de Lope J., Department of AI, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Madrid, 28660, Spain; Macas B., Department of Electronics, Computer Technology and Projects, Universidad Politécnica de Cartagena, Cartagena, Spain, Instituto Argentino de Matemática Alberto Calderón y Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina; Marrero-Aguiar V., Facultad de Filología, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Martinez J.J., Department of Electronics, Computer Technology and Projects, Universidad Politécnica de Cartagena, Cartagena, Spain; Martinez-Murcia F.J., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Martínez-Tomás R., Department of AI, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Mekyska J., Department of Telecommunications, Brno University of Technology, Brno, 61600, Czech Republic; Nalepa G.J., Jagiellonian Human-Centered AI Laboratory (JAHCAI) and Institute of Applied Computer Science, Jagiellonian University, Kraków, Poland; Novais P., ALGORITMI Research Centre/LASI, University of Minho, Braga, Portugal; Orellana D., Facultad de Energía, Universidad Nacional de Loja, Loja, Ecuador; Ortiz A., Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain, Department of Communications Engineering, University of Malaga, Malaga, Spain; Palacios-Alonso D., Escuela Técnica Superior de Ingeniería Informática, Universidad Rey Juan Carlos, Campus de Móstoles, Móstoles, Madrid, 28933, Spain, Neuromorphic Speech Processing Lab, Center for Biomedical Technology, Universidad Politécnica de Madrid, Campus de Montegancedo, Pozuelo de Alarcón, Madrid, 28223, Spain; Palma J., Department of Information and Communication Engineering, University of Murcia, Murcia, Spain; Pereira A., Computer Science and Communications Research Centre, School of Technology and Management, Polytechnic Institute of Leiria, Leiria, Portugal; Pinacho-Davidson P., Department of Computer Science, Faculty of Engineering, Universidad de Concepción, Concepción, Chile; Pinninghoff M.A., Department of Computer Science, Faculty of Engineering, Universidad de Concepción, Concepción, Chile; Ponticorvo M., Department of Humanistic Studies, University of Naples Federico II, Napoli, Italy; Psarrou A., University of Westminster, London, United Kingdom; Ramírez J., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Rincón M., Department of AI, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain; Rodellar-Biarge V., Neuromorphic Speech Processing Lab, Center for Biomedical Technology, Universidad Politécnica de Madrid, Campus de Montegancedo, Pozuelo de Alarcón, Madrid, 28223, Spain; Rodríguez-Rodríguez I., Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain, Department of Communications Engineering, University of Malaga, Malaga, Spain; Roelofsma P.H.M.P., Erasmus MC, Rotterdam, Netherlands; Santos J., Centre for Information and Communications Technology Research (CITIC), Department of Computer Science and Information Technologies, University of A Coruña, A Coruña, Spain; Salas-Gonzalez D., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Salcedo-Lagos P., Department of Educational Informatics, Universidad de Concepción, Concepción, Chile; Segovia F., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Shoeibi A., SiPBA at Data Science and Computational Intelligence Institute, University of Granada, Granada, Spain, Data Science and Computational Intelligence Institute (DaSCII), University of Granada, Granada, Spain; Silva M., Universidad Mayor de San Andrés, La Paz, Bolivia; Simic D., University of Novi Sad, Novi Sad, 21102, Serbia; Suckling J., Department of Psychiatry, University of Cambridge, Cambridge, United Kingdom; Treur J., Vrije Universiteit Amsterdam, Department of Computer Science, Amsterdam, Netherlands; Tsanas A., Usher Institute, Faculty of Medicine, University of Edinburgh, Edinburgh, United Kingdom; Varela R., Department of Computer Science, University of Oviedo, Oviedo, Spain; Wang S.H., School of Computing and Mathematical Sciences, University of Leicester, Leicester, United Kingdom; Wang W., School of Computing and Mathematical Sciences, University of Leicester, Leicester, United Kingdom; Zhang Y.D., School of Computing and Mathematical Sciences, University of Leicester, Leicester, United Kingdom; Zhu H., School of Computing and Mathematical Sciences, University of Leicester, Leicester, United Kingdom; Zhu Z., School of Computing and Mathematical Sciences, University of Leicester, Leicester, United Kingdom; Ferrández-Vicente J.M., Department of Electronics, Computer Technology and Projects, Universidad Politécnica de Cartagena, Cartagena, Spain, Neuromorphic Speech Processing Lab, Center for Biomedical Technology, Universidad Politécnica de Madrid, Campus de Montegancedo, Pozuelo de Alarcón, Madrid, 28223, Spain","Deep Learning (DL), a groundbreaking branch of Machine Learning (ML), has emerged as a driving force in both theoretical and applied Artificial Intelligence (AI). DL algorithms, rooted in complex and non-linear artificial neural systems, excel at extracting high-level features from data. DL has demonstrated human-level performance in real-world tasks, including clinical diagnostics, and has unlocked solutions to previously intractable problems in virtual agent design, robotics, genomics, neuroimaging, computer vision, and industrial automation. In this paper, the most relevant advances from the last few years in Artificial Intelligence (AI) and several applications to neuroscience, neuroimaging, computer vision, and robotics are presented, reviewed and discussed. In this way, we summarize the state-of-the-art in AI methods, models and applications within a collection of works presented at the 9th International Conference on the Interplay between Natural and Artificial Computation (IWINAC). The works presented in this paper are excellent examples of new scientific discoveries made in laboratories that have successfully transitioned to real-life applications. © 2023 The Author(s)","Biomedical applications; Computational approaches; Computer-aided diagnosis systems; Data science; Deep learning; Explainable Artificial Intelligence; Machine learning; Neuroscience; Robotics","","Elsevier B.V.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85166914338"
"Bini F.; Franzò M.; Maccaro A.; Piaggio D.; Pecchia L.; Marinozzi F.","Bini, Fabiano (23003587800); Franzò, Michela (57218352832); Maccaro, Alessia (57216878584); Piaggio, Davide (57194697624); Pecchia, Leandro (35746897300); Marinozzi, Franco (6602668385)","23003587800; 57218352832; 57216878584; 57194697624; 35746897300; 6602668385","Is medical device regulatory compliance growing as fast as extended reality to avoid misunderstandings in the future?","2023","Health and Technology","13","5","","831","842","11","3","10.1007/s12553-023-00775-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175793172&doi=10.1007%2fs12553-023-00775-x&partnerID=40&md5=e3e435f507a617ecbd5114b3d1ef5ae5","Department of Mechanical and Aerospace Engineering, Sapienza University of Rome, Rome, Italy; Department of Medico-Surgical Sciences and Biotechnologies, Sapienza University of Rome, Rome, Italy; School of Engineering, University of Warwick, Coventry, United Kingdom; Department of Engineering, Campus Bio-Medico of Rome, Rome, Italy","Bini F., Department of Mechanical and Aerospace Engineering, Sapienza University of Rome, Rome, Italy; Franzò M., Department of Medico-Surgical Sciences and Biotechnologies, Sapienza University of Rome, Rome, Italy; Maccaro A., School of Engineering, University of Warwick, Coventry, United Kingdom; Piaggio D., School of Engineering, University of Warwick, Coventry, United Kingdom; Pecchia L., School of Engineering, University of Warwick, Coventry, United Kingdom, Department of Engineering, Campus Bio-Medico of Rome, Rome, Italy; Marinozzi F., Department of Mechanical and Aerospace Engineering, Sapienza University of Rome, Rome, Italy","Purpose: European Extended Reality (XR) industry is expected to significantly increase by 2025 with an extreme impact on the Healthcare scenario. Considering that the transition period for the Medical Device Regulation 2017/745 (MDR 2017/745) will end in May 2024, purpose of this study is to assess whether the Medical Device Regulatory Compliance is ready to cope with the inclusion of XR and its possible social and economic impact in the world of medical device software (MDSW). Methods: XR publications patterns were evaluated since MDR 2017/745 release on different databases. European normative about MDSW are consulted, followed by the European Database of Medical Devices (EUDAMED). Results: The number of publications on XR have increased since 2017 and healthcare is the third highest-impacted subject area. Specific classes for software have been introduces in the European Nomenclature of Medical Devices (EMDN) and some XR applications have already been registered in EUDAMED classified as MDSW. Conclusions: XR will become intrinsic in everyday medical protocol and guidelines. The establishment of the IEEE Virtual Reality and Augmented Reality Working Group and the statement of VR for remoting surgery as a MDSW in MDCG 2019-11 are demonstration of the necessity of MD regulatory compliance in being able to keep up with the upcoming XR technologies. The Authors agree that the competent authorities should consider intervening in the European Regulative Compliance to cope with the revolution of Phygital in Healthcare and to regulate procedures involving the use of XR in medicine preventing future misunderstanding and criticalities especially for high risk situations. © 2023, The Author(s).","Extended reality; Health technology; Medical device regulation; Phygital; Regulatory framework","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85175793172"
"Bishop E.; Allington D.; Ringrose T.; Martin C.; Aldea A.; García-Jaramillo M.; León-Vargas F.; Leal Y.; Henao D.; Gómez A.M.","Bishop, Emma (57973076200); Allington, Daisy (57973503500); Ringrose, Tim (57458136400); Martin, Clare (55483434400); Aldea, Arantza (7004521107); García-Jaramillo, Maira (57201472821); León-Vargas, Fabian (54787902000); Leal, Yenny (36247354900); Henao, Diana (57208968680); Gómez, Ana Maria (58415134300)","57973076200; 57973503500; 57458136400; 55483434400; 7004521107; 57201472821; 54787902000; 36247354900; 57208968680; 58415134300","Design and Usability of an Avatar-Based Learning Program to Support Diabetes Education: Quality Improvement Study in Colombia","2023","Journal of Diabetes Science and Technology","17","5","","1142","1153","11","1","10.1177/19322968221136141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142364427&doi=10.1177%2f19322968221136141&partnerID=40&md5=f7e24c46f0cdb65e07c9befb9e06ab15","Cognitant Group, Oxford, United Kingdom; Faculty of Technology, Design and Environment, Oxford Brookes University, Oxford, United Kingdom; Faculty of Engineering, Universidad EAN, Bogotá, Colombia; Faculty of Mechanical, Electronic and Biomedical Engineering, Universidad Antonio Nariño, Bogotá, Colombia; Institut d’Investigació Biomèdica de Girona Dr. Josep Trueta, Girona, Spain; Endocrinology Unit, Hospital Universitario San Ignacio, Pontificia Universidad Javeriana, Bogotá, Colombia","Bishop E., Cognitant Group, Oxford, United Kingdom; Allington D., Cognitant Group, Oxford, United Kingdom; Ringrose T., Cognitant Group, Oxford, United Kingdom; Martin C., Faculty of Technology, Design and Environment, Oxford Brookes University, Oxford, United Kingdom; Aldea A., Faculty of Technology, Design and Environment, Oxford Brookes University, Oxford, United Kingdom; García-Jaramillo M., Faculty of Engineering, Universidad EAN, Bogotá, Colombia; León-Vargas F., Faculty of Mechanical, Electronic and Biomedical Engineering, Universidad Antonio Nariño, Bogotá, Colombia; Leal Y., Institut d’Investigació Biomèdica de Girona Dr. Josep Trueta, Girona, Spain; Henao D., Endocrinology Unit, Hospital Universitario San Ignacio, Pontificia Universidad Javeriana, Bogotá, Colombia; Gómez A.M., Endocrinology Unit, Hospital Universitario San Ignacio, Pontificia Universidad Javeriana, Bogotá, Colombia","Background: This quality improvement study, entitled Avatar-Based LEarning for Diabetes Optimal Control (ABLEDOC), explored the feasibility of delivering an educational program to people with diabetes in Colombia. The aim was to discover how this approach could be used to improve awareness and understanding of the condition, the effects of treatment, and strategies for effective management of blood-glucose control. Methods: Individuals with diabetes were recruited by Colombian endocrinologists to a human-centered study to codesign the educational program, using the Double Diamond model. Participants contributed to two phases. The first phase focused on gathering unmet educational needs and choice of curriculum. Three prototypes were developed as a result. During phase 2, a different group of participants engaged with the program for several weeks, before reporting back. Results: Thirty-six participants completed a Web survey during phase 1, and five were also interviewed by telephone. The majority (33 of 36; 91%) were receptive to the prospect of educational interventions and ranked the chosen topic of hypoglycemia highly. In phase 2, the three prototypes were tested by 17 participants, 10 of whom also gave feedback in focus groups. The response was overwhelmingly positive, with 16 of 17 (94%) stating they would use a program like this again. The 3D version was the most highly rated. Conclusions: Immersive, avatar-based programs, delivered through smartphone, have the potential to deliver educational information that is trusted, engaging, and useful. Future work includes expansion of the curriculum, evaluation with a larger group, and exploration of the prospective role of artificial intelligence in personalizing this form of educational intervention. © 2022 Diabetes Technology Society.","avatar; Colombia; diabetes management; education; human-centered design; virtual reality","","SAGE Publications Inc.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85142364427"
"Miller C.; Padmos R.M.; van der Kolk M.; Józsa T.I.; Samuels N.; Xue Y.; Payne S.J.; Hoekstra A.G.","Miller, Claire (57219640134); Padmos, Raymond M. (57190497667); van der Kolk, Max (57195069698); Józsa, Tamás I. (56419767600); Samuels, Noor (57190815303); Xue, Yidan (57218122825); Payne, Stephen J. (35729165200); Hoekstra, Alfons G. (7007050341)","57219640134; 57190497667; 57195069698; 56419767600; 57190815303; 57218122825; 35729165200; 7007050341","In silico trials for treatment of acute ischemic stroke: Design and implementation","2021","Computers in Biology and Medicine","137","","104802","","","","12","10.1016/j.compbiomed.2021.104802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114768839&doi=10.1016%2fj.compbiomed.2021.104802&partnerID=40&md5=02eb7b16c03eb237429ae4fd93ba1aa9","Computational Science Laboratory, Informatics Institute, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands; Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford OX1 3PJ, UK, United Kingdom; Department of Radiology and Nuclear Medicine, Department of Neurology, Department of Public Health, Erasmus MC, University Medical Center, Rotterdam, Netherlands","Miller C., Computational Science Laboratory, Informatics Institute, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands; Padmos R.M., Computational Science Laboratory, Informatics Institute, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands; van der Kolk M., Computational Science Laboratory, Informatics Institute, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands; Józsa T.I., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford OX1 3PJ, UK, United Kingdom; Samuels N., Department of Radiology and Nuclear Medicine, Department of Neurology, Department of Public Health, Erasmus MC, University Medical Center, Rotterdam, Netherlands; Xue Y., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford OX1 3PJ, UK, United Kingdom; Payne S.J., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Parks Road, Oxford OX1 3PJ, UK, United Kingdom; Hoekstra A.G., Computational Science Laboratory, Informatics Institute, Faculty of Science, University of Amsterdam, Science Park 904, Amsterdam, 1098 XH, Netherlands","An in silico trial simulates a disease and its corresponding therapies on a cohort of virtual patients to support the development and evaluation of medical devices, drugs, and treatment. In silico trials have the potential to refine, reduce cost, and partially replace current in vivo studies, namely clinical trials and animal testing. We present the design and implementation of an in silico trial for treatment of acute ischemic stroke. We propose an event-based modelling approach for the simulation of a disease and injury, where changes to the state of the system (the events) are assumed to be instantaneous. Using this approach we are able to combine a diverse set of models, spanning multiple time scales, to model acute ischemic stroke, treatment, and resulting brain tissue injury. The in silico trial is designed to be modular to aid development and reproducibility. It provides a comprehensive framework for application to any potential in silico trial. A statistical population model is used to generate cohorts of virtual patients. Patient functional outcomes are also predicted with a statistical model, using treatment and injury results and the patient's clinical parameters. We demonstrate the functionality of the event-based modelling approach and trial framework by running proof of concept in silico trials. The proof of concept trials simulate the same cohort of patients twice: once with successful treatment (successful recanalisation) and once with unsuccessful treatment (unsuccessful treatment). Ways to overcome some of the challenges and difficulties in setting up such an in silico trial are discussed, such as validation and computational limitations. © 2021 The Author(s)","Acute ischemic stroke; Computational biology; Event-based modelling; In silico clinical trial","","Elsevier Ltd","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85114768839"
"Ebbing J.; Wiklund P.N.; Akre O.; Carlsson S.; Olsson M.J.; Höijer J.; Heimer M.; Collins J.W.","Ebbing, Jan (25653800300); Wiklund, Peter N. (35303958500); Akre, Olof (6602199428); Carlsson, Stefan (8523702300); Olsson, Mats J. (35512724700); Höijer, Jonas (56446908700); Heimer, Maurice (57200326667); Collins, Justin W. (7404950765)","25653800300; 35303958500; 6602199428; 8523702300; 35512724700; 56446908700; 57200326667; 7404950765","Development and validation of non-guided bladder-neck and neurovascular-bundle dissection modules of the RobotiX-Mentor® full-procedure robotic-assisted radical prostatectomy virtual reality simulation","2021","International Journal of Medical Robotics and Computer Assisted Surgery","17","2","e2195","","","","10","10.1002/rcs.2195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096655638&doi=10.1002%2frcs.2195&partnerID=40&md5=d6d947dc16119ec2ca3a3f89960bfd6d","University Hospital Basel, Department of Urology, Basel, Switzerland; Karolinska University Hospital, Department of Urology, Stockholm, Sweden; Karolinska Institutet, Department of Molecular Medicine and Surgery (MMK), Stockholm, Sweden; Icahn School of Medicine at Mount Sinai, Department of Urology, New York, NY, United States; Karolinska Institutet, Unit of Biostatistics, Institute of Environmental Medicine (IMM), Stockholm, Sweden; Charité – University Hospital, Medical Department, Division of Nephrology, Berlin, Germany; University College London Hospital, London, United Kingdom","Ebbing J., University Hospital Basel, Department of Urology, Basel, Switzerland, Karolinska University Hospital, Department of Urology, Stockholm, Sweden; Wiklund P.N., Karolinska University Hospital, Department of Urology, Stockholm, Sweden, Karolinska Institutet, Department of Molecular Medicine and Surgery (MMK), Stockholm, Sweden, Icahn School of Medicine at Mount Sinai, Department of Urology, New York, NY, United States; Akre O., Karolinska University Hospital, Department of Urology, Stockholm, Sweden, Karolinska Institutet, Department of Molecular Medicine and Surgery (MMK), Stockholm, Sweden; Carlsson S., Karolinska University Hospital, Department of Urology, Stockholm, Sweden, Karolinska Institutet, Department of Molecular Medicine and Surgery (MMK), Stockholm, Sweden; Olsson M.J., Karolinska University Hospital, Department of Urology, Stockholm, Sweden; Höijer J., Karolinska Institutet, Unit of Biostatistics, Institute of Environmental Medicine (IMM), Stockholm, Sweden; Heimer M., University Hospital Basel, Department of Urology, Basel, Switzerland, Charité – University Hospital, Medical Department, Division of Nephrology, Berlin, Germany; Collins J.W., Karolinska Institutet, Department of Molecular Medicine and Surgery (MMK), Stockholm, Sweden, University College London Hospital, London, United Kingdom","Background: Full-procedure virtual reality (VR) simulator training in robotic-assisted radical prostatectomy (RARP) is a new tool in surgical education. Methods: Description of the development of a VR RARP simulation model, (RobotiX-Mentor®) including non-guided bladder neck (ngBND) and neurovascular bundle dissection (ngNVBD) modules, and assessment of face, content, and construct validation of the ngBND and ngNVBD modules by robotic surgeons with different experience levels. Results: Simulator and ngBND/ngNVBD modules were rated highly by all surgeons for realism and usability as training tool. In the ngBND-task construct, validation was not achieved in task-specific performance metrics. In the ngNVBD, task-specific performance of the expert/intermediately experienced surgeons was significantly better than that of novices. Conclusions: We proved face and content validity of simulator and both modules, and construct validity for generic metrics of the ngBND module and for generic and task-specific metrics of the ngNVBD module. © 2020 The Authors. The International Journal of Medical Robotics and Computer Assisted Surgery published by John Wiley & Sons Ltd.","education; prostate; robotic-assisted radical prostatectomy; simulator; training; validation; virtual reality","","John Wiley and Sons Ltd","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85096655638"
"Teng L.; Jeronimo K.; Wei T.; Nemitz M.P.; Lyu G.; Stokes A.A.","Teng, Lijun (57206149068); Jeronimo, Karina (56180949200); Wei, Tianqi (55844871500); Nemitz, Markus P. (57194517430); Lyu, Geng (57200559994); Stokes, Adam A (36792605700)","57206149068; 56180949200; 55844871500; 57194517430; 57200559994; 36792605700","Integrating soft sensor systems using conductive thread","2018","Journal of Micromechanics and Microengineering","28","5","054001","","","","9","10.1088/1361-6439/aaaca8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044218640&doi=10.1088%2f1361-6439%2faaaca8&partnerID=40&md5=58d9d0f4c9ba49deb6efd38ef29cda5d","School of Engineering, Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3LJ, United Kingdom; Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, Informatics Forum, 10 Crichton St, Edinburgh, EH8 9AB, United Kingdom; Department of Computer Science and Engineering, University of Michigan, 2260 Hayward St. BBB3737, Ann Arbor, 48109, MI, United States","Teng L., School of Engineering, Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3LJ, United Kingdom; Jeronimo K., School of Engineering, Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3LJ, United Kingdom; Wei T., School of Engineering, Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3LJ, United Kingdom, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, Informatics Forum, 10 Crichton St, Edinburgh, EH8 9AB, United Kingdom; Nemitz M.P., School of Engineering, Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3LJ, United Kingdom, Department of Computer Science and Engineering, University of Michigan, 2260 Hayward St. BBB3737, Ann Arbor, 48109, MI, United States; Lyu G., Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, Informatics Forum, 10 Crichton St, Edinburgh, EH8 9AB, United Kingdom; Stokes A.A., School of Engineering, Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3LJ, United Kingdom","We are part of a growing community of researchers who are developing a new class of soft machines. By using mechanically soft materials (MPa modulus) we can design systems which overcome the bulk-mechanical mismatches between soft biological systems and hard engineered components. To develop fully integrated soft machines - which include power, communications, and control sub-systems - the research community requires methods for interconnecting between soft and hard electronics. Sensors based upon eutectic gallium alloys in microfluidic channels can be used to measure normal and strain forces, but integrating these sensors into systems of heterogeneous Young's modulus is difficult due the complexity of finding a material which is electrically conductive, mechanically flexible, and stable over prolonged periods of time. Many existing gallium-based liquid alloy sensors are not mechanically or electrically robust, and have poor stability over time. We present the design and fabrication of a high-resolution pressure-sensor soft system that can transduce normal force into a digital output. In this soft system, which is built on a monolithic silicone substrate, a galinstan-based microfluidic pressure sensor is integrated with a flexible printed circuit board. We used conductive thread as the interconnect and found that this method alleviates problems arising due to the mechanical mismatch between conventional metal wires and soft or liquid materials. Conductive thread is low-cost, it is readily wetted by the liquid metal, it produces little bending moment into the microfluidic channel, and it can be connected directly onto the copper bond-pads of the flexible printed circuit board. We built a bridge-system to provide stable readings from the galinstan pressure sensor. This system gives linear measurement results between 500-3500 Pa of applied pressure. We anticipate that integrated systems of this type will find utility in soft-robotic systems as used for wearable technologies like virtual reality, or in soft-medical devices such as exoskeletal rehabilitation robots. © 2018 IOP Publishing Ltd.","conductive thread; sensors; soft robotics; soft systems; system integration; wearable technologies","","Institute of Physics Publishing","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85044218640"
"Dutta A.; Singh M.; Kumar K.; Ribera-Navarro A.N.; Santiago R.; Kaul R.P.; Patil S.; Kalaskar D.M.","Dutta, Abir (57204712739); Singh, Menaka (57202077579); Kumar, Kathryn (57214395462); Ribera-Navarro, Aida Neverro (58133591400); Santiago, Rodney (57209890737); Kaul, Ruchi Pathak (57211484979); Patil, Sanganagouda (58316697800); Kalaskar, Deepak M (24070966200)","57204712739; 57202077579; 57214395462; 58133591400; 57209890737; 57211484979; 58316697800; 24070966200","Accuracy of 3D printed spine models for pre-surgical planning of complex adolescent idiopathic scoliosis (AIS) in spinal surgeries: a case series","2023","Annals of 3D Printed Medicine","11","","100117","","","","1","10.1016/j.stlm.2023.100117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162082119&doi=10.1016%2fj.stlm.2023.100117&partnerID=40&md5=6b1d25d629bd64a84f6675271df9d255","UCL Institute of Orthopaedic & Musculoskeletal Science, Division of Surgery & Interventional Science, University College London, Royal National Orthopaedic Hospital, Stanmore, HA7 4LP, London, United Kingdom; Royal National Orthopaedic Hospital NHS Trust, Spinal Surgery Unit, Stanmore, HA7 4LP, London, United Kingdom; Department of Radiology, Royal National Orthopaedic Hospital, Stanmore, United Kingdom","Dutta A., UCL Institute of Orthopaedic & Musculoskeletal Science, Division of Surgery & Interventional Science, University College London, Royal National Orthopaedic Hospital, Stanmore, HA7 4LP, London, United Kingdom, Royal National Orthopaedic Hospital NHS Trust, Spinal Surgery Unit, Stanmore, HA7 4LP, London, United Kingdom; Singh M., UCL Institute of Orthopaedic & Musculoskeletal Science, Division of Surgery & Interventional Science, University College London, Royal National Orthopaedic Hospital, Stanmore, HA7 4LP, London, United Kingdom; Kumar K., UCL Institute of Orthopaedic & Musculoskeletal Science, Division of Surgery & Interventional Science, University College London, Royal National Orthopaedic Hospital, Stanmore, HA7 4LP, London, United Kingdom; Ribera-Navarro A.N., UCL Institute of Orthopaedic & Musculoskeletal Science, Division of Surgery & Interventional Science, University College London, Royal National Orthopaedic Hospital, Stanmore, HA7 4LP, London, United Kingdom; Santiago R., Department of Radiology, Royal National Orthopaedic Hospital, Stanmore, United Kingdom; Kaul R.P., UCL Institute of Orthopaedic & Musculoskeletal Science, Division of Surgery & Interventional Science, University College London, Royal National Orthopaedic Hospital, Stanmore, HA7 4LP, London, United Kingdom; Patil S., Royal National Orthopaedic Hospital NHS Trust, Spinal Surgery Unit, Stanmore, HA7 4LP, London, United Kingdom; Kalaskar D.M., UCL Institute of Orthopaedic & Musculoskeletal Science, Division of Surgery & Interventional Science, University College London, Royal National Orthopaedic Hospital, Stanmore, HA7 4LP, London, United Kingdom, Royal National Orthopaedic Hospital NHS Trust, Spinal Surgery Unit, Stanmore, HA7 4LP, London, United Kingdom","Adolescent idiopathic scoliosis (AIS) is a noticeable spinal deformity in both adult and adolescent population. In majority of the cases, the gold standard of treatment is surgical intervention. Technological advancements in medical imaging and 3D printing have revolutionised the surgical planning and intraoperative decision making for surgeons in spinal surgery. However, its applicability for planning complex spinal surgeries is poorly documented with human subjects. The objective of this study is to evaluate the accuracy of 3D printed models for complex spinal deformities based on Cobb angles between 40° to 95°.This is a retrospective cohort study where, five CT scans of the patients with AIS were segmented and 3D printed for evaluating the accuracy. Consideration was given to the Inter-patient and acquisition apparatus variability of the CT-scan dataset to understand the effect on trueness and accuracy of the developed CAD models. The developed anatomical models were re-scanned for analysing quantitative surface deviation to assess the accuracy of 3D printed spinal models. Results show that the average of the root mean square error (RMSE) between the 3DP models and virtual models developed using CT scan of mean surface deviations for the five 3d printed models was found to be 0.5±0.07 mm. Based on the RMSE, it can be concluded that 3D printing based workflow is accurate enough to be used for presurgical planning for complex adolescent spinal deformities. Image acquisition and post processing parameters, type of 3D printing technology plays key role in acquiring required accuracy for surgical applications. © 2023 The Author(s)","3D Printing; 3D Reconstruction; Additive manufacturing; Adolescent idiopathic scoliosis; Surgical planning","","Elsevier Inc.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85162082119"
"Beams R.; Brown E.; Cheng W.-C.; Joyner J.S.; Kim A.S.; Kontson K.; Amiras D.; Baeuerle T.; Greenleaf W.; Grossmann R.J.; Gupta A.; Hamilton C.; Hua H.; Huynh T.T.; Leuze C.; Murthi S.B.; Penczek J.; Silva J.; Spiegel B.; Varshney A.; Badano A.","Beams, Ryan (26427914500); Brown, Ellenor (57639012100); Cheng, Wei-Chung (8533815100); Joyner, Janell S. (57208710278); Kim, Andrea S. (57215650096); Kontson, Kimberly (55841179400); Amiras, Dimitri (15055323000); Baeuerle, Tassilo (57211197632); Greenleaf, Walter (6603992302); Grossmann, Rafael J. (57222220423); Gupta, Atul (57195528334); Hamilton, Christoffer (57640530800); Hua, Hong (7103212541); Huynh, Tran Tu (57639012300); Leuze, Christoph (54995657100); Murthi, Sarah B. (12792069400); Penczek, John (6602593957); Silva, Jennifer (35312081300); Spiegel, Brennan (7003350770); Varshney, Amitabh (7007155280); Badano, Aldo (7003552264)","26427914500; 57639012100; 8533815100; 57208710278; 57215650096; 55841179400; 15055323000; 57211197632; 6603992302; 57222220423; 57195528334; 57640530800; 7103212541; 57639012300; 54995657100; 12792069400; 6602593957; 35312081300; 7003350770; 7007155280; 7003552264","Evaluation Challenges for the Application of Extended Reality Devices in Medicine","2022","Journal of Digital Imaging","35","5","","1409","1418","9","21","10.1007/s10278-022-00622-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128828198&doi=10.1007%2fs10278-022-00622-x&partnerID=40&md5=7483f195a1df234c5f9ca2da53c31d20","Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States; Department of Imaging, Imperial College Healthcare NHS Trust, London, United Kingdom; CognifiSense, Inc., Sunnyvale, CA, United States; Stanford University Virtual Human Interaction Lab, Stanford University, Stanford, CA, United States; Northern Light Health, Brewer, ME, United States; Philips, Cambridge, MA, United States; Brainlab AG, Munich, Germany; James C. Wyant College of Optical Sciences, University of Arizona, Tucson, AZ, United States; OpticSurg Inc., Wilmington, DE, United States; Department of Radiology, Stanford University, Stanford, CA, United States; R Adams Cowley Shock Trauma Center, University of Maryland Baltimore, Baltimore, MD, United States; NIST, Boulder, CO, United States; University of Colorado, Boulder, CO, United States; SentiAR, Inc., St Louis, MT, United States; School of Medicine, Division of Pediatric Cardiology, Washington University, St Louis, MO, United States; Department of Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Department of Computer Science, University of Maryland, College Park, MD, United States","Beams R., Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States; Brown E., Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States; Cheng W.-C., Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States; Joyner J.S., Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States; Kim A.S., Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States; Kontson K., Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States; Amiras D., Department of Imaging, Imperial College Healthcare NHS Trust, London, United Kingdom; Baeuerle T., CognifiSense, Inc., Sunnyvale, CA, United States; Greenleaf W., Stanford University Virtual Human Interaction Lab, Stanford University, Stanford, CA, United States; Grossmann R.J., Northern Light Health, Brewer, ME, United States; Gupta A., Philips, Cambridge, MA, United States; Hamilton C., Brainlab AG, Munich, Germany; Hua H., James C. Wyant College of Optical Sciences, University of Arizona, Tucson, AZ, United States; Huynh T.T., OpticSurg Inc., Wilmington, DE, United States; Leuze C., Department of Radiology, Stanford University, Stanford, CA, United States; Murthi S.B., R Adams Cowley Shock Trauma Center, University of Maryland Baltimore, Baltimore, MD, United States; Penczek J., NIST, Boulder, CO, United States, University of Colorado, Boulder, CO, United States; Silva J., SentiAR, Inc., St Louis, MT, United States, School of Medicine, Division of Pediatric Cardiology, Washington University, St Louis, MO, United States; Spiegel B., Department of Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Varshney A., Department of Computer Science, University of Maryland, College Park, MD, United States; Badano A., Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, United States","Augmented and virtual reality devices are being actively investigated and implemented for a wide range of medical uses. However, significant gaps in the evaluation of these medical devices and applications hinder their regulatory evaluation. Addressing these gaps is critical to demonstrating the devices’ safety and effectiveness. We outline the key technical and clinical evaluation challenges discussed during the US Food and Drug Administration’s public workshop, “Medical Extended Reality: Toward Best Evaluation Practices for Virtual and Augmented Reality in Medicine” and future directions for evaluation method development. Evaluation challenges were categorized into several key technical and clinical areas. Finally, we highlight current efforts in the standards communities and illustrate connections between the evaluation challenges and the intended uses of the medical extended reality (MXR) devices. Participants concluded that additional research is needed to assess the safety and effectiveness of MXR devices across the use cases. © 2022, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.","Augmented reality; Image quality; Medical imaging; Virtual reality","","Institute for Ionics","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85128828198"
"Iqbal H.; Tatti F.; Rodriguez y Baena F.","Iqbal, Hisham (57226356654); Tatti, Fabio (57226860792); Rodriguez y Baena, Ferdinando (15132536100)","57226356654; 57226860792; 15132536100","Augmented reality in robotic assisted orthopaedic surgery: A pilot study","2021","Journal of Biomedical Informatics","120","","103841","","","","18","10.1016/j.jbi.2021.103841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111268768&doi=10.1016%2fj.jbi.2021.103841&partnerID=40&md5=4daf1e8c842a55c9b3c8705a8e532ed4","Mechatronics in Medicine Laboratory, Imperial College London, London, UK, United Kingdom","Iqbal H., Mechatronics in Medicine Laboratory, Imperial College London, London, UK, United Kingdom; Tatti F., Mechatronics in Medicine Laboratory, Imperial College London, London, UK, United Kingdom; Rodriguez y Baena F., Mechatronics in Medicine Laboratory, Imperial College London, London, UK, United Kingdom","Background: The research and development of augmented-reality (AR) technologies in surgical applications has seen an evolution of the traditional user-interfaces (UI) utilised by clinicians when conducting robot-assisted orthopaedic surgeries. The typical UI for such systems relies on surgeons managing 3D medical imaging data in the 2D space of a touchscreen monitor, located away from the operating site. Conversely, AR can provide a composite view overlaying the real surgical scene with co-located virtual holographic representations of medical data, leading to a more immersive and intuitive operator experience. Materials and Methods: This work explores the integration of AR within an orthopaedic setting by capturing and replicating the UI of an existing surgical robot within an AR head-mounted display worn by the clinician. The resulting mixed-reality workflow enabled users to simultaneously view the operating-site and real-time holographic operating informatics when carrying out a robot-assisted patellofemoral-arthroplasty (PFA). Ten surgeons were recruited to test the impact of the AR system on procedure completion time and operating surface roughness. Results and Discussion: The integration of AR did not appear to require subjects to significantly alter their surgical techniques, which was demonstrated by non-significant changes to the study's clinical metrics, with a statistically insignificant mean increase in operating time (+0.778 s, p = 0.488) and a statistically insignificant change in mean surface roughness (p = 0.274). Additionally, a post-operative survey indicated a positive consensus on the usability of the AR system without incurring noticeable physical distress such as eyestrain or fatigue. Conclusions: Overall, these study results demonstrated a successful integration of AR technologies within the framework of an existing robot-assisted surgical platform with no significant negative effects in two quantitative metrics of surgical performance, and a positive outcome relating to user-centric and ergonomic evaluation criteria. © 2021 Elsevier Inc.","Augmented Reality; Human-Machine Interfacing; Surgical Workflows","","Academic Press Inc.","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85111268768"
"Davies A.C.; Harris D.; Banks-Gatenby A.; Brass A.","Davies, Angela C. (57208076958); Harris, Diane (57214157215); Banks-Gatenby, Amanda (57209880172); Brass, Andy (7007146387)","57208076958; 57214157215; 57209880172; 7007146387","Problem-based learning in clinical bioinformatics education: Does it help to create communities of practice?","2019","PLoS Computational Biology","15","6","e1006746","","","","8","10.1371/journal.pcbi.1006746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068962817&doi=10.1371%2fjournal.pcbi.1006746&partnerID=40&md5=b0e09f2c6bb039b0e065b950913dd5f3","School of Health Sciences, Faculty of Biology Medicine and Health, The University of Manchester, Manchester, United Kingdom; Manchester Institute of Education, University of Manchester, Manchester, United Kingdom","Davies A.C., School of Health Sciences, Faculty of Biology Medicine and Health, The University of Manchester, Manchester, United Kingdom; Harris D., Manchester Institute of Education, University of Manchester, Manchester, United Kingdom; Banks-Gatenby A., Manchester Institute of Education, University of Manchester, Manchester, United Kingdom; Brass A., School of Health Sciences, Faculty of Biology Medicine and Health, The University of Manchester, Manchester, United Kingdom","We have now reached the genomics era within medicine; genomics is being used to personalise treatment, make diagnoses, prognoses, and predict adverse outcomes resulting from treatment with certain drugs. Genomic data is now abundant in healthcare, and the newly created profession of clinical bioinformaticians are responsible for its analysis. In the United Kingdom, clinical bioinformaticians are trained within a 3-year programme, integrating a work-based placement with a part-time Master’s degree. As this profession is still developing, trainees can feel isolated from their peers whom are located in other hospitals and can find it difficult to gain the mentorship that they require to complete their training. Building strong networks or communities of practice (CoPs) and allowing sharing of knowledge and experiences is one solution to addressing this isolation. Within the Master’s delivered at the University of Manchester, we have integrated group-centred problem-based learning (PBL) using real clinical case studies worked on during each course unit. This approach is combined with a flipped style of teaching providing access to online content in our Virtual Learning Environment before the course. The face-to-face teaching is used to focus on the application of the students’ knowledge to clinical case studies. In this study, we conducted semistructured interviews with 8 students, spanning 3 cohorts of students. We evaluated the effectiveness of this style of teaching and whether it had contributed to the formation of CoPs between our students. Our findings demonstrated that this style of teaching was preferred by our students to a more traditional lecture-based format and that the problem-based learning approach enabled the formation of CoPs within these cohorts. These CoPs are valuable in the development of this new profession and assist with the production of new guidelines and policies that are helping to professionalise this new group of healthcare scientists. © 2019 Davies et al.","","","Public Library of Science","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85068962817"
"Kasztelnik M.; Coto E.; Bubak M.; Malawski M.; Nowakowski P.; Arenas J.; Saglimbeni A.; Testi D.; Frangi A.F.","Kasztelnik, Marek (24474623200); Coto, Ernesto (58444452400); Bubak, Marian (56214344100); Malawski, Maciej (22433325400); Nowakowski, Piotr (24475061000); Arenas, Juan (57194333795); Saglimbeni, Alfredo (57191243730); Testi, Debora (6701897246); Frangi, Alejandro F. (7005249248)","24474623200; 58444452400; 56214344100; 22433325400; 24475061000; 57194333795; 57191243730; 6701897246; 7005249248","Support for Taverna workflows in the VPH-Share cloud platform","2017","Computer Methods and Programs in Biomedicine","146","","","37","46","9","6","10.1016/j.cmpb.2017.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019653165&doi=10.1016%2fj.cmpb.2017.05.006&partnerID=40&md5=3a31638af923854083c96b071b86129d","ACC Cyfronet AGH, Krakow, Poland; Centre for Computational Imaging & Simulation Technologies in Biomedicine (CISTIB), Electronic and Electrical Engineering Department, The University of Sheffield, Sheffield, United Kingdom; Department of Computer Science, AGH University of Science and Technology, Krakow, Poland; CINECA SuperComputing Centre, Casalecchio di Reno, Italy","Kasztelnik M., ACC Cyfronet AGH, Krakow, Poland; Coto E., Centre for Computational Imaging & Simulation Technologies in Biomedicine (CISTIB), Electronic and Electrical Engineering Department, The University of Sheffield, Sheffield, United Kingdom; Bubak M., ACC Cyfronet AGH, Krakow, Poland, Department of Computer Science, AGH University of Science and Technology, Krakow, Poland; Malawski M., ACC Cyfronet AGH, Krakow, Poland, Department of Computer Science, AGH University of Science and Technology, Krakow, Poland; Nowakowski P., ACC Cyfronet AGH, Krakow, Poland; Arenas J., Centre for Computational Imaging & Simulation Technologies in Biomedicine (CISTIB), Electronic and Electrical Engineering Department, The University of Sheffield, Sheffield, United Kingdom; Saglimbeni A., CINECA SuperComputing Centre, Casalecchio di Reno, Italy; Testi D., CINECA SuperComputing Centre, Casalecchio di Reno, Italy; Frangi A.F., Centre for Computational Imaging & Simulation Technologies in Biomedicine (CISTIB), Electronic and Electrical Engineering Department, The University of Sheffield, Sheffield, United Kingdom","Background and objective: To address the increasing need for collaborative endeavours within the Virtual Physiological Human (VPH) community, the VPH-Share collaborative cloud platform allows researchers to expose and share sequences of complex biomedical processing tasks in the form of computational workflows. The Taverna Workflow System is a very popular tool for orchestrating complex biomedical & bioinformatics processing tasks in the VPH community. This paper describes the VPH-Share components that support the building and execution of Taverna workflows, and explains how they interact with other VPH-Share components to improve the capabilities of the VPH-Share platform. Methods: Taverna workflow support is delivered by the Atmosphere cloud management platform and the VPH-Share Taverna plugin. These components are explained in detail, along with the two main procedures that were developed to enable this seamless integration: workflow composition and execution. Results: 1) Seamless integration of VPH-Share with other components and systems. 2) Extended range of different tools for workflows. 3) Successful integration of scientific workflows from other VPH projects. 4) Execution speed improvement for medical applications. Conclusion: The presented workflow integration provides VPH-Share users with a wide range of different possibilities to compose and execute workflows, such as desktop or online composition, online batch execution, multithreading, remote execution, etc. The specific advantages of each supported tool are presented, as are the roles of Atmosphere and the VPH-Share plugin within the VPH-Share project. The combination of the VPH-Share plugin and Atmosphere engenders the VPH-Share infrastructure with far more flexible, powerful and usable capabilities for the VPH-Share community. As both components can continue to evolve and improve independently, we acknowledge that further improvements are still to be developed and will be described. © 2017 Elsevier B.V.","Atmosphere cloud; RESTful API; Taverna workflow; VPH-Share","","Elsevier Ireland Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85019653165"
"Dagnino G.; Georgilas I.; Köhler P.; Morad S.; Atkins R.; Dogramadzi S.","Dagnino, Giulio (56445301900); Georgilas, Ioannis (55851947284); Köhler, Paul (57189443251); Morad, Samir (56650793100); Atkins, Roger (56911861900); Dogramadzi, Sanja (6507900733)","56445301900; 55851947284; 57189443251; 56650793100; 56911861900; 6507900733","Navigation system for robot-assisted intra-articular lower-limb fracture surgery","2016","International Journal of Computer Assisted Radiology and Surgery","11","10","","1831","1843","12","43","10.1007/s11548-016-1418-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970967302&doi=10.1007%2fs11548-016-1418-z&partnerID=40&md5=6ee65328c356cc5f262b8f336ae8f886","Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom; Bristol Royal Infirmary, Upper Maudlin Street, Bristol, BS2 8HW, United Kingdom","Dagnino G., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom; Georgilas I., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom; Köhler P., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom; Morad S., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom; Atkins R., Bristol Royal Infirmary, Upper Maudlin Street, Bristol, BS2 8HW, United Kingdom; Dogramadzi S., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom","Purpose: In the surgical treatment for lower-leg intra-articular fractures, the fragments have to be positioned and aligned to reconstruct the fractured bone as precisely as possible, to allow the joint to function correctly again. Standard procedures use 2D radiographs to estimate the desired reduction position of bone fragments. However, optimal correction in a 3D space requires 3D imaging. This paper introduces a new navigation system that uses pre-operative planning based on 3D CT data and intra-operative 3D guidance to virtually reduce lower-limb intra-articular fractures. Physical reduction in the fractures is then performed by our robotic system based on the virtual reduction. Methods: 3D models of bone fragments are segmented from CT scan. Fragments are pre-operatively visualized on the screen and virtually manipulated by the surgeon through a dedicated GUI to achieve the virtual reduction in the fracture. Intra-operatively, the actual position of the bone fragments is provided by an optical tracker enabling real-time 3D guidance. The motion commands for the robot connected to the bone fragment are generated, and the fracture physically reduced based on the surgeon’s virtual reduction. To test the system, four femur models were fractured to obtain four different distal femur fracture types. Each one of them was subsequently reduced 20 times by a surgeon using our system. Results: The navigation system allowed an orthopaedic surgeon to virtually reduce the fracture with a maximum residual positioning error of 0.95±0.3mm (translational) and 1. 4 ∘± 0. 5 ∘ (rotational). Correspondent physical reductions resulted in an accuracy of 1.03 ± 0.2 mm and 1. 56 ∘± 0. 1 ∘, when the robot reduced the fracture. Conclusions: Experimental outcome demonstrates the accuracy and effectiveness of the proposed navigation system, presenting a fracture reduction accuracy of about 1 mm and 1. 5 ∘, and meeting the clinical requirements for distal femur fracture reduction procedures. © 2016, The Author(s).","3D medical imaging; Computer-assisted surgery; Fracture reduction planning; Fracture surgery; Image guidance; Medical robotics","","Springer Verlag","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84970967302"
"AboMoslim M.; Babili A.; Ghaseminejad-Tafreshi N.; Manson M.; Fattah F.; El Joueidi S.; Staples J.A.; Tam P.; Lester R.T.","AboMoslim, Maryam (57762771300); Babili, Abdulaa (57220191650); Ghaseminejad-Tafreshi, Niloufar (57217026930); Manson, Matthew (57981160600); Fattah, Fanan (57981822200); El Joueidi, Samia (57210794524); Staples, John A. (55123300200); Tam, Penny (40262677200); Lester, Richard T. (15051914100)","57762771300; 57220191650; 57217026930; 57981160600; 57981822200; 57210794524; 55123300200; 40262677200; 15051914100","Mobile phone access and preferences among medical inpatients at an urban Canadian hospital for post-discharge planning: A pre-COVID-19 cross-sectional survey","2022","Frontiers in Digital Health","4","","928602","","","","0","10.3389/fdgth.2022.928602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142652575&doi=10.3389%2ffdgth.2022.928602&partnerID=40&md5=081ed5a84882f9225e5c0257164f7ce0","Division of Infectious Disease, Faculty of Medicine, University of British Columbia, Vancouver, BC, Canada; Faculty of Public Health and Policy, London School of Hygiene & Tropical Medicine, London, United Kingdom; Division of Vancouver Costal Health Research Institutute, Centre for Clinical Epidemiology & Evaluation, Vancouver, BC, Canada; Division of General Internal Medicine, Department of Medicine, University of British Columbia, Vancouver, BC, Canada","AboMoslim M., Division of Infectious Disease, Faculty of Medicine, University of British Columbia, Vancouver, BC, Canada; Babili A., Faculty of Public Health and Policy, London School of Hygiene & Tropical Medicine, London, United Kingdom; Ghaseminejad-Tafreshi N., Division of Infectious Disease, Faculty of Medicine, University of British Columbia, Vancouver, BC, Canada; Manson M., Division of Infectious Disease, Faculty of Medicine, University of British Columbia, Vancouver, BC, Canada; Fattah F., Division of Infectious Disease, Faculty of Medicine, University of British Columbia, Vancouver, BC, Canada; El Joueidi S., Division of Infectious Disease, Faculty of Medicine, University of British Columbia, Vancouver, BC, Canada; Staples J.A., Division of Vancouver Costal Health Research Institutute, Centre for Clinical Epidemiology & Evaluation, Vancouver, BC, Canada, Division of General Internal Medicine, Department of Medicine, University of British Columbia, Vancouver, BC, Canada; Tam P., Division of General Internal Medicine, Department of Medicine, University of British Columbia, Vancouver, BC, Canada; Lester R.T., Division of Infectious Disease, Faculty of Medicine, University of British Columbia, Vancouver, BC, Canada","Background: Digital health interventions are increasingly used for patient care, yet little data is available on the phone access type and usage preferences amongst medical ward inpatients to inform the most appropriate digital interventions post-discharge. Methods: To identify mobile phone ownership, internet access, and cellular use preferences among medical inpatients, we conducted a researcher-administered survey of patients admitted to five internal medicine units at Vancouver General Hospital (VGH) in January 2020. The survey was administered over 2 days separated by a 2-week period. Results: A total of 81 inpatients completed the questionnaire. Survey found that 85.2% of survey respondents had mobile phone access where 63.0% owned their own mobile phone, and 22.2% had access to a mobile phone via a proxy (or an authorized third-party) such as a family member. All participants with mobile phone access had cellular plans (i.e., phone and text); however, a quarter of respondents did not have data plans with internet access. Survey showed that 71.1% of males owned a mobile phone compared to only 52.8% of females. All participants at a “high” risk of readmission had access to a mobile phone, either as phone-owners or proxy-dependent users. Conclusion: Access to mobile phones among medical ward inpatients, 85.2%, was comparable to smartphone penetration rates amongst Canadians in 2019, 85.1%. More patients had cellular than data plans (i.e., internet and applications). Understanding patient-specific access is key to informing potential uptake of digital health interventions aimed at using patients' mobile phones (mHealth) from an effectiveness and equity lens. 2022 AboMoslim, Babili, Ghaseminejad-Tafreshi, Manson, Fattah, El Joueidi, Staples, Tam and Lester.","digital health; health services planning; hospital readmission; mHealth; mobile phone penetration; patient engagement; virtual care","","Frontiers Media S.A.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142652575"
"Evans S.L.; Keenan B.E.; Hill J.; Zappala S.; Bennion N.; Avril S.","Evans, S.L. (9244387900); Keenan, B.E. (56222155500); Hill, J. (58637019400); Zappala, S. (57193410714); Bennion, N. (57207794386); Avril, S. (6602427519)","9244387900; 56222155500; 58637019400; 57193410714; 57207794386; 6602427519","Rapid, non-invasive, in vivo measurement of tissue mechanical properties using gravitational loading and a nonlinear virtual fields method","2023","Journal of the Royal Society Interface","20","207","20230384","","","","0","10.1098/rsif.2023.0384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173606807&doi=10.1098%2frsif.2023.0384&partnerID=40&md5=a3b82c9ee3ac4e56cd88d0c02a8b0500","School of Engineering, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom; School of Computer Science, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom; Mines Saint-Étienne, Univ Lyon, Univ Jean Monnet, INSERM, U 1059 Sainbiose, Saint-Étienne, 42023, France","Evans S.L., School of Engineering, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom; Keenan B.E., School of Engineering, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom; Hill J., School of Engineering, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom; Zappala S., School of Engineering, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom, School of Computer Science, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom; Bennion N., School of Engineering, Cardiff University, The Parade, Cardiff, CF24 3AA, United Kingdom; Avril S., Mines Saint-Étienne, Univ Lyon, Univ Jean Monnet, INSERM, U 1059 Sainbiose, Saint-Étienne, 42023, France","Measuring the mechanical properties of soft tissues in vivo is important in biomechanics and for diagnosis and staging of diseases, but challenging because it is difficult to control the boundary conditions. We present a novel, non-invasive method for measuring tissue properties using gravitational loading. MRI images of an organ in different positions are registered to measure tissue displacements due to gravitational forces in different positions. Considering equilibrium between stresses and gravity, we established a nonlinear virtual fields method to identify the tissue properties. The method was applied to the human brain as a proof of concept, using an Ogden model. Sensitivity analysis showed that the bulk modulus could be identified accurately while the shear modulus was identified with greater uncertainty; the strains were too small to identify the strain stiffening exponent. The measured properties agreed well with published in vitro data. The technique offers very promising perspectives, allowing the non-invasive measurement of otherwise inaccessible tissues and providing new information such as the bulk modulus under static loading, which has never previously been measured in vivo. © 2023 The Authors.","brain; mechanical properties; virtual fields","","Royal Society Publishing","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85173606807"
"Sibrina D.; Bethapudi S.; Koulieris G.A.","Sibrina, David (57222232683); Bethapudi, Sarath (55652453600); Koulieris, George Alex (55556245000)","57222232683; 55652453600; 55556245000","OrthopedVR: clinical assessment and pre-operative planning of paediatric patients with lower limb rotational abnormalities in virtual reality","2023","Visual Computer","39","8","","3621","3633","12","1","10.1007/s00371-023-02949-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163692565&doi=10.1007%2fs00371-023-02949-0&partnerID=40&md5=a2edfffb81869e7480797831702f5700","Durham University, Durham, United Kingdom; University Hospital of North Durham, Durham, United Kingdom","Sibrina D., Durham University, Durham, United Kingdom; Bethapudi S., University Hospital of North Durham, Durham, United Kingdom; Koulieris G.A., Durham University, Durham, United Kingdom","Rotational abnormalities in the lower limbs causing patellar mal-tracking negatively affect patients’ lives, particularly young patients (10–17 years old). Recent studies suggest that rotational abnormalities can increase degenerative effects on the joints of the lower limbs. Rotational abnormalities are diagnosed using 2D CT imaging and X-rays, and these data are then used by surgeons to make decisions during an operation. However, 3D representation of data is preferable in the examination of 3D structures, such as bones. This correlates with added benefits for medical judgement, pre-operative planning, and clinical training. Virtual reality can enable the transformation of standard clinical imaging examination methods (CT/MRI) into immersive examinations and pre-operative planning in 3D. We present a VR system (OrthopedVR) which allows orthopaedic surgeons to examine patients’ specific anatomy of the lower limbs in an immersive three-dimensional environment and to simulate the effect of potential surgical interventions such as corrective osteotomies in VR. In OrthopedVR, surgeons can perform corrective incisions and re-align segments into desired rotational angles. From the system evaluation performed by experienced surgeons we found that OrthopedVR provides a better understanding of lower limb alignment and rotational profiles in comparison with isolated 2D CT scans. In addition, it was demonstrated that using VR software improves pre-operative planning, surgical precision and post-operative outcomes for patients. Our study results indicate that our system can become a stepping stone into simulating corrective surgeries of the lower limbs, and suggest future improvements which will help adopt VR surgical planning into the clinical orthopaedic practice. © 2023, The Author(s).","Decision-making; Surgical planning; Virtual collaborative osteotomies; Virtual reality; VR collaborative environment","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85163692565"
"Connolly A.; Williams S.; Rhode K.; Rinaldi C.A.; Bishop M.J.","Connolly, Adam (56379722800); Williams, Steven (55520636500); Rhode, Kawal (9245867600); Rinaldi, Christopher A. (57217533072); Bishop, Martin J. (26664065700)","56379722800; 55520636500; 9245867600; 57217533072; 26664065700","Conceptual intra-cardiac electrode configurations that facilitate directional cardiac stimulation for optimal electrotherapy","2019","IEEE Transactions on Biomedical Engineering","66","5","8470986","1259","1268","9","5","10.1109/TBME.2018.2871863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054283451&doi=10.1109%2fTBME.2018.2871863&partnerID=40&md5=5ab88bc069a8aaa13bc67bd7191000e6","Department of Biomedical Engineering, School of Imaging Sciences and Biomedical Engineering, King's College London, London, WC2R 2LS, United Kingdom","Connolly A., Department of Biomedical Engineering, School of Imaging Sciences and Biomedical Engineering, King's College London, London, WC2R 2LS, United Kingdom; Williams S., Department of Biomedical Engineering, School of Imaging Sciences and Biomedical Engineering, King's College London, London, WC2R 2LS, United Kingdom; Rhode K., Department of Biomedical Engineering, School of Imaging Sciences and Biomedical Engineering, King's College London, London, WC2R 2LS, United Kingdom; Rinaldi C.A., Department of Biomedical Engineering, School of Imaging Sciences and Biomedical Engineering, King's College London, London, WC2R 2LS, United Kingdom; Bishop M.J., Department of Biomedical Engineering, School of Imaging Sciences and Biomedical Engineering, King's College London, London, WC2R 2LS, United Kingdom","Objective: Electrotherapy remains the most effective direct therapy against lethal cardiac arrhythmias. When an arrhythmic event is sensed, either strong electric shocks or controlled rapid pacing is automatically applied directly to the heart via an implanted cardioverter defibrillator (ICDs). Despite their success, ICDs remain a highly non-optimal therapy: The strong shocks required for defibrillation cause significant extra-cardiac stimulation, resulting in pain and long-term tissue damage, and can also limit battery life. When used in anti-tachycardia pacing mode, ICDs are also often ineffective, as the pacing electrode can be far away from the centre of the arrhythmia, making it hard for the paced wave to interrupt and terminate it. Methods: In this paper, we present two conceptual intra-cardiac directional electrode configurations in silico based on novel arrangements of pairs of positive-negative electrodes. Both configurations have the potential to cause preferential excitation on specific regions of the heart. Results: We demonstrate how the properties of the induced field varies spatially around the electrodes and how it depends upon the specific arrangements of dipole electrode pairs. The results show that when tested within anatomically-realistic rabbit ventricular models, both electrode configurations produce strong virtual electrodes on the targeted endocardial surfaces, with weaker virtual electrodes produced elsewhere. Conclusions: The proposed electrode configurations may facilitate targeted far-field anti-tachycardia pacing and/or defibrillation, which may be useful in cases where conventional anti-tachycardia pacing fails. In addition, the conceptual electrode designs intrinsically confine the electric field to the immediate vicinity of the electrodes, and may, thus, minimize pain due to unnecessary extra-cardiac stimulation. © 1964-2012 IEEE.","Anti-tachycardia pacing; Bidomain; Computational modelling; Defibrillation","","IEEE Computer Society","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85054283451"
"Burge T.A.; Jeffers J.R.T.; Myant C.W.","Burge, Thomas A. (57561650200); Jeffers, Jonathan R. T. (8686421500); Myant, Connor W. (26634376000)","57561650200; 8686421500; 26634376000","A computational design of experiments based method for evaluation of off-the-shelf total knee replacement implants","2023","Computer Methods in Biomechanics and Biomedical Engineering","26","6","","629","638","9","1","10.1080/10255842.2022.2075224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132614055&doi=10.1080%2f10255842.2022.2075224&partnerID=40&md5=28fa76611d30916bc487c0613d46d2c3","Dyson School of Design Engineering, Imperial College, London, United Kingdom; Department of Mechanical Engineering, Imperial College, London, United Kingdom","Burge T.A., Dyson School of Design Engineering, Imperial College, London, United Kingdom; Jeffers J.R.T., Department of Mechanical Engineering, Imperial College, London, United Kingdom; Myant C.W., Dyson School of Design Engineering, Imperial College, London, United Kingdom","A methodology to explore the design space of off-the-shelf total knee replacement implant designs is outlined. Generic femur component and tibia plate designs were scaled to thousands of sizes and virtually fitted to 244 test subjects. Various implant designs and sizing requirements between genders and ethnicities were evaluated. 5 sizes optimised via the methodology produced a good global fit for most subjects. However, clinically significant over/underhang was present in 19% of subjects for tibia plates and 25% for femur components, reducing to 11/20% with 8 sizes. The analysis highlighted subtly better fit performance was obtained using sizes with unequal spacing. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","design of experiments; Total knee replacement; virtual assessment of medical devices","","Taylor and Francis Ltd.","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85132614055"
"Dagnino G.; Georgilas I.; Morad S.; Gibbons P.; Tarassoli P.; Atkins R.; Dogramadzi S.","Dagnino, Giulio (56445301900); Georgilas, Ioannis (55851947284); Morad, Samir (56650793100); Gibbons, Peter (57194108920); Tarassoli, Payam (35320332700); Atkins, Roger (56911861900); Dogramadzi, Sanja (6507900733)","56445301900; 55851947284; 56650793100; 57194108920; 35320332700; 56911861900; 6507900733","Image-Guided Surgical Robotic System for Percutaneous Reduction of Joint Fractures","2017","Annals of Biomedical Engineering","45","11","","2648","2662","14","35","10.1007/s10439-017-1901-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027517951&doi=10.1007%2fs10439-017-1901-x&partnerID=40&md5=cae53b6874fd5cb877019fe10aeab17e","Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS161QY, United Kingdom; Aston University, Birmingham, B47ET, United Kingdom; University Hospitals Bristol, Upper Maudlin Street, Bristol, BS28HW, United Kingdom","Dagnino G., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS161QY, United Kingdom; Georgilas I., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS161QY, United Kingdom; Morad S., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS161QY, United Kingdom, Aston University, Birmingham, B47ET, United Kingdom; Gibbons P., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS161QY, United Kingdom; Tarassoli P., University Hospitals Bristol, Upper Maudlin Street, Bristol, BS28HW, United Kingdom; Atkins R., University Hospitals Bristol, Upper Maudlin Street, Bristol, BS28HW, United Kingdom; Dogramadzi S., Bristol Robotics Laboratory, University of the West of England, Coldharbour Lane, Bristol, BS161QY, United Kingdom","Complex joint fractures often require an open surgical procedure, which is associated with extensive soft tissue damages and longer hospitalization and rehabilitation time. Percutaneous techniques can potentially mitigate these risks but their application to joint fractures is limited by the current sub-optimal 2D intra-operative imaging (fluoroscopy) and by the high forces involved in the fragment manipulation (due to the presence of soft tissue, e.g., muscles) which might result in fracture malreduction. Integration of robotic assistance and 3D image guidance can potentially overcome these issues. The authors propose an image-guided surgical robotic system for the percutaneous treatment of knee joint fractures, i.e., the robot-assisted fracture surgery (RAFS) system. It allows simultaneous manipulation of two bone fragments, safer robot-bone fixation system, and a traction performing robotic manipulator. This system has led to a novel clinical workflow and has been tested both in laboratory and in clinically relevant cadaveric trials. The RAFS system was tested on 9 cadaver specimens and was able to reduce 7 out of 9 distal femur fractures (T- and Y-shape 33-C1) with acceptable accuracy (≈1 mm, demonstrating its applicability to fix knee joint fractures. This study paved the way to develop novel technologies for percutaneous treatment of complex fractures including hip, ankle, and shoulder, thus representing a step toward minimally-invasive fracture surgeries. © 2017, The Author(s).","Cadaveric experimental study; Computer-assisted surgery; Medical robotics; Navigation; Percutaneous fracture surgery; Virtual planning","","Springer New York LLC","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85027517951"
"Hyde E.R.; Berger L.U.; Ramachandran N.; Hughes-Hallett A.; Pavithran N.P.; Tran M.G.B.; Ourselin S.; Bex A.; Mumtaz F.H.","Hyde, E.R. (55558229000); Berger, L.U. (56727606600); Ramachandran, N. (8833101600); Hughes-Hallett, A. (55694086700); Pavithran, N.P. (57192122610); Tran, M.G.B. (57216523282); Ourselin, S. (6602233595); Bex, A. (7004237921); Mumtaz, F.H. (7004238749)","55558229000; 56727606600; 8833101600; 55694086700; 57192122610; 57216523282; 6602233595; 7004237921; 7004238749","Interactive virtual 3D models of renal cancer patient anatomies alter partial nephrectomy surgical planning decisions and increase surgeon confidence compared to volume-rendered images","2019","International Journal of Computer Assisted Radiology and Surgery","14","4","","723","732","9","34","10.1007/s11548-019-01913-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063055275&doi=10.1007%2fs11548-019-01913-5&partnerID=40&md5=40df22ed07baa7bb3a13f262614a9734","School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Innersight Labs Ltd, London, United Kingdom; Department of Radiology, UCLH NHS Foundation Trust, London, United Kingdom; Specialist Centre for Kidney Cancer, Department of Urology, The Royal Free London NHS Foundation Trust, London, United Kingdom; University College London Division of Surgery and Interventional Science, London, United Kingdom","Hyde E.R., School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom, Innersight Labs Ltd, London, United Kingdom; Berger L.U., School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom, Innersight Labs Ltd, London, United Kingdom; Ramachandran N., Department of Radiology, UCLH NHS Foundation Trust, London, United Kingdom; Hughes-Hallett A., Specialist Centre for Kidney Cancer, Department of Urology, The Royal Free London NHS Foundation Trust, London, United Kingdom; Pavithran N.P., Specialist Centre for Kidney Cancer, Department of Urology, The Royal Free London NHS Foundation Trust, London, United Kingdom; Tran M.G.B., Specialist Centre for Kidney Cancer, Department of Urology, The Royal Free London NHS Foundation Trust, London, United Kingdom; Ourselin S., School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Bex A., Specialist Centre for Kidney Cancer, Department of Urology, The Royal Free London NHS Foundation Trust, London, United Kingdom, University College London Division of Surgery and Interventional Science, London, United Kingdom; Mumtaz F.H., Specialist Centre for Kidney Cancer, Department of Urology, The Royal Free London NHS Foundation Trust, London, United Kingdom","Purpose: To determine whether the interactive visualisation of patient-specific virtual 3D models of the renal anatomy influences the pre-operative decision-making process of urological surgeons for complex renal cancer operations. Methods: Five historic renal cancer patient pre-operative computed tomography (CT) datasets were retrospectively selected based on RENAL nephrectomy score and variety of anatomy. Interactive virtual 3D models were generated for each dataset using image segmentation software and were made available for online visualisation and manipulation. Consultant urologists were invited to participate in the survey which consisted of CT and volume-rendered images (VRI) for the control arm, and CT with segmentation overlay and the virtual 3D model for the intervention arm. A questionnaire regarding anatomical structures, surgical approach, and confidence was administered. Results: Twenty-five participants were recruited (54% response rate), with 19/25 having > 5 years of renal surgery experience. The median anatomical clarity score increased from 3 for the control to 5 for the intervention arm. A change in planned surgical approach was reported in 19% of cases. Virtual 3D models increased surgeon confidence in the surgical decisions in 4/5 patient datasets. There was a statistically significant improvement in surgeon opinion of the potential utility for decision-making purposes of virtual 3D models as compared to VRI at the multidisciplinary team meeting, theatre planning, and intra-operative stages. Conclusion: The use of pre-operative interactive virtual 3D models for surgery planning influences surgical decision-making. Further studies are needed to investigate if the use of these models changes renal cancer surgery outcomes. © 2019, The Author(s).","Computed tomography; Interactive virtual 3D model; Renal masses; Surgical planning; Urological oncology","","Springer Verlag","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85063055275"
"Almarzouqi A.; Aburayya A.; Salloum S.A.","Almarzouqi, Amina (57215840603); Aburayya, Ahmad (57214098954); Salloum, Said A. (57195670894)","57215840603; 57214098954; 57195670894","Prediction of User's Intention to Use Metaverse System in Medical Education: A Hybrid SEM-ML Learning Approach","2022","IEEE Access","10","","","43421","43434","13","153","10.1109/ACCESS.2022.3169285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128687026&doi=10.1109%2fACCESS.2022.3169285&partnerID=40&md5=bc29e0f082f683c163f17c1467d8ff7f","Department Of Health Service Administration, College Of Health Sciences, University Of Sharjah, Sharjah, United Arab Emirates; Quality And Corporate Development Office, Dubai Health Authority, Dubai, United Arab Emirates; School Of Science Engineering And Environment, University Of Salford, Manchester, M5 4WT, United Kingdom","Almarzouqi A., Department Of Health Service Administration, College Of Health Sciences, University Of Sharjah, Sharjah, United Arab Emirates; Aburayya A., Quality And Corporate Development Office, Dubai Health Authority, Dubai, United Arab Emirates; Salloum S.A., School Of Science Engineering And Environment, University Of Salford, Manchester, M5 4WT, United Kingdom","Metaverse (MS) is a digital universe accessible through a virtual environment. It is established through the merging of virtually improved physical and digital reality. Metaverse (MS) offers enhanced immersive experiences and a more interactive learning experience for students in learning and educational settings. It is an expanded and synchronous communication setting that allows different users to share their experiences. The present study aims to evaluate students' perception of the application of MS in the United Arab Emirates (UAE) for medical-educational purposes. In this study, 1858 university students were surveyed to examine this model. The study's conceptual framework consisted of adoption constructs including Technology Acceptance Model (TAM), Personal innovativeness (PI), Perceived Compatibility (PCO), User Satisfaction (US), Perceived Triability (PTR), and Perceived Observability (POB). The study was unique because the model correlated technology-based features and individual-based features. The study also used hybrid analyses such as Machine Learning (ML) algorithms and Structural Equation Modelling (SEM). The present study also employs the Importance Performance Map Analysis (IPMA) to assess the importance and performance factors. The study finds US as an essential determinant of users' intention to use the metaverse (UMS). The present study's finding is useful for stakeholders in the educational sector in understanding the importance of each factor and in making plans based on the order of significance of each factor. The study also methodologically contributes to Information Systems (IS) literature because it is one of the few studies that have used a complementary multi-analytical approach such as ML algorithms to investigate the UMS metaverse systems.  © 2013 IEEE.","Compatibility; Observability; Personal innovativeness; Satisfaction; Triability; Usersa' satisfaction Metaverse","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85128687026"
"Pérez-Pachón L.; Sharma P.; Brech H.; Gregory J.; Lowe T.; Poyade M.; Gröning F.","Pérez-Pachón, Laura (57197761946); Sharma, Parivrudh (57214919065); Brech, Helena (57223098264); Gregory, Jenny (12240027100); Lowe, Terry (7102566499); Poyade, Matthieu (35485091300); Gröning, Flora (6504498397)","57197761946; 57214919065; 57223098264; 12240027100; 7102566499; 35485091300; 6504498397","Effect of marker position and size on the registration accuracy of HoloLens in a non-clinical setting with implications for high-precision surgical tasks","2021","International Journal of Computer Assisted Radiology and Surgery","16","6","","955","966","11","18","10.1007/s11548-021-02354-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104799589&doi=10.1007%2fs11548-021-02354-9&partnerID=40&md5=4fa32549fcf01b3cbfea6420add4992d","School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, United Kingdom; School of Simulation and Visualisation, Glasgow School of Art, Glasgow, United Kingdom; Head and Neck Oncology Unit, Aberdeen Royal Infirmary (NHS Grampian), Aberdeen, United Kingdom","Pérez-Pachón L., School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, United Kingdom; Sharma P., School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, United Kingdom; Brech H., School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, United Kingdom; Gregory J., School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, United Kingdom; Lowe T., School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, United Kingdom, Head and Neck Oncology Unit, Aberdeen Royal Infirmary (NHS Grampian), Aberdeen, United Kingdom; Poyade M., School of Simulation and Visualisation, Glasgow School of Art, Glasgow, United Kingdom; Gröning F., School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, United Kingdom","Purpose: Emerging holographic headsets can be used to register patient-specific virtual models obtained from medical scans with the patient’s body. Maximising accuracy of the virtual models’ inclination angle and position (ideally, ≤ 2° and ≤ 2 mm, respectively, as in currently approved navigation systems) is vital for this application to be useful. This study investigated the accuracy with which a holographic headset registers virtual models with real-world features based on the position and size of image markers. Methods: HoloLens® and the image-pattern-recognition tool Vuforia Engine™ were used to overlay a 5-cm-radius virtual hexagon on a monitor’s surface in a predefined position. The headset’s camera detection of an image marker (displayed on the monitor) triggered the rendering of the virtual hexagon on the headset’s lenses. 4 × 4, 8 × 8 and 12 × 12 cm image markers displayed at nine different positions were used. In total, the position and dimensions of 114 virtual hexagons were measured on photographs captured by the headset’s camera. Results: Some image marker positions and the smallest image marker (4 × 4 cm) led to larger errors in the perceived dimensions of the virtual models than other image marker positions and larger markers (8 × 8 and 12 × 12 cm). ≤ 2° and ≤ 2 mm errors were found in 70.7% and 76% of cases, respectively. Conclusion: Errors obtained in a non-negligible percentage of cases are not acceptable for certain surgical tasks (e.g. the identification of correct trajectories of surgical instruments). Achieving sufficient accuracy with image marker sizes that meet surgical needs and regardless of image marker position remains a challenge. © 2021, The Author(s).","Augmented reality; Holographic headsets’ registration error; Image marker; Image-guided surgery","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85104799589"
"Ye J.; Stewart E.; Roberts C.","Ye, Jiaqi (57217267146); Stewart, Edward (27868160000); Roberts, Clive (55429645500)","57217267146; 27868160000; 55429645500","Use of a 3D model to improve the performance of laser-based railway track inspection","2019","Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit","233","3","","337","355","18","34","10.1177/0954409718795714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053381107&doi=10.1177%2f0954409718795714&partnerID=40&md5=3149b2b7a9954b7590acb4806a8222af","Centre for Railway Research and Education, University of Birmingham, Birmingham, United Kingdom","Ye J., Centre for Railway Research and Education, University of Birmingham, Birmingham, United Kingdom; Stewart E., Centre for Railway Research and Education, University of Birmingham, Birmingham, United Kingdom; Roberts C., Centre for Railway Research and Education, University of Birmingham, Birmingham, United Kingdom","In recent decades, 3D reconstruction techniques have been applied in an increasing number of areas such as virtual reality, robot navigation, medical imaging and architectural restoration of cultural relics. Most of the inspection techniques used in railway systems are, however, still implemented on a 2D basis. This is particularly true of track inspection due to its linear nature. Benefiting from the development of sensor technology and constantly improving processors, higher quality 3D model reconstructions are becoming possible which push the technology into more challenging areas. One such advancement is the use of 3D perceptual techniques in railway systems. This paper presents a novel 3D perceptual system, based on a low-cost 2D laser sensor, which has been developed for the detection and characterisation of physical surface defects in railway tracks. An innovative prototype system has been developed to capture and correlate the laser scan data; dedicated 3D data processing procedures have then been developed in the form of three specific defect-detection algorithms (depth gradient, face normal and face-normal gradient) which are applied to the 3D model. The system has been tested with rail samples in the laboratory and at the Long Marston Railway Test Track. The 3D models developed represent the external surface of the samples both laterally (2D slices) and longitudinally (3D model), and common surface defects can be detected and represented in 3D. The results demonstrate the feasibility of applying 3D reconstruction-based inspection techniques to railway systems. © IMechE 2018.","3D model; condition monitoring; defect detection; inspection; laser; model-based; non-contact; Rail","","SAGE Publications Ltd","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85053381107"
"Chen X.; Ravikumar N.; Xia Y.; Attar R.; Diaz-Pinto A.; Piechnik S.K.; Neubauer S.; Petersen S.E.; Frangi A.F.","Chen, Xiang (57200532416); Ravikumar, Nishant (57190258888); Xia, Yan (57219626194); Attar, Rahman (57205141029); Diaz-Pinto, Andres (57204781309); Piechnik, Stefan K (7004664392); Neubauer, Stefan (55794522200); Petersen, Steffen E (35430477200); Frangi, Alejandro F (7005249248)","57200532416; 57190258888; 57219626194; 57205141029; 57204781309; 7004664392; 55794522200; 35430477200; 7005249248","Shape registration with learned deformations for 3D shape reconstruction from sparse and incomplete point clouds","2021","Medical Image Analysis","74","","102228","","","","18","10.1016/j.media.2021.102228","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115442981&doi=10.1016%2fj.media.2021.102228&partnerID=40&md5=b1e809c218540254105c3546e24bf538","Centre for Computational Imaging and Simulation Technologies in Biomedicine, School of Computing, University of Leeds, Leeds, United Kingdom; Biomedical Imaging Department, Leeds Institute for Cardiovascular and Metabolic Medicine, School of Medicine University of Leeds, Leeds, United Kingdom; Department of Cardiovascular Sciences, KU Leuven, Leuven, Belgium; Department of Electrical Engineering, KU Leuven, Leuven, Belgium; Oxford Center for Clinical Magnetic Resonance Research (OCMR), Division of Cardiovascular Medicine, University of Oxford, John Radcliffe Hospital, Oxford, United Kingdom; William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University London, Charterhouse Square, London, EC1M 6BQ, United Kingdom; Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, West Smithfield, London, EC1A 7BE, United Kingdom; Health Data Research UK, London, United Kingdom; Alan Turing Institute, London, United Kingdom","Chen X., Centre for Computational Imaging and Simulation Technologies in Biomedicine, School of Computing, University of Leeds, Leeds, United Kingdom, Biomedical Imaging Department, Leeds Institute for Cardiovascular and Metabolic Medicine, School of Medicine University of Leeds, Leeds, United Kingdom; Ravikumar N., Centre for Computational Imaging and Simulation Technologies in Biomedicine, School of Computing, University of Leeds, Leeds, United Kingdom, Biomedical Imaging Department, Leeds Institute for Cardiovascular and Metabolic Medicine, School of Medicine University of Leeds, Leeds, United Kingdom; Xia Y., Centre for Computational Imaging and Simulation Technologies in Biomedicine, School of Computing, University of Leeds, Leeds, United Kingdom, Biomedical Imaging Department, Leeds Institute for Cardiovascular and Metabolic Medicine, School of Medicine University of Leeds, Leeds, United Kingdom; Attar R., Centre for Computational Imaging and Simulation Technologies in Biomedicine, School of Computing, University of Leeds, Leeds, United Kingdom, Biomedical Imaging Department, Leeds Institute for Cardiovascular and Metabolic Medicine, School of Medicine University of Leeds, Leeds, United Kingdom; Diaz-Pinto A., Centre for Computational Imaging and Simulation Technologies in Biomedicine, School of Computing, University of Leeds, Leeds, United Kingdom, Biomedical Imaging Department, Leeds Institute for Cardiovascular and Metabolic Medicine, School of Medicine University of Leeds, Leeds, United Kingdom; Piechnik S.K., Oxford Center for Clinical Magnetic Resonance Research (OCMR), Division of Cardiovascular Medicine, University of Oxford, John Radcliffe Hospital, Oxford, United Kingdom; Neubauer S., Oxford Center for Clinical Magnetic Resonance Research (OCMR), Division of Cardiovascular Medicine, University of Oxford, John Radcliffe Hospital, Oxford, United Kingdom; Petersen S.E., William Harvey Research Institute, NIHR Barts Biomedical Research Centre, Queen Mary University London, Charterhouse Square, London, EC1M 6BQ, United Kingdom, Barts Heart Centre, St Bartholomew's Hospital, Barts Health NHS Trust, West Smithfield, London, EC1A 7BE, United Kingdom, Health Data Research UK, London, United Kingdom, Alan Turing Institute, London, United Kingdom; Frangi A.F., Centre for Computational Imaging and Simulation Technologies in Biomedicine, School of Computing, University of Leeds, Leeds, United Kingdom, Biomedical Imaging Department, Leeds Institute for Cardiovascular and Metabolic Medicine, School of Medicine University of Leeds, Leeds, United Kingdom, Department of Cardiovascular Sciences, KU Leuven, Leuven, Belgium, Department of Electrical Engineering, KU Leuven, Leuven, Belgium, Alan Turing Institute, London, United Kingdom","Shape reconstruction from sparse point clouds/images is a challenging and relevant task required for a variety of applications in computer vision and medical image analysis (e.g. surgical navigation, cardiac motion analysis, augmented/virtual reality systems). A subset of such methods, viz. 3D shape reconstruction from 2D contours, is especially relevant for computer-aided diagnosis and intervention applications involving meshes derived from multiple 2D image slices, views or projections. We propose a deep learning architecture, coined Mesh Reconstruction Network (MR-Net), which tackles this problem. MR-Net enables accurate 3D mesh reconstruction in real-time despite missing data and with sparse annotations. Using 3D cardiac shape reconstruction from 2D contours defined on short-axis cardiac magnetic resonance image slices as an exemplar, we demonstrate that our approach consistently outperforms state-of-the-art techniques for shape reconstruction from unstructured point clouds. Our approach can reconstruct 3D cardiac meshes to within 2.5-mm point-to-point error, concerning the ground-truth data (the original image spatial resolution is ∼1.8×1.8×10mm3). We further evaluate the robustness of the proposed approach to incomplete data, and contours estimated using an automatic segmentation algorithm. MR-Net is generic and could reconstruct shapes of other organs, making it compelling as a tool for various applications in medical image analysis. © 2021 The Author(s)","Cardiac mesh reconstruction; Cardiac surface reconstruction; Contours to mesh reconstruction; Deep learning; Graph convolutional network","","Elsevier B.V.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85115442981"
"McCullough J.W.S.; Richardson R.A.; Patronis A.; Halver R.; Marshall R.; Ruefenacht M.; Wylie B.J.N.; Odaker T.; Wiedemann M.; Lloyd B.; Neufeld E.; Sutmann G.; Skjellum A.; Kranzlmüller D.; Coveney P.V.","McCullough, J.W.S. (57192239242); Richardson, R.A. (56493993600); Patronis, A. (55855397100); Halver, R. (55988894500); Marshall, R. (57213377625); Ruefenacht, M. (57191978335); Wylie, B.J.N. (55672993700); Odaker, T. (57188704367); Wiedemann, M. (57136538300); Lloyd, B. (18037849500); Neufeld, E. (35243137100); Sutmann, G. (6701490227); Skjellum, A. (6603727002); Kranzlmüller, D. (26643233300); Coveney, P.V. (7005747590)","57192239242; 56493993600; 55855397100; 55988894500; 57213377625; 57191978335; 55672993700; 57188704367; 57136538300; 18037849500; 35243137100; 6701490227; 6603727002; 26643233300; 7005747590","Towards blood flow in the virtual human: Efficient self-coupling of HemeLB: Virtual Human Blood Flow with HemeLB","2021","Interface Focus","11","1","20190119","","","","11","10.1098/rsfs.2019.0119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099519820&doi=10.1098%2frsfs.2019.0119&partnerID=40&md5=0d20cd2c71fc0ec458b108b617f0dd28","Centre for Computational Science, Department of Chemistry, University College London, London, United Kingdom; Jülich Supercomputing Centre, Forschungszentrum Jülich, Jülich, Germany; SimCenter, University of Tennessee at Chattanooga, Chattanooga, TN, United States; Leibniz Supercomputing Centre, Leibniz-Rechenzentrum (LRZ), Garching, Germany; Foundation for Research on Information Technologies in Society (it'Is), Zurich, Switzerland; ICAMS, Ruhr-University Bochum, Bochum, Germany; Informatics Institute, University of Amsterdam, Amsterdam, Netherlands","McCullough J.W.S., Centre for Computational Science, Department of Chemistry, University College London, London, United Kingdom; Richardson R.A., Centre for Computational Science, Department of Chemistry, University College London, London, United Kingdom; Patronis A., Centre for Computational Science, Department of Chemistry, University College London, London, United Kingdom, Jülich Supercomputing Centre, Forschungszentrum Jülich, Jülich, Germany; Halver R., Jülich Supercomputing Centre, Forschungszentrum Jülich, Jülich, Germany; Marshall R., SimCenter, University of Tennessee at Chattanooga, Chattanooga, TN, United States; Ruefenacht M., SimCenter, University of Tennessee at Chattanooga, Chattanooga, TN, United States; Wylie B.J.N., Jülich Supercomputing Centre, Forschungszentrum Jülich, Jülich, Germany; Odaker T., Leibniz Supercomputing Centre, Leibniz-Rechenzentrum (LRZ), Garching, Germany; Wiedemann M., Leibniz Supercomputing Centre, Leibniz-Rechenzentrum (LRZ), Garching, Germany; Lloyd B., Foundation for Research on Information Technologies in Society (it'Is), Zurich, Switzerland; Neufeld E., Foundation for Research on Information Technologies in Society (it'Is), Zurich, Switzerland; Sutmann G., Jülich Supercomputing Centre, Forschungszentrum Jülich, Jülich, Germany, ICAMS, Ruhr-University Bochum, Bochum, Germany, Informatics Institute, University of Amsterdam, Amsterdam, Netherlands; Skjellum A., SimCenter, University of Tennessee at Chattanooga, Chattanooga, TN, United States; Kranzlmüller D., Leibniz Supercomputing Centre, Leibniz-Rechenzentrum (LRZ), Garching, Germany; Coveney P.V., Centre for Computational Science, Department of Chemistry, University College London, London, United Kingdom","Many scientific and medical researchers are working towards the creation of a virtual human- A personalized digital copy of an individual-that will assist in a patient's diagnosis, treatment and recovery. The complex nature of living systems means that the development of this remains a major challenge. We describe progress in enabling the HemeLB lattice Boltzmann code to simulate 3D macroscopic blood flow on a full human scale. Significant developments in memory management and load balancing allow near linear scaling performance of the code on hundreds of thousands of computer cores. Integral to the construction of a virtual human, we also outline the implementation of a self-coupling strategy for HemeLB. This allows simultaneous simulation of arterial and venous vascular trees based on human-specific geometries. © 2020 The Authors.","blood flow modelling; high-performance computing; lattice Boltzmann method; virtual human","","Royal Society Publishing","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85099519820"
"Xi L.; Zhao Y.; Chen L.; Gao Q.H.; Tang W.; Wan T.R.; Xue T.","Xi, Long (57223087113); Zhao, Yan (57225061385); Chen, Long (57196277812); Gao, Qing Hong (57196277401); Tang, Wen (55748093500); Wan, Tao Ruan (36874481000); Xue, Tao (57220196544)","57223087113; 57225061385; 57196277812; 57196277401; 55748093500; 36874481000; 57220196544","Recovering dense 3D point clouds from single endoscopic image","2021","Computer Methods and Programs in Biomedicine","205","","106077","","","","11","10.1016/j.cmpb.2021.106077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104783895&doi=10.1016%2fj.cmpb.2021.106077&partnerID=40&md5=5982b02d001c64f1845185fd7e68f6c3","Bournemouth University, Poole, BH12 5BB, Dorset, United Kingdom; Lyft Level 5, London, EC2A 3AH, United Kingdom; University of Btadford, Bradford, BD7 1DP, United Kingdom; Xian Polytechnic University, Xian, 710048, Shaanxi, China","Xi L., Bournemouth University, Poole, BH12 5BB, Dorset, United Kingdom; Zhao Y., Bournemouth University, Poole, BH12 5BB, Dorset, United Kingdom; Chen L., Lyft Level 5, London, EC2A 3AH, United Kingdom; Gao Q.H., Bournemouth University, Poole, BH12 5BB, Dorset, United Kingdom; Tang W., Bournemouth University, Poole, BH12 5BB, Dorset, United Kingdom; Wan T.R., University of Btadford, Bradford, BD7 1DP, United Kingdom; Xue T., Xian Polytechnic University, Xian, 710048, Shaanxi, China","Background and objective: Recovering high-quality 3D point clouds from monocular endoscopic images is a challenging task. This paper proposes a novel deep learning-based computational framework for 3D point cloud reconstruction from single monocular endoscopic images. Methods: An unsupervised mono-depth learning network is used to generate depth information from monocular images. Given a single mono endoscopic image, the network is capable of depicting a depth map. The depth map is then used to recover a dense 3D point cloud. A generative Endo-AE network based on an auto-encoder is trained to repair defects of the dense point cloud by generating the best representation from the incomplete data. The performance of the proposed framework is evaluated against state-of-the-art learning-based methods. The results are also compared with non-learning based stereo 3D reconstruction algorithms. Results: Our proposed methods outperform both the state-of-the-art learning-based and non-learning based methods for 3D point cloud reconstruction. The Endo-AE model for point cloud completion can generate high-quality, dense 3D endoscopic point clouds from incomplete point clouds with holes. Our framework is able to recover complete 3D point clouds with the missing rate of information up to 60%. Five large medical in-vivo databases of 3D point clouds of real endoscopic scenes have been generated and two synthetic 3D medical datasets are created. We have made these datasets publicly available for researchers free of charge. Conclusions: The proposed computational framework can produce high-quality and dense 3D point clouds from single mono-endoscopy images for augmented reality, virtual reality and other computer-mediated medical applications. © 2021","3D point clouds; Artificial intelligence/ deep learning; Augmented reality; Minimally invasive surgery; Monocular endoscopic scenes; Virtual reality","","Elsevier Ireland Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85104783895"
"Sauchelli S.; Pickles T.; Voinescu A.; Choi H.; Sherlock B.; Zhang J.; Colyer S.; Grant S.; Sundari S.; Lasseter G.","Sauchelli, Sarah (56123298000); Pickles, Tim (36560197900); Voinescu, Alexandra (55927550800); Choi, Heungjae (16030668600); Sherlock, Ben (57406337600); Zhang, Jingjing (57406326900); Colyer, Steffi (57188837684); Grant, Sabrina (57193321123); Sundari, Sethu (57406327000); Lasseter, Gemma (35388949800)","56123298000; 36560197900; 55927550800; 16030668600; 57406337600; 57406326900; 57188837684; 57193321123; 57406327000; 35388949800","Public attitudes towards the use of novel technologies in their future healthcare: a UK survey","2023","BMC Medical Informatics and Decision Making","23","1","38","","","","2","10.1186/s12911-023-02118-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148550838&doi=10.1186%2fs12911-023-02118-2&partnerID=40&md5=ce72f9a78656261cabff7b24969c5944","National Institute for Health Research Bristol Biomedical Research Centre, University Hospitals of Bristol and Weston NHS Foundation Trust and University of Bristol, Bristol, United Kingdom; Centre for Trials Research, College of Biomedical and Life Sciences, Cardiff University, Cardiff, United Kingdom; Department of Psychology, University of Bath, Bath, United Kingdom; School of Engineering, Cardiff University, Cardiff, United Kingdom; College of Medicine and Health, University of Exeter, Exeter, United Kingdom; Department of Mathematical Sciences, University of Essex, Colchester, United Kingdom; Department of Health, University of Bath, Bath, United Kingdom; Musculoskeletal Research Unit, Translational Health Sciences, Bristol Medical School, University of Bristol, Bristol, United Kingdom; School of Nursing and Midwifery, University of Worcester, Worcester, United Kingdom; NIHR Health Protection Research Unit (HPRU) in Behavioural Science and Evaluation, University of Bristol in Collaboration with UK Health Security Agency (UKHSA), Bristol Medical School, Population Health Sciences, University of Bristol, Bristol, United Kingdom","Sauchelli S., National Institute for Health Research Bristol Biomedical Research Centre, University Hospitals of Bristol and Weston NHS Foundation Trust and University of Bristol, Bristol, United Kingdom; Pickles T., Centre for Trials Research, College of Biomedical and Life Sciences, Cardiff University, Cardiff, United Kingdom; Voinescu A., Department of Psychology, University of Bath, Bath, United Kingdom; Choi H., School of Engineering, Cardiff University, Cardiff, United Kingdom; Sherlock B., College of Medicine and Health, University of Exeter, Exeter, United Kingdom; Zhang J., Department of Mathematical Sciences, University of Essex, Colchester, United Kingdom; Colyer S., Department of Health, University of Bath, Bath, United Kingdom; Grant S., Musculoskeletal Research Unit, Translational Health Sciences, Bristol Medical School, University of Bristol, Bristol, United Kingdom; Sundari S., School of Nursing and Midwifery, University of Worcester, Worcester, United Kingdom; Lasseter G., NIHR Health Protection Research Unit (HPRU) in Behavioural Science and Evaluation, University of Bristol in Collaboration with UK Health Security Agency (UKHSA), Bristol Medical School, Population Health Sciences, University of Bristol, Bristol, United Kingdom","Background: Innovation in healthcare technologies can result in more convenient and effective treatment that is less costly, but a persistent challenge to widespread adoption in health and social care is end user acceptability. The purpose of this study was to capture UK public opinions and attitudes to novel healthcare technologies (NHTs), and to better understand the factors that contribute to acceptance and future use. Methods: An online survey was distributed to the UK public between April and May 2020. Respondents received brief information about four novel healthcare technologies (NHTs) in development: a laser-based tool for early diagnosis of osteoarthritis, a virtual reality tool to support diabetes self-management, a non-invasive continuous glucose monitor using microwave signals, a mobile app for patient reported monitoring of rheumatoid arthritis. They were queried on their general familiarity and attitudes to technology, and their willingness to accept each NHT in their future care. Responses were analysed using summary statistics and content analysis. Results: Knowledge about NHTs was diverse, with respondents being more aware about the health applications of mobile apps (66%), followed by laser-based technology (63.8%), microwave signalling (28%), and virtual reality (18.3%). Increasing age and the presence of a self-reported medical condition favoured acceptability for some NHTs, whereas self-reported understanding of how the NHT works resulted in elevated acceptance scores across all NHTs presented. Common contributors to hesitancy were safety and risks from use. Respondents wanted more information and evidence to help inform their decisions, ideally provided verbally by a general practitioner or health professional. Other concerns, such as privacy, were NHT-specific but equally important in decision-making. Conclusions: Early insight into the knowledge and preconceptions of the public about NHTs in development can assist their design and prospectively mitigate obstacles to acceptance and adoption. © 2023, The Author(s).","Acceptability; Attitudes; Laser; Microwave signals; Mobile application; Novel healthcare technologies; Survey; Virtual reality","","BioMed Central Ltd","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85148550838"
"Weld A.; Cartucho J.; Xu C.; Davids J.; Giannarou S.","Weld, Alistair (57357134900); Cartucho, Joao (57204141345); Xu, Chi (57671796400); Davids, Joseph (57225468339); Giannarou, Stamatia (14834012300)","57357134900; 57204141345; 57671796400; 57225468339; 14834012300","Regularising disparity estimation via multi task learning with structured light reconstruction","2023","Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization","11","4","","1206","1214","8","0","10.1080/21681163.2022.2156391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144164496&doi=10.1080%2f21681163.2022.2156391&partnerID=40&md5=df45ab0ba74392146d9641638cf6c299","The Hamlyn Centre, Imperial College London, London, United Kingdom","Weld A., The Hamlyn Centre, Imperial College London, London, United Kingdom; Cartucho J., The Hamlyn Centre, Imperial College London, London, United Kingdom; Xu C., The Hamlyn Centre, Imperial College London, London, United Kingdom; Davids J., The Hamlyn Centre, Imperial College London, London, United Kingdom; Giannarou S., The Hamlyn Centre, Imperial College London, London, United Kingdom","3D reconstruction is a useful tool for surgical planning and guidance. Supervised methods for disparity/depth estimation are the state of the art, with demonstrated performances far superior to all alternatives, such as self supervised and traditional geometric methods. However, supervised training requires large datasets, and in this field, data is lacking. In this paper, we investigate the learning of structured light projections to enhance the development of disparity estimation networks. Improving supervised learning on small datasets without needing to collect extra data. We first show that it is possible to learn the projection of structured light on a scene. Secondly, we show that the joint training of structured light and disparity, using a multi-task learning (MTL) framework, improves the learning of disparity. Our MTL setup outperformed the single task learning (STL) network in every validation test. Notably, in the generalisation test, the STL error was 1.4 times worse than that of the best MTL performance. A dataset containing stereoscopic images, disparity maps and structured light projections on medical phantoms and ex vivo tissue was created for evaluation together with virtual scenes. This dataset will be made publicly available in the future. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Disparity estimation; multi task learning; small data; structured light","","Taylor and Francis Ltd.","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85144164496"
"Minnema J.; Wolff J.; Koivisto J.; Lucka F.; Batenburg K.J.; Forouzanfar T.; van Eijnatten M.","Minnema, Jordi (57204318302); Wolff, Jan (55554972400); Koivisto, Juha (56487467800); Lucka, Felix (52364146500); Batenburg, Kees Joost (55879451400); Forouzanfar, Tymour (6602281425); van Eijnatten, Maureen (56204979200)","57204318302; 55554972400; 56487467800; 52364146500; 55879451400; 6602281425; 56204979200","Comparison of convolutional neural network training strategies for cone-beam CT image segmentation","2021","Computer Methods and Programs in Biomedicine","207","","106192","","","","15","10.1016/j.cmpb.2021.106192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110593795&doi=10.1016%2fj.cmpb.2021.106192&partnerID=40&md5=a50222492fe4fbde8116510d04041d17","Department of Oral and Maxillofacial Surgery/Pathology, 3D Innovationlab, Amsterdam UMC and Academic Centre for Dentistry Amsterdam (ACTA), Vrije Universiteit Amsterdam, Amsterdam Movement Sciences, Amsterdam, 1081 HV, Netherlands; Fraunhofer Research Institution for Additive Manufacturing Technologies IAPT, Am Schleusengraben 13, Hamburg, 21029, Germany; Department of Oral and Maxillofacial Surgery, Division for Regenerative Orofacial Medicine, University Hospital Hamburg-Eppendorf, Hamburg, 20246, Germany; Department of Physics, University of Helsinki, Helsinki, 20560, Finland; Centrum Wiskunde & Informatica (CWI), Amsterdam, 1090 GB, Netherlands; University College London, London, WC1E 6BT, United Kingdom; Department of Dentistry and Oral Health, Aarhus University, Vennelyst Boulevard 9, Aarhus C, DK-8000, Denmark","Minnema J., Department of Oral and Maxillofacial Surgery/Pathology, 3D Innovationlab, Amsterdam UMC and Academic Centre for Dentistry Amsterdam (ACTA), Vrije Universiteit Amsterdam, Amsterdam Movement Sciences, Amsterdam, 1081 HV, Netherlands; Wolff J., Fraunhofer Research Institution for Additive Manufacturing Technologies IAPT, Am Schleusengraben 13, Hamburg, 21029, Germany, Department of Oral and Maxillofacial Surgery, Division for Regenerative Orofacial Medicine, University Hospital Hamburg-Eppendorf, Hamburg, 20246, Germany, Department of Dentistry and Oral Health, Aarhus University, Vennelyst Boulevard 9, Aarhus C, DK-8000, Denmark; Koivisto J., Department of Physics, University of Helsinki, Helsinki, 20560, Finland; Lucka F., Centrum Wiskunde & Informatica (CWI), Amsterdam, 1090 GB, Netherlands, University College London, London, WC1E 6BT, United Kingdom; Batenburg K.J., Centrum Wiskunde & Informatica (CWI), Amsterdam, 1090 GB, Netherlands; Forouzanfar T., Department of Oral and Maxillofacial Surgery/Pathology, 3D Innovationlab, Amsterdam UMC and Academic Centre for Dentistry Amsterdam (ACTA), Vrije Universiteit Amsterdam, Amsterdam Movement Sciences, Amsterdam, 1081 HV, Netherlands; van Eijnatten M., Centrum Wiskunde & Informatica (CWI), Amsterdam, 1090 GB, Netherlands","Background and objective: Over the past decade, convolutional neural networks (CNNs) have revolutionized the field of medical image segmentation. Prompted by the developments in computational resources and the availability of large datasets, a wide variety of different two-dimensional (2D) and three-dimensional (3D) CNN training strategies have been proposed. However, a systematic comparison of the impact of these strategies on the image segmentation performance is still lacking. Therefore, this study aimed to compare eight different CNN training strategies, namely 2D (axial, sagittal and coronal slices), 2.5D (3 and 5 adjacent slices), majority voting, randomly oriented 2D cross-sections and 3D patches. Methods: These eight strategies were used to train a U-Net and an MS-D network for the segmentation of simulated cone-beam computed tomography (CBCT) images comprising randomly-placed non-overlapping cylinders and experimental CBCT images of anthropomorphic phantom heads. The resulting segmentation performances were quantitatively compared by calculating Dice similarity coefficients. In addition, all segmented and gold standard experimental CBCT images were converted into virtual 3D models and compared using orientation-based surface comparisons. Results: The CNN training strategy that generally resulted in the best performances on both simulated and experimental CBCT images was majority voting. When employing 2D training strategies, the segmentation performance can be optimized by training on image slices that are perpendicular to the predominant orientation of the anatomical structure of interest. Such spatial features should be taken into account when choosing or developing novel CNN training strategies for medical image segmentation. Conclusions: The results of this study will help clinicians and engineers to choose the most-suited CNN training strategy for CBCT image segmentation. © 2021","Cone-beam computed tomography; Convolutional neural networks; Deep learning; Medical image segmentation; Training strategies","","Elsevier Ireland Ltd","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85110593795"
"Viviani M.; Crocamo C.; Mazzola M.; Bartoli F.; Carrà G.; Pasi G.","Viviani, Marco (13410043100); Crocamo, Cristina (55634683100); Mazzola, Matteo (58021631900); Bartoli, Francesco (55249556900); Carrà, Giuseppe (7003818736); Pasi, Gabriella (7003307397)","13410043100; 55634683100; 58021631900; 55249556900; 7003818736; 7003307397","Assessing vulnerability to psychological distress during the COVID-19 pandemic through the analysis of microblogging content","2021","Future Generation Computer Systems","125","","","446","459","13","17","10.1016/j.future.2021.06.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109427663&doi=10.1016%2fj.future.2021.06.044&partnerID=40&md5=dba6a260db2d98fcb4e75cece9572631","Department of Informatics, Systems, and Communication (DISCo), University of Milano-Bicocca, Milan, Italy; Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy; Department of Mental Health & Addiction, ASST Nord Milano, Bassini Hospital, Cinisello Balsamo, Italy; Division of Psychiatry, University College London (UCL), London, UK, United Kingdom","Viviani M., Department of Informatics, Systems, and Communication (DISCo), University of Milano-Bicocca, Milan, Italy; Crocamo C., Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy; Mazzola M., Department of Informatics, Systems, and Communication (DISCo), University of Milano-Bicocca, Milan, Italy; Bartoli F., Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy, Department of Mental Health & Addiction, ASST Nord Milano, Bassini Hospital, Cinisello Balsamo, Italy; Carrà G., Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy, Department of Mental Health & Addiction, ASST Nord Milano, Bassini Hospital, Cinisello Balsamo, Italy, Division of Psychiatry, University College London (UCL), London, UK, United Kingdom; Pasi G., Department of Informatics, Systems, and Communication (DISCo), University of Milano-Bicocca, Milan, Italy","In recent years we have witnessed a growing interest in the analysis of social media data under different perspectives, since these online platforms have become the preferred tool for generating and sharing content across different users organized into virtual communities, based on their common interests, needs, and perceptions. In the current study, by considering a collection of social textual contents related to COVID-19 gathered on the Twitter microblogging platform in the period between August and December 2020, we aimed at evaluating the possible effects of some critical factors related to the pandemic on the mental well-being of the population. In particular, we aimed at investigating potential lexicon identifiers of vulnerability to psychological distress in digital social interactions with respect to distinct COVID-related scenarios, which could be “at risk” from a psychological discomfort point of view. Such scenarios have been associated with peculiar topics discussed on Twitter. For this purpose, two approaches based on a “top-down” and a “bottom-up” strategy were adopted. In the top-down approach, three potential scenarios were initially selected by medical experts, and associated with topics extracted from the Twitter dataset in a hybrid unsupervised-supervised way. On the other hand, in the bottom-up approach, three topics were extracted in a totally unsupervised way capitalizing on a Twitter dataset filtered according to the presence of keywords related to vulnerability to psychological distress, and associated with at-risk scenarios. The identification of such scenarios with both approaches made it possible to capture and analyze the potential psychological vulnerability in critical situations. © 2021","Mental health; Psychological distress; Sentiment analysis; Social media; Social network analysis; Vulnerability","","Elsevier B.V.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85109427663"
"Korzeniowski P.; White R.J.; Bello F.","Korzeniowski, Przemyslaw (56422138400); White, Ruth J. (57196275639); Bello, Fernando (24329025000)","56422138400; 57196275639; 24329025000","VCSim3: a VR simulator for cardiovascular interventions","2018","International Journal of Computer Assisted Radiology and Surgery","13","1","","135","149","14","21","10.1007/s11548-017-1679-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032481444&doi=10.1007%2fs11548-017-1679-1&partnerID=40&md5=377a122d264ac63f7fb6d88b3681fb17","Simulation and Modelling in Medicine and Surgery, Centre for Engagement and Simulation Science, Imperial College London, London, United Kingdom; Chelsea and Westminster Hospital, 369 Fulham Road, London, SW10 9NH, United Kingdom","Korzeniowski P., Simulation and Modelling in Medicine and Surgery, Centre for Engagement and Simulation Science, Imperial College London, London, United Kingdom, Chelsea and Westminster Hospital, 369 Fulham Road, London, SW10 9NH, United Kingdom; White R.J., Simulation and Modelling in Medicine and Surgery, Centre for Engagement and Simulation Science, Imperial College London, London, United Kingdom; Bello F., Simulation and Modelling in Medicine and Surgery, Centre for Engagement and Simulation Science, Imperial College London, London, United Kingdom","Purpose: Effective and safe performance of cardiovascular interventions requires excellent catheter/guidewire manipulation skills. These skills are currently mainly gained through an apprenticeship on real patients, which may not be safe or cost-effective. Computer simulation offers an alternative for core skills training. However, replicating the physical behaviour of real instruments navigated through blood vessels is a challenging task. Methods: We have developed VCSim3—a virtual reality simulator for cardiovascular interventions. The simulator leverages an inextensible Cosserat rod to model virtual catheters and guidewires. Their mechanical properties were optimized with respect to their real counterparts scanned in a silicone phantom using X-ray CT imaging. The instruments are manipulated via a VSP haptic device. Supporting solutions such as fluoroscopic visualization, contrast flow propagation, cardiac motion, balloon inflation, and stent deployment, enable performing a complete angioplasty procedure. Results: We present detailed results of simulation accuracy of the virtual instruments, along with their computational performance. In addition, the results of a preliminary face and content validation study conveyed on a group of 17 interventional radiologists are given. Conclusions: VR simulation of cardiovascular procedure can contribute to surgical training and improve the educational experience without putting patients at risk, raising ethical issues or requiring expensive animal or cadaver facilities. VCSim3 is still a prototype, yet the initial results indicate that it provides promising foundations for further development. © 2017, The Author(s).","Catheter; Coronary interventions; Cosserat rod; Guidewire; Medical training; VR simulator","","Springer Verlag","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85032481444"
"Talbot H.; Spadoni F.; Duriez C.; Sermesant M.; O'Neill M.; Jaïs P.; Cotin S.; Delingette H.","Talbot, Hugo (55632334300); Spadoni, Federico (56422061500); Duriez, Christian (56416177200); Sermesant, Maxime (6506746084); O'Neill, Mark (12775028900); Jaïs, Pierre (7005544071); Cotin, Stéphane (6701381230); Delingette, Hervé (7004183160)","55632334300; 56422061500; 56416177200; 6506746084; 12775028900; 7005544071; 6701381230; 7004183160","Interactive training system for interventional electrocardiology procedures","2017","Medical Image Analysis","35","","","225","237","12","18","10.1016/j.media.2016.06.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979284367&doi=10.1016%2fj.media.2016.06.040&partnerID=40&md5=9b94a9fbc685fa18174a39207d7395e5","Inria, France; Department of Cardiology, Guy's and St. Thomas’ NHS, London, United Kingdom; Hôpital Haut-l’évêque - IHU Liryc, Bordeaux, France","Talbot H., Inria, France; Spadoni F., Inria, France; Duriez C., Inria, France; Sermesant M., Inria, France; O'Neill M., Department of Cardiology, Guy's and St. Thomas’ NHS, London, United Kingdom; Jaïs P., Hôpital Haut-l’évêque - IHU Liryc, Bordeaux, France; Cotin S., Inria, France; Delingette H., Inria, France","Recent progress in cardiac catheterization and devices has allowed the development of new therapies for severe cardiac diseases like arrhythmias and heart failure. The skills required for such interventions are very challenging to learn, and are typically acquired over several years. Virtual reality simulators may reduce this burden by allowing trainees to practice such procedures without risk to patients. In this paper, we propose the first training system dedicated to cardiac electrophysiology, including pacing and ablation procedures. Our framework involves the simulation of a catheter navigation that reproduces issues intrinsic to intra-cardiac catheterization, and a graphics processing unit (GPU)-based electrophysiological model. A multithreading approach is proposed to compute both physical simulations (navigation and electrophysiology) asynchronously. With this method, we reach computational performances that account for user interactions in real-time. Based on a scenario of cardiac arrhythmia, we demonstrate the ability of the user-guided simulator to navigate inside vessels and cardiac cavities with a catheter and to reproduce an ablation procedure involving: extra-cellular potential measurements, endocardial surface reconstruction, electrophysiology mapping, radio-frequency (RF) ablation, as well as electrical stimulation. A clinical evaluation assessing the different aspects of the simulation is presented. This works is a step towards computerized medical learning curriculum. © 2016 Elsevier B.V.","Endovascular navigation; Interactive simulation; Real-time electrophysiology; Training simulator","","Elsevier B.V.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84979284367"
"Hu Y.; Kasivisvanathan V.; Simmons L.A.M.; Clarkson M.J.; Thompson S.A.; Shah T.T.; Ahmed H.U.; Punwani S.; Hawkes D.J.; Emberton M.; Moore C.M.; Barratt D.C.","Hu, Yipeng (24512208500); Kasivisvanathan, Veeru (35336774700); Simmons, Lucy A. M. (37038344200); Clarkson, Matthew J. (7006920406); Thompson, Stephen A. (57037694400); Shah, Taimur T. (57114379700); Ahmed, Hashim U. (8147855500); Punwani, Shonit (17036141700); Hawkes, David J. (35464300200); Emberton, Mark (7004667094); Moore, Caroline M. (58670222900); Barratt, Dean C. (7005201740)","24512208500; 35336774700; 37038344200; 7006920406; 57037694400; 57114379700; 8147855500; 17036141700; 35464300200; 7004667094; 58670222900; 7005201740","Development and Phantom Validation of a 3-D-Ultrasound-Guided System for Targeting MRI-Visible Lesions during Transrectal Prostate Biopsy","2017","IEEE Transactions on Biomedical Engineering","64","4","7496950","946","958","12","17","10.1109/TBME.2016.2582734","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017583807&doi=10.1109%2fTBME.2016.2582734&partnerID=40&md5=32b32a74d689cb72b073f1cf31a257e2","UCL Centre for Medical Image Computing, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Division of Surgical and Interventional Sciences, University College London, United Kingdom; UCL Centre for Medical Imaging, Division of Medicine, University College London, United Kingdom","Hu Y., UCL Centre for Medical Image Computing, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Kasivisvanathan V., Division of Surgical and Interventional Sciences, University College London, United Kingdom; Simmons L.A.M., Division of Surgical and Interventional Sciences, University College London, United Kingdom; Clarkson M.J., UCL Centre for Medical Image Computing, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Thompson S.A., UCL Centre for Medical Image Computing, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Shah T.T., Division of Surgical and Interventional Sciences, University College London, United Kingdom; Ahmed H.U., Division of Surgical and Interventional Sciences, University College London, United Kingdom; Punwani S., UCL Centre for Medical Imaging, Division of Medicine, University College London, United Kingdom; Hawkes D.J., UCL Centre for Medical Image Computing, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Emberton M., Division of Surgical and Interventional Sciences, University College London, United Kingdom; Moore C.M., Division of Surgical and Interventional Sciences, University College London, United Kingdom; Barratt D.C., UCL Centre for Medical Image Computing, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom","Objective: Three-and four-dimensional transrectal ultrasound transducers are now available from most major ultrasound equipment manufacturers, but currently are incorporated into only one commercial prostate biopsy guidance system. Such transducers offer the benefits of rapid volumetric imaging, but can cause substantial measurement distortion in electromagnetic tracking sensors, which are commonly used to enable 3-D navigation. In this paper, we describe the design, development, and validation of a 3-D-ultrasound-guided transrectal prostate biopsy system that employs high-Accuracy optical tracking to localize the ultrasound probe and prostate targets in 3-D physical space. Methods: The accuracy of the system was validated by evaluating the targeted needle placement error after inserting a biopsy needle to sample planned targets in a phantom using standard 2-D ultrasound guidance versus real-Time 3-D guidance provided by the new system. Results: The overall mean needle-segment-To-Target distance error was 3.6 ± 4.0 mm and mean needle-To-Target distance was 3.2 ± 2.4 mm. Conclusion: A significant increase in needle placement accuracy was observed when using the 3-D guidance system compared with visual targeting of invisible (virtual) lesions using a standard B-mode ultrasound-guided biopsy technique. © 1964-2012 IEEE.","image registration; Image-guided interventions; prostate cancer; tracking; transrectal biopsy","","IEEE Computer Society","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85017583807"
"Galappaththige S.; Gray R.A.; Costa C.M.; Niederer S.; Pathmanathan P.","Galappaththige, Suran (56716578100); Gray, Richard A. (7403689645); Costa, Caroline Mendonca (24474173000); Niederer, Steven (6507804465); Pathmanathan, Pras (24484191400)","56716578100; 7403689645; 24474173000; 6507804465; 24484191400","Credibility assessment of patient-specific computational modeling using patient-specific cardiac modeling as an exemplar","2022","PLoS Computational Biology","18","10","e1010541","","","","6","10.1371/journal.pcbi.1010541","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139572246&doi=10.1371%2fjournal.pcbi.1010541&partnerID=40&md5=544ac69759c3dc7d5cf19a0dbb45d2d6","Center for Devices and Radiological Health, US Food and Drug Administration, Silver Spring, MD, United States; School of Biomedical Engineering & Imaging Sciences, King’s College London, London, United Kingdom","Galappaththige S., Center for Devices and Radiological Health, US Food and Drug Administration, Silver Spring, MD, United States; Gray R.A., Center for Devices and Radiological Health, US Food and Drug Administration, Silver Spring, MD, United States; Costa C.M., School of Biomedical Engineering & Imaging Sciences, King’s College London, London, United Kingdom; Niederer S., School of Biomedical Engineering & Imaging Sciences, King’s College London, London, United Kingdom; Pathmanathan P., Center for Devices and Radiological Health, US Food and Drug Administration, Silver Spring, MD, United States","Reliable and robust simulation of individual patients using patient-specific models (PSMs) is one of the next frontiers for modeling and simulation (M&S) in healthcare. PSMs, which form the basis of digital twins, can be employed as clinical tools to, for example, assess disease state, predict response to therapy, or optimize therapy. They may also be used to construct virtual cohorts of patients, for in silico evaluation of medical product safety and/or performance. Methods and frameworks have recently been proposed for evaluating the credibility of M&S in healthcare applications. However, such efforts have generally been motivated by models of medical devices or generic patient models; how best to evaluate the credibility of PSMs has largely been unexplored. The aim of this paper is to understand and demonstrate the credibility assessment process for PSMs using patient-specific cardiac electrophysiological (EP) modeling as an exemplar. We first review approaches used to generate cardiac PSMs and consider how verification, validation, and uncertainty quantification (VVUQ) apply to cardiac PSMs. Next, we execute two simulation studies using a publicly available virtual cohort of 24 patient-specific ventricular models, the first a multi-patient verification study, the second investigating the impact of uncertainty in personalized and non-personalized inputs in a virtual cohort. We then use the findings from our analyses to identify how important characteristics of PSMs can be considered when assessing credibility with the approach of the ASME V&V40 Standard, accounting for PSM concepts such as inter- and intra-user variability, multi-patient and “every-patient” error estimation, uncertainty quantification in personalized vs non-personalized inputs, clinical validation, and others. The results of this paper will be useful to developers of cardiac and other medical image based PSMs, when assessing PSM credibility. This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the Creative Commons CC0 public domain dedication.","","","Public Library of Science","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139572246"
"Marlevi D.; Balmus M.; Hessenthaler A.; Viola F.; Fovargue D.; Vecchi A.D.; Lamata P.; Burris N.S.; Pagani F.D.; Engvall J.; Edelman E.R.; Ebbers T.; Nordsletten D.A.","Marlevi, David (57204277535); Balmus, Maximilian (57205678281); Hessenthaler, Andreas (57193168777); Viola, Federica (57195150818); Fovargue, Daniel (55826845500); Vecchi, Adelaide de (36476204700); Lamata, Pablo (12806240900); Burris, Nicholas S. (15821842600); Pagani, Francis D. (57216999172); Engvall, Jan (7003822648); Edelman, Elazer R. (7006343554); Ebbers, Tino (6603253440); Nordsletten, David A. (22954349100)","57204277535; 57205678281; 57193168777; 57195150818; 55826845500; 36476204700; 12806240900; 15821842600; 57216999172; 7003822648; 7006343554; 6603253440; 22954349100","Non-invasive estimation of relative pressure for intracardiac flows using virtual work-energy","2021","Medical Image Analysis","68","","101948","","","","15","10.1016/j.media.2020.101948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098474544&doi=10.1016%2fj.media.2020.101948&partnerID=40&md5=99330115edc5a24fab7f1c636e61aab4","Institute for Medical Engineering and Science, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, SE1 7EH, London, United Kingdom; Institute for Modelling and Simulation of Biomechanical Systems, University of Stuttgart, Pfaffenwaldring 5a, 70569, Stuttgart, Germany; Department of Medical and Health Sciences and Center for Medical Image Science and Visualization (CMIV), Linköping Unversity, SE-58185, Linköping, Sweden; Department of Radiology, University of Michigan, 1500 E. Medical Center Drive, Ann Arbor, 48109, MI, United States; Department of Surgery and Biomedical Engineering, University of Michigan, 2800 Plymouth Rd, Ann Arbor, 48109, MI, United States","Marlevi D., Institute for Medical Engineering and Science, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Balmus M., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, SE1 7EH, London, United Kingdom; Hessenthaler A., Institute for Modelling and Simulation of Biomechanical Systems, University of Stuttgart, Pfaffenwaldring 5a, 70569, Stuttgart, Germany; Viola F., Department of Medical and Health Sciences and Center for Medical Image Science and Visualization (CMIV), Linköping Unversity, SE-58185, Linköping, Sweden; Fovargue D., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, SE1 7EH, London, United Kingdom; Vecchi A.D., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, SE1 7EH, London, United Kingdom; Lamata P., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, SE1 7EH, London, United Kingdom; Burris N.S., Department of Radiology, University of Michigan, 1500 E. Medical Center Drive, Ann Arbor, 48109, MI, United States; Pagani F.D., Department of Radiology, University of Michigan, 1500 E. Medical Center Drive, Ann Arbor, 48109, MI, United States; Engvall J., Department of Medical and Health Sciences and Center for Medical Image Science and Visualization (CMIV), Linköping Unversity, SE-58185, Linköping, Sweden; Edelman E.R., Institute for Medical Engineering and Science, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Ebbers T., Department of Medical and Health Sciences and Center for Medical Image Science and Visualization (CMIV), Linköping Unversity, SE-58185, Linköping, Sweden; Nordsletten D.A., School of Biomedical Engineering and Imaging Sciences, The Rayne Institute, King's College London, SE1 7EH, London, United Kingdom, Department of Surgery and Biomedical Engineering, University of Michigan, 2800 Plymouth Rd, Ann Arbor, 48109, MI, United States","Intracardiac blood flow is driven by differences in relative pressure, and assessing these is critical in understanding cardiac disease. Non-invasive image-based methods exist to assess relative pressure, however, the complex flow and dynamically moving fluid domain of the intracardiac space limits assessment. Recently, we proposed a method, νWERP, utilizing an auxiliary virtual field to probe relative pressure through complex, and previously inaccessible flow domains. Here we present an extension of νWERP for intracardiac flow assessments, solving the virtual field over sub-domains to effectively handle the dynamically shifting flow domain. The extended νWERP is validated in an in-silico benchmark problem, as well as in a patient-specific simulation model of the left heart, proving accurate over ranges of realistic image resolutions and noise levels, as well as superior to alternative approaches. Lastly, the extended νWERP is applied on clinically acquired 4D Flow MRI data, exhibiting realistic ventricular relative pressure patterns, as well as indicating signs of diastolic dysfunction in an exemplifying patient case. Summarized, the extended νWERP approach represents a directly applicable implementation for intracardiac flow assessments. © 2020 The Authors","4D Flow MRI; Cardiac hemodynamics; Dynamic domains; Fluid mechanics; Relative pressure; Virtual work-energy","","Elsevier B.V.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85098474544"
"Rao A.; Hassan S.; Evans D.; Nassr R.; Carruthers D.; Wilson A.S.","Rao, Abhishek (58915311000); Hassan, Sara (57037839300); Evans, Deborah (57221705724); Nassr, Rasheed (54929102600); Carruthers, David (7005297969); Wilson, Andrew Sean (14824312600)","58915311000; 57037839300; 57221705724; 54929102600; 7005297969; 14824312600","A Structured Approach to the Development and Evaluation of a Virtual Reality Eye Examination Simulation","2024","International Journal of Human-Computer Interaction","","","","","","","0","10.1080/10447318.2024.2318535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186395593&doi=10.1080%2f10447318.2024.2318535&partnerID=40&md5=cec197450b63240a1178859cf14178f4","Postgraduate Centre, City Hospital, Sandwell and West Birmingham NHS Trust, Birmingham, United Kingdom; College of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, United Kingdom","Rao A., Postgraduate Centre, City Hospital, Sandwell and West Birmingham NHS Trust, Birmingham, United Kingdom; Hassan S., College of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, United Kingdom; Evans D., College of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, United Kingdom; Nassr R., College of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, United Kingdom; Carruthers D., Postgraduate Centre, City Hospital, Sandwell and West Birmingham NHS Trust, Birmingham, United Kingdom; Wilson A.S., College of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, United Kingdom","Ophthalmoscopy is a required clinical skill which is difficult to learn. This paper describes the development of a VR ophthalmoscopy app to support learning of this skill. It was developed using the Unity game engine, Google CardboardTM and smart phone. Forty-eight clinicians agreed to evaluate it for system usability (SUS), technology acceptance and knowledge acquisition (pre and post quizzes). Twenty-seven volunteers undertook the quiz. Mean scores improved by all (6.3 ± 1.5 to 8.4 ± 0.8 p < 0.001); medical students (6.2 ± 1.5 to 8.5 ± 0.9 p < 0.001 n:20); doctors (6.4 ± 1.5 to 8.3 ± 0.8 p < 0.05 n:7). Overall, SUS was 74 ± 11 (n:33), medical students rating 72 ± 12 (n:20) and doctors 77 ± 9 (n:13). Forty-eight volunteers provided feedback on technology acceptance. All highly rated its ease of use and how it improved their confidence in being able to perform this diagnostic procedure. Regression analyses emphasized the importance of usability, ability to perform the task and ease of use as predictors of success. Ninety percent of users felt that this type of technology would benefit their clinical training but should not replace other forms of teaching. Owing to the lack of technical-focused development frameworks this study also defines an appropriate framework that ensures clinicians are central to the process. © 2024 The Author(s). Published with license by Taylor & Francis Group, LLC.","clinical simulation; medical training; ophthalmology; software development life cycle; Virtual reality","","Taylor and Francis Ltd.","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85186395593"
"Herrero P.; Bondia J.; Giménez M.; Oliver N.; Georgiou P.","Herrero, Pau (8693403100); Bondia, Jorge (6602880910); Giménez, Marga (25926434200); Oliver, Nick (8414954000); Georgiou, Pantelis (16301582200)","8693403100; 6602880910; 25926434200; 8414954000; 16301582200","Automatic Adaptation of Basal Insulin Using Sensor-Augmented Pump Therapy","2018","Journal of Diabetes Science and Technology","12","2","","282","294","12","19","10.1177/1932296818761752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042850296&doi=10.1177%2f1932296818761752&partnerID=40&md5=9ec7364fd2e753caac063d099ae45690","Centre for Bio-Inspired Technology, Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom; Institut Universitari d’Automàtica i Informàtica Industrial, Universitat Politècnica de València, València, Spain; Division of Diabetes, Endocrinology and Metabolism, Department of Medicine, Faculty of Medicine Imperial College, London, United Kingdom; Diabetes Unit, Endocrinology Department, ICMDiM Hospital Clínic, Barcelona, Spain","Herrero P., Centre for Bio-Inspired Technology, Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom; Bondia J., Institut Universitari d’Automàtica i Informàtica Industrial, Universitat Politècnica de València, València, Spain; Giménez M., Division of Diabetes, Endocrinology and Metabolism, Department of Medicine, Faculty of Medicine Imperial College, London, United Kingdom; Oliver N., Diabetes Unit, Endocrinology Department, ICMDiM Hospital Clínic, Barcelona, Spain; Georgiou P., Centre for Bio-Inspired Technology, Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom","Background: People with insulin-dependent diabetes rely on an intensified insulin regimen. Despite several guidelines, they are usually impractical and fall short in achieving optimal glycemic outcomes. In this work, a novel technique for automatic adaptation of the basal insulin profile of people with diabetes on sensor-augmented pump therapy is presented. Methods: The presented technique is based on a run-to-run control law that overcomes some of the limitations of previously proposed methods. To prove its validity, an in silico validation was performed. Finally, the artificial intelligence technique of case-based reasoning is proposed as a potential solution to deal with variability in basal insulin requirements. Results: Over a period of 4 months, the proposed run-to-run control law successfully adapts the basal insulin profile of a virtual population (10 adults, 10 adolescents, and 10 children). In particular, average percentage time in target [70, 180] mg/dl was significantly improved over the evaluated period (first week versus last week): 70.9 ± 11.8 versus 91.1 ± 4.4 (adults), 46.5 ± 11.9 versus 80.1 ± 10.9 (adolescents), 49.4 ± 12.9 versus 73.7 ± 4.1 (children). Average percentage time in hypoglycemia (<70 mg/dl) was also significantly reduced: 9.7 ± 6.6 versus 0.9 ± 1.2 (adults), 10.5 ± 8.3 versus 0.83 ± 1.0 (adolescents), 10.9 ± 6.1 versus 3.2 ± 3.5 (children). When compared against an existing technique over the whole evaluated period, the presented approach achieved superior results on percentage of time in hypoglycemia: 3.9 ± 2.6 versus 2.6 ± 2.2 (adults), 2.9 ± 1.9 versus 2.0 ± 1.5 (adolescents), 4.6 ± 2.8 versus 3.5 ± 2.0 (children), without increasing the percentage time in hyperglycemia. Conclusion: The present study shows the potential of a novel technique to effectively adjust the basal insulin profile of a type 1 diabetes population on sensor-augmented insulin pump therapy. © 2018, © 2018 Diabetes Technology Society.","adaptive control; artificial intelligence; basal insulin; case-based reasoning; run-to-run; type 1 diabetes","","SAGE Publications Inc.","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85042850296"
"Huang D.; Wang X.; Liu J.; Li J.; Tang W.","Huang, Dongjin (35731385000); Wang, Xianglong (57208397335); Liu, Jinhua (57212019049); Li, Jinyao (57221613137); Tang, Wen (55748093500)","35731385000; 57208397335; 57212019049; 57221613137; 55748093500","Virtual reality safety training using deep EEG-net and physiology data","2022","Visual Computer","38","4","","1195","1207","12","17","10.1007/s00371-021-02140-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105488136&doi=10.1007%2fs00371-021-02140-3&partnerID=40&md5=29b0251fd7571450d2ceb65c4bbedd96","Shanghai Film Academy, Shanghai University, Shanghai, China; The Faculty of Science, Design and Technology, University of Bournemouth, Dorset, Poole, United Kingdom","Huang D., Shanghai Film Academy, Shanghai University, Shanghai, China; Wang X., Shanghai Film Academy, Shanghai University, Shanghai, China; Liu J., Shanghai Film Academy, Shanghai University, Shanghai, China; Li J., Shanghai Film Academy, Shanghai University, Shanghai, China; Tang W., The Faculty of Science, Design and Technology, University of Bournemouth, Dorset, Poole, United Kingdom","Virtual reality (VR) safety training systems can enhance safety awareness while supporting health assessment in various work conditions. This paper proposes a novel VR system for construction safety training, which augments an individual’s functioning in VR via a brain–computer interface of electroencephalography (EEG) and physiology data such as blood pressure and heart rate. The use of VR aims to support high levels of interactions and immersion. Crucially, we apply novel clipping training algorithms to improve the performance of a deep EEG neural network, including batch normalization and ELU activation functions for real-time assessment. It significantly improves the system performance in time efficiency while maintaining high accuracy of over 80% on the testing datasets. For assessing workers’ competence under various construction environments, the risk assessment metrics are developed based on a statistical model and workers’ EEG data. One hundred and seventeen construction workers in Shanghai took part in the study. Nine of the participants’ EEG is identified with highly abnormal levels by the proposed evaluation metric. They have undergone further medical examinations, and among them, six are diagnosed with high-risk health conditions. It proves that our system plays a significant role in understanding workers’ physical condition, enhancing safety awareness, and reducing accidents. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Brain–computer interface; Construction safety; EEG neural network; Health assessment; Virtual reality","","Springer Science and Business Media Deutschland GmbH","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85105488136"
"van Meggelen M.; Morina N.; van der Heiden C.; Brinkman W.-P.; Yocarini I.E.; Tielman M.L.; Rodenburg J.; van Ee E.; van Schie K.; Broekman M.E.; Franken I.H.A.","van Meggelen, Marieke (56897263700); Morina, Nexhmedin (57197268422); van der Heiden, Colin (33867856200); Brinkman, Willem-Paul (8707580500); Yocarini, Iris E. (56989845300); Tielman, Myrthe L. (56085264900); Rodenburg, Jan (57214722452); van Ee, Elisa (55351016200); van Schie, Kevin (56989668400); Broekman, Marijke E. (57948683500); Franken, Ingmar H. A. (6603898904)","56897263700; 57197268422; 33867856200; 8707580500; 56989845300; 56085264900; 57214722452; 55351016200; 56989668400; 57948683500; 6603898904","A randomized controlled trial to pilot the efficacy of a computer-based intervention with elements of virtual reality and limited therapist assistance for the treatment of post-traumatic stress disorder","2022","Frontiers in Digital Health","4","","974668","","","","4","10.3389/fdgth.2022.974668","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140966047&doi=10.3389%2ffdgth.2022.974668&partnerID=40&md5=fadf8896de567504e28d178f072f8dc6","Department of Psychology, Child and Education Studies, Erasmus School of Social and Behavioural Sciences, Erasmus University Rotterdam, Rotterdam, Netherlands; Parnassia Group, Outpatient Treatment Center PsyQ, The Hague, Netherlands; Department of Clinical Psychology and Psychotherapy, University of Münster, Münster, Germany; Parnassia Group, Outpatient Treatment Center PsyQ, Rotterdam, Netherlands; Department of Intelligent Systems, Delft University of Technology, Delft, Netherlands; Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands; De Hemisfeer, Praktijk Voor Psychotrauma / Migratieproblematiek, ‘s-Hertogenbosch, Netherlands; Reinier van Arkel, Psychotrauma Centrum Zuid-Nederland, ‘s-Hertogenbosch, Netherlands; Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom","van Meggelen M., Department of Psychology, Child and Education Studies, Erasmus School of Social and Behavioural Sciences, Erasmus University Rotterdam, Rotterdam, Netherlands, Parnassia Group, Outpatient Treatment Center PsyQ, The Hague, Netherlands; Morina N., Department of Clinical Psychology and Psychotherapy, University of Münster, Münster, Germany; van der Heiden C., Department of Psychology, Child and Education Studies, Erasmus School of Social and Behavioural Sciences, Erasmus University Rotterdam, Rotterdam, Netherlands, Parnassia Group, Outpatient Treatment Center PsyQ, Rotterdam, Netherlands; Brinkman W.-P., Department of Intelligent Systems, Delft University of Technology, Delft, Netherlands; Yocarini I.E., Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands; Tielman M.L., Department of Intelligent Systems, Delft University of Technology, Delft, Netherlands; Rodenburg J., De Hemisfeer, Praktijk Voor Psychotrauma / Migratieproblematiek, ‘s-Hertogenbosch, Netherlands; van Ee E., Reinier van Arkel, Psychotrauma Centrum Zuid-Nederland, ‘s-Hertogenbosch, Netherlands, Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; van Schie K., Department of Psychology, Child and Education Studies, Erasmus School of Social and Behavioural Sciences, Erasmus University Rotterdam, Rotterdam, Netherlands, MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom; Broekman M.E., Parnassia Group, Outpatient Treatment Center PsyQ, Rotterdam, Netherlands; Franken I.H.A., Department of Psychology, Child and Education Studies, Erasmus School of Social and Behavioural Sciences, Erasmus University Rotterdam, Rotterdam, Netherlands","Although well-established therapies exist for post-traumatic stress disorder (PTSD), barriers to seek mental health care are high. Technology-based interventions may play a role in improving the reach of efforts to treat, especially when therapist availability is low. The goal of the current randomized controlled trial was to pilot the efficacy of a computer-based trauma intervention with elements of virtual reality (VR; 3MR system) and limited therapist involvement for the treatment of PTSD in a childhood sexual abuse (CSA) and war veteran sample and to compare this to “treatment as usual” (TAU). TAU consisted of evidence-based approaches such as imaginal exposure, EMDR, or narrative exposure therapy. A total of 44 patients with PTSD were included and randomly assigned to 12 sessions of 3MR intervention or TAU (completer n 3MR = 12, TAU = 18). Several measures (PCL-5, BDI-II, OQ-45-2, and the M.I.N.I. 5.0.0.) were administered to measure symptoms of PTSD and depression and scores of overall well-being at pre, post, and a three-month follow-up measurement. Analyses suggest that symptoms of PTSD and depression in the 3MR condition decreased, and overall well-being increased between pre and post measurements. Results did not indicate any clear differences between the treatment conditions over time which suggests that treatment gains of the 3MR intervention seem no less than those of TAU. Finally, both treatment conditions produced similar remission rates of PTSD and depression. Therefore, the 3MR intervention could possibly constitute an appropriate treatment alternative. The small sample size as well as evident drop-out rates in the 3MR condition (45%) do warrant further research. The procedures of this study were approved by the Medical Ethical Research Committee (MERC) of the Erasmus Medical Center in Rotterdam (MEC-NL46279.078.13) and pre-registered via ClinicalTrials.gov (Protocol Record CI1-12-S028-1). 2022 Van Meggelen, Morina, Van Der Heiden, Brinkman, Yocarini, Tielman, Rodenburg, Van Ee, Van Schie, Broekman and Franken.","childhood sexual abuse; computer-based; intervention; post-traumatic stress disorder; PTSD; virtual reality; war veterans","","Frontiers Media S.A.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85140966047"
"Mallik R.; Patel M.; Atkinson B.; Kar P.","Mallik, Ritwika (57202303324); Patel, Mayank (57198082683); Atkinson, Ben (57779380300); Kar, Partha (36965819400)","57202303324; 57198082683; 57779380300; 36965819400","Exploring the Role of Virtual Reality to Support Clinical Diabetes Training—A Pilot Study","2022","Journal of Diabetes Science and Technology","16","4","","844","851","7","10","10.1177/19322968211027847","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109273474&doi=10.1177%2f19322968211027847&partnerID=40&md5=1c18c9367e0aab1b16350e16ac548847","Clinical Research Fellow in Diabetes and Endocrinology, Royal London Hospital, Barts Health NHS Trust, London, United Kingdom; Consultant in Diabetes and Acute Medicine, University Hospital Southampton, Hampshire, Southampton, United Kingdom; Consultant in Emergency Medicine, Wessex Emergency Medicine Simulation Lead, Emergency Department, Portsmouth Hospital University NHS Trust, Cosham, Portsmouth, United Kingdom; Diabetes with NHS England, Consultant in Diabetes Endocrinology, Portsmouth Hospital University NHS Trust, Cosham, Portsmouth, United Kingdom","Mallik R., Clinical Research Fellow in Diabetes and Endocrinology, Royal London Hospital, Barts Health NHS Trust, London, United Kingdom; Patel M., Consultant in Diabetes and Acute Medicine, University Hospital Southampton, Hampshire, Southampton, United Kingdom; Atkinson B., Consultant in Emergency Medicine, Wessex Emergency Medicine Simulation Lead, Emergency Department, Portsmouth Hospital University NHS Trust, Cosham, Portsmouth, United Kingdom; Kar P., Diabetes with NHS England, Consultant in Diabetes Endocrinology, Portsmouth Hospital University NHS Trust, Cosham, Portsmouth, United Kingdom","Background: It is estimated that 16 to 25% of patients in hospital have diabetes and 1 in 25 inpatients with Type 1 Diabetes develop diabetic ketoacidosis (DKA). It is vital that non-specialist doctors recognize and appropriately manage diabetes emergencies. Simulation training is increasingly being used in healthcare and virtual reality (VR) based educational resources is transforming medical education. This study aimed to evaluate the use of virtual reality to help non-specialist clinicians manage clinical scenarios related to diabetes. Methods: This pilot project, titled ‘DEVICE’ (Diabetes Emergencies: Virtual Interactive Clinical Education) was developed in collaboration with Oxford Medical Simulation. Fully interactive immersive VR scenarios were created to stimulate real life diabetes emergencies. Users then received personalized feedback and performance metrics. Feedback surveys were provided before and after the participation in the VR scenario. Kirkpatrick’s training evaluation model was used. Results: Thirty-nine participants from 2 hospitals in UK provided feedback up to 3 months after attending the VR education sessions. Overall feedback was extremely positive, and participants found this immersive teaching experience very helpful. After use of virtual reality scenarios, the mean trainee confidence in managing DKA (on an 8-point Likert scale) increased from 3.92 (3.38-4.47) 95% CI to 5.41 (4.79-6.03) 95% CI (statistically significant). The VR study demonstrates Kirkpatrick level 3 in the follow up survey. Conclusion: VR based training scenarios in this pilot project increased confidence in managing diabetes emergencies and demonstrated positive changes in their behavior. VR education is a safe, useful and a well-liked training tool for diabetes emergencies. © 2021 Diabetes Technology Society.","diabetes; diabetic ketoacidosis; DKA; patients with diabetes; Simulation Based Medical Education; virtual reality","","SAGE Publications Inc.","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85109273474"
"Smith L.N.; Farooq A.R.; Smith M.L.; Ivanov I.E.; Orlando A.","Smith, L.N. (9237709400); Farooq, A.R. (7007061766); Smith, M.L. (55495905800); Ivanov, I.E. (57197556858); Orlando, A. (57190245075)","9237709400; 7007061766; 55495905800; 57197556858; 57190245075","Realistic and interactive high-resolution 4D environments for real-time surgeon and patient interaction","2017","International Journal of Medical Robotics and Computer Assisted Surgery","13","2","e1761","","","","6","10.1002/rcs.1761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978737352&doi=10.1002%2frcs.1761&partnerID=40&md5=4df78f1e3fe0d780be18747dc8466602","Department of Engineering, Design and Mathematics, University of the West of England, Bristol, United Kingdom","Smith L.N., Department of Engineering, Design and Mathematics, University of the West of England, Bristol, United Kingdom; Farooq A.R., Department of Engineering, Design and Mathematics, University of the West of England, Bristol, United Kingdom; Smith M.L., Department of Engineering, Design and Mathematics, University of the West of England, Bristol, United Kingdom; Ivanov I.E., Department of Engineering, Design and Mathematics, University of the West of England, Bristol, United Kingdom; Orlando A., Department of Engineering, Design and Mathematics, University of the West of England, Bristol, United Kingdom","Background: Remote consultations that are realistic enough to be useful medically offer considerable clinical, logistical and cost benefits. Despite advances in virtual reality and vision hardware and software, these benefits are currently often unrealised. Method: The proposed approach combines high spatial and temporal resolution 3D and 2D machine vision with virtual reality techniques, in order to develop new environments and instruments that will enable realistic remote consultations and the generation of new types of useful clinical data. Results: New types of clinical data have been generated for skin analysis and respiration measurement; and the combination of 3D with 2D data was found to offer potential for the generation of realistic virtual consultations. Conclusion: An innovative combination of high resolution machine vision data and virtual reality online methods, promises to provide advanced functionality and significant medical benefits, particularly in regions where populations are dispersed or access to clinicians is limited. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","3d imaging; cancer; capture of new types of clinical data; computer assisted surgery; general surgery; machine vision; modelling; plastic surgery; realistic interactive high-resolution 4D environments; remote medical consultancy/diagnosis; sensors; virtual reality; vision","","John Wiley and Sons Ltd","Article","Final","","Scopus","2-s2.0-84978737352"
"Sadeghi A.H.; Peek J.J.; Max S.A.; Smit L.L.; Martina B.G.; Rosalia R.A.; Bakhuis W.; Bogers A.J.J.C.; Mahtab E.A.F.","Sadeghi, Amir H. (57216637508); Peek, Jette J. (57366182700); Max, Samuel A. (57395885500); Smit, Liselot L. (57489864800); Martina, Bryan G. (57490341700); Rosalia, Rodney A. (23499317700); Bakhuis, Wouter (57226565628); Bogers, Ad J.J.C. (35479551300); Mahtab, Edris A.F. (16022407600)","57216637508; 57366182700; 57395885500; 57489864800; 57490341700; 23499317700; 57226565628; 35479551300; 16022407600","Virtual Reality Simulation Training for Cardiopulmonary Resuscitation After Cardiac Surgery: Face and Content Validity Study","2022","JMIR Serious Games","10","1","e30456","","","","14","10.2196/30456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126450563&doi=10.2196%2f30456&partnerID=40&md5=022874e5174ffe5aa7c4a92e1c945621","Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands; Educational Program Technical Medicine, Leiden University Medical Center, Delft University of Technology, Erasmus University Medical Center Rotterdam, Delft, Rotterdam, Leiden, Netherlands; Medical Sciences Division, University of Oxford, Oxford, United Kingdom; Department of Clinical Research, Zan Mitrev Clinic, Skopje, North Macedonia","Sadeghi A.H., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands; Peek J.J., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands, Educational Program Technical Medicine, Leiden University Medical Center, Delft University of Technology, Erasmus University Medical Center Rotterdam, Delft, Rotterdam, Leiden, Netherlands; Max S.A., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands, Medical Sciences Division, University of Oxford, Oxford, United Kingdom; Smit L.L., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands; Martina B.G., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands; Rosalia R.A., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands, Department of Clinical Research, Zan Mitrev Clinic, Skopje, North Macedonia; Bakhuis W., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands; Bogers A.J.J.C., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands; Mahtab E.A.F., Department of Cardiothoracic Surgery, Erasmus University Medical Center, Rotterdam, Netherlands","Background: Cardiac arrest after cardiac surgery commonly has a reversible cause, where emergency resternotomy is often required for treatment, as recommended by international guidelines. We have developed a virtual reality (VR) simulation for training of cardiopulmonary resuscitation (CPR) and emergency resternotomy procedures after cardiac surgery, the Cardiopulmonary Resuscitation Virtual Reality Simulator (CPVR-sim). Two fictive clinical scenarios were used: one case of pulseless electrical activity (PEA) and a combined case of PEA and ventricular fibrillation. In this prospective study, we researched the face validity and content validity of the CPVR-sim. Objective: We designed a prospective study to assess the feasibility and to establish the face and content validity of two clinical scenarios (shockable and nonshockable cardiac arrest) of the CPVR-sim partly divided into a group of novices and experts in performing CPR and emergency resternotomies in patients after cardiac surgery. Methods: Clinicians (staff cardiothoracic surgeons, physicians, surgical residents, nurse practitioners, and medical students) participated in this study and performed two different scenarios, either PEA or combined PEA and ventricular fibrillation. All participants (N=41) performed a simulation and completed the questionnaire rating the simulator's usefulness, satisfaction, ease of use, effectiveness, and immersiveness to assess face validity and content validity. Results: Responses toward face validity and content validity were predominantly positive in both groups. Most participants in the PEA scenario (n=26, 87%) felt actively involved in the simulation, and 23 (77%) participants felt in charge of the situation. The participants thought it was easy to learn how to interact with the software (n=24, 80%) and thought that the software responded adequately (n=21, 70%). All 15 (100%) expert participants preferred VR training as an addition to conventional training. Moreover, 13 (87%) of the expert participants would recommend VR training to other colleagues, and 14 (93%) of the expert participants thought the CPVR-sim was a useful method to train for infrequent post-cardiac surgery emergencies requiring CPR. Additionally, 10 (91%) of the participants thought it was easy to move in the VR environment, and that the CPVR-sim responded adequately in this scenario. Conclusions: We developed a proof-of-concept VR simulation for CPR training with two scenarios of a patient after cardiac surgery, which participants found was immersive and useful. By proving the face validity and content validity of the CPVR-sim, we present the first step toward a cardiothoracic surgery VR training platform. © 2022 JMIR Publications Inc.. All right reserved.","cardiac surgery; cardiopulmonary resuscitation; digital health; emergency resternotomy; medical training; serious games;virtual reality simulation; simulation training; virtual reality; virtual training","","JMIR Publications Inc.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126450563"
"Park J.J.; Tiefenbach J.; Demetriades A.K.","Park, Jay J. (57223873479); Tiefenbach, Jakov (57211014747); Demetriades, Andreas K. (7004877691)","57223873479; 57211014747; 7004877691","The role of artificial intelligence in surgical simulation","2022","Frontiers in Medical Technology","4","","1076755","","","","12","10.3389/fmedt.2022.1076755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158075546&doi=10.3389%2ffmedt.2022.1076755&partnerID=40&md5=e0040b97e088bfcad6c04208fbf19071","Department of General Surgery, Norfolk and Norwich University Hospital, Norwich, United Kingdom; Edinburgh Medical School, University of Edinburgh, Edinburgh, United Kingdom; Neurological Institute, Cleveland Clinic, Cleveland, OH, United States; Department of Neurosurgery, Royal Infirmary of Edinburgh, Edinburgh, United Kingdom","Park J.J., Department of General Surgery, Norfolk and Norwich University Hospital, Norwich, United Kingdom, Edinburgh Medical School, University of Edinburgh, Edinburgh, United Kingdom; Tiefenbach J., Neurological Institute, Cleveland Clinic, Cleveland, OH, United States; Demetriades A.K., Edinburgh Medical School, University of Edinburgh, Edinburgh, United Kingdom, Department of Neurosurgery, Royal Infirmary of Edinburgh, Edinburgh, United Kingdom","Artificial Intelligence (AI) plays an integral role in enhancing the quality of surgical simulation, which is increasingly becoming a popular tool for enriching the training experience of a surgeon. This spans the spectrum from facilitating preoperative planning, to intraoperative visualisation and guidance, ultimately with the aim of improving patient safety. Although arguably still in its early stages of widespread clinical application, AI technology enables personal evaluation and provides personalised feedback in surgical training simulations. Several forms of surgical visualisation technologies currently in use for anatomical education and presurgical assessment rely on different AI algorithms. However, while it is promising to see clinical examples and technological reports attesting to the efficacy of AI-supported surgical simulators, barriers to wide-spread commercialisation of such devices and software remain complex and multifactorial. High implementation and production costs, scarcity of reports evidencing the superiority of such technology, and intrinsic technological limitations remain at the forefront. As AI technology is key to driving the future of surgical simulation, this paper will review the literature delineating its current state, challenges, and prospects. In addition, a consolidated list of FDA/CE approved AI-powered medical devices for surgical simulation is presented, in order to shed light on the existing gap between academic achievements and the universal commercialisation of AI-enabled simulators. We call for further clinical assessment of AI-supported surgical simulators to support novel regulatory body approved devices and usher surgery into a new era of surgical education. 2022 Park, Tiefenbach and Demetriades.","artificial intelligence (AI); augemented reality; deep learning; machine learning; mixed reality; surgical simulation; surgical training; virtual reality","","Frontiers Media S.A.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85158075546"
"Phellan R.; Lindner T.; Helle M.; Falcão A.X.; Okell T.W.; Forkert N.D.","Phellan, Renzo (56319193000); Lindner, Thomas (56562662000); Helle, Michael (23024457400); Falcão, Alexandre X. (7006331391); Okell, Thomas W. (36026997900); Forkert, Nils D. (16549854100)","56319193000; 56562662000; 23024457400; 7006331391; 36026997900; 16549854100","A methodology for generating four-dimensional arterial spin labeling MR angiography virtual phantoms","2019","Medical Image Analysis","56","","","184","192","8","2","10.1016/j.media.2019.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067514240&doi=10.1016%2fj.media.2019.06.002&partnerID=40&md5=c45144be7f388a1172f89fccf7c3d664","Department of Radiology and Hotchkiss Brains Institute, University of Calgary, Calgary, AB, Canada; Clinic for Radiology and Neuroradiology, University Medical Center Schleswig-Holstein, Kiel, Germany; Philips Technologie GmbH, Innovative Technologies, Hamburg, Germany; Laboratory of Image Data Science Institute of Computing, University of Campinas, Campinas, SP, Brazil; Wellcome Centre for Integrative Neuroimaging FMRIB Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, United Kingdom","Phellan R., Department of Radiology and Hotchkiss Brains Institute, University of Calgary, Calgary, AB, Canada; Lindner T., Clinic for Radiology and Neuroradiology, University Medical Center Schleswig-Holstein, Kiel, Germany; Helle M., Philips Technologie GmbH, Innovative Technologies, Hamburg, Germany; Falcão A.X., Laboratory of Image Data Science Institute of Computing, University of Campinas, Campinas, SP, Brazil; Okell T.W., Wellcome Centre for Integrative Neuroimaging FMRIB Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, United Kingdom; Forkert N.D., Department of Radiology and Hotchkiss Brains Institute, University of Calgary, Calgary, AB, Canada","Four-dimensional arterial spin labeling magnetic resonance angiography (4D ASL MRA) is a non-invasive medical imaging modality that can be used for anatomical and hemodynamic analysis of the cerebrovascular system. However, it generates a considerable amount of data, which is tedious to analyze visually. As an alternative, medical image processing methods can be used to process the data and present measurements of the geometry and blood flow in the cerebrovascular system to the user, such as vessel radius, tortuosity, blood flow volume, and transit time. Nevertheless, evaluating medical image processing methods developed for this modality requires annotated data, which can be time-consuming and expensive to obtain. Alternatively, virtual simulations are a faster and less expensive option that can be used for initial evaluation of image processing methods. The present work proposes a methodology for generating annotated 4D ASL MRA virtual phantoms, in different scenarios with different acquisition parameter settings. In each scenario, the phantoms are generated using real cerebrovascular geometries of healthy volunteers, where blood flow is simulated according to a mathematical model specifically designed to describe the signal observed in 4D ASL MRA images. Realistic noise is added using an homomorphic approach, designed to replicate noise characteristic of multi-coil acquisitions. In order to exemplify the utility of the phantoms, they are used to evaluate the accuracy of a method to estimate blood flow parameter values, such as relative blood volume and transit time, in different scenarios. The estimated values are then compared to its corresponding virtual ground-truth values. The accuracy of the results is ranked according to the average absolute error. The results of the experiments show that blood flow parameters can be more accurately estimated when blood is magnetically labeled for longer periods of time and when the datasets are acquired with higher temporal resolution. In summary, the present work describes a methodology to create annotated virtual phantoms, which represent a useful alternative for initial evaluation of medical image processing methods for 4D ASL MRA images. © 2019 Elsevier B.V.","Angiography; Arterial spin labeling; Blood flow analysis; Cerebrovascular imaging; Phantom models","","Elsevier B.V.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85067514240"
"Yamin H.G.; Gazit T.; Tchemodanov N.; Raz G.; Jackont G.; Charles F.; Fried I.; Hendler T.; Cavazza M.","Yamin, Hagar Grazya (55549754900); Gazit, Tomer (22957486200); Tchemodanov, Natalia (57196416497); Raz, Gal (54996059200); Jackont, Gilan (56150774300); Charles, Fred (7007088055); Fried, Itzhak (7006553962); Hendler, Talma (7004564546); Cavazza, Marc (7007101480)","55549754900; 22957486200; 57196416497; 54996059200; 56150774300; 7007088055; 7006553962; 7004564546; 7007101480","Depth electrode neurofeedback with a virtual reality interface*","2017","Brain-Computer Interfaces","4","4","","201","213","12","12","10.1080/2326263X.2017.1338008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056818438&doi=10.1080%2f2326263X.2017.1338008&partnerID=40&md5=efb67b8aefb62b85fec6f650ee6846b3","Center for Brain Functions, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel; Department of Neurosurgery, David Geffen School of Medicine and Semel Institute for Neuroscience and Human Behavior, University of California Los Angeles, Los Angeles, CA, United States; Department of Creative Technology, Faculty of Science and Technology, Bournemouth University, Poole, United Kingdom; Functional Neurosurgery Unit, Tel-Aviv Medical Center and Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel; School of Engineering and Digital Arts, University of Kent, Canterbury, United Kingdom","Yamin H.G., Center for Brain Functions, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel; Gazit T., Center for Brain Functions, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel; Tchemodanov N., Department of Neurosurgery, David Geffen School of Medicine and Semel Institute for Neuroscience and Human Behavior, University of California Los Angeles, Los Angeles, CA, United States; Raz G., Center for Brain Functions, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel; Jackont G., Center for Brain Functions, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel; Charles F., Department of Creative Technology, Faculty of Science and Technology, Bournemouth University, Poole, United Kingdom; Fried I., Department of Neurosurgery, David Geffen School of Medicine and Semel Institute for Neuroscience and Human Behavior, University of California Los Angeles, Los Angeles, CA, United States, Functional Neurosurgery Unit, Tel-Aviv Medical Center and Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel; Hendler T., Center for Brain Functions, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel; Cavazza M., School of Engineering and Digital Arts, University of Kent, Canterbury, United Kingdom","Invasive brain–computer interfaces (BCI) provide better signal quality in terms of spatial localization, frequencies and signal/noise ratio, in addition to giving access to deep brain regions that play important roles in cognitive or affective processes. Despite some anecdotal attempts, little work has explored the possibility of integrating such BCI input into more sophisticated interactive systems like those which can be developed with game engines. In this article, we integrated an amygdala depth electrode recorder with a virtual environment controlling a virtual crowd. Subjects were asked to down regulate their amygdala using the level of unrest in the virtual room as feedback on how successful they were. We report early results which suggest that users adapt very easily to this paradigm and that the timing and fluctuations of amygdala activity during self-regulation can be matched by crowd animation in the virtual room. This suggests that depth electrodes could also serve as high-performance affective interfaces, notwithstanding their strictly limited availability, justified on medical grounds only. © 2017, © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Application development and evaluation; Brain–computer interface (BCI); electroencephalogram (EEG); intracranial depth electrodes; neurofeedback (NF); neurosurgical approaches and methods, affective computing; signal acquisition: EEG (other)","","Taylor and Francis Ltd.","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85056818438"
"Ashmore J.; Di Pietro J.; Williams K.; Stokes E.; Symons A.; Smith M.; Clegg L.; McGrath C.","Ashmore, Jonathan (57216028733); Di Pietro, Jerome (57220907611); Williams, Kelly (57220907496); Stokes, Euan (57220907605); Symons, Anna (57220907469); Smith, Martina (57198460551); Clegg, Louise (57220907571); McGrath, Cormac (57198091910)","57216028733; 57220907611; 57220907496; 57220907605; 57220907469; 57198460551; 57220907571; 57198091910","A free virtual reality experience to prepare pediatric patients for magnetic resonance imaging: Cross-sectional questionnaire study","2019","JMIR Pediatrics and Parenting","2","1","e11684","","","","40","10.2196/11684","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097141282&doi=10.2196%2f11684&partnerID=40&md5=b4944e160741f8d90ade0adab8c988d1","Department of Medical Physics and Bioengineering, NHS Highland, Old Perth Road, Inverness, United Kingdom; Department of Neuroradiology, King's College Hospital, London, United Kingdom; Centre for Neuroimaging Sciences, King's College London, London, United Kingdom; Faculty of Life Sciences and Medicine, King's College London, London, United Kingdom; King's College Hospital, London, United Kingdom; South London and the Maudsley NHS Trust, London, United Kingdom; Radiological Sciences and Imaging, Regional Medical Physics Service, Belfast Health and Social Care Trust, Belfast, United Kingdom","Ashmore J., Department of Medical Physics and Bioengineering, NHS Highland, Old Perth Road, Inverness, United Kingdom, Department of Neuroradiology, King's College Hospital, London, United Kingdom, Centre for Neuroimaging Sciences, King's College London, London, United Kingdom; Di Pietro J., Faculty of Life Sciences and Medicine, King's College London, London, United Kingdom; Williams K., King's College Hospital, London, United Kingdom; Stokes E., Department of Neuroradiology, King's College Hospital, London, United Kingdom; Symons A., Department of Neuroradiology, King's College Hospital, London, United Kingdom; Smith M., Department of Neuroradiology, King's College Hospital, London, United Kingdom; Clegg L., South London and the Maudsley NHS Trust, London, United Kingdom; McGrath C., Radiological Sciences and Imaging, Regional Medical Physics Service, Belfast Health and Social Care Trust, Belfast, United Kingdom","Background: A magnetic resonance image (MRI) is a diagnostic test that requires patients to lie still for prolonged periods within a claustrophobic and noisy environment. This can be difficult for children to tolerate, and often general anesthetic (GA) is required at considerable cost and detriment to patient safety. Virtual reality (VR) is a newly emerging technology that can be implemented at low cost within a health care setting. It has been shown to reduce fear associated with a number of high-anxiety situations and medical procedures. Objective: The goal of the research was to develop a VR resource to prepare pediatric patients for MRI, helping to reduce anxieties in children undergoing the procedure. Methods: A freely accessible VR preparation resource was developed to prepare pediatric patients for their upcoming MRI. The resource consists of an app and supporting preparation book and used a series of panoramic 360 degree videos of the entire MRI journey, including footage from within the bore of the scanner. The app, deployed via the Android Play Store and iOS App Store, can be viewed on most mobile phones, allowing a child to experience an MRI in VR using an inexpensive Google Cardboard headset. The app contains 360 degree videos within an animated, interactive VR interface designed for 4 to 12-year-olds. The resource was evaluated as part of a clinical audit on 23 patients (aged 4 to 12 years), and feedback was obtained from 10 staff members. In 5 patients, the resource was evaluated as a tool to prepare patients for an awake MRI who otherwise were booked to have an MRI under GA. Results: The VR preparation resource has been successfully implemented at 3 UK institutions. Of the 23 patients surveyed, on a scale of 1 to 10, the VR resource was rated with a median score of 8.5 for enjoyment, 8 for helpfulness, and 10 for ease of use. All patients agreed that it made them feel more positive about their MRI, and all suggested they would recommend the resource to other children. When considering their experiences using the resource with pediatric patients, on a scale of 1 to 10, the staff members rated the VR resource a median score of 8.5 for enjoyment, 9 for helpfulness, and 9 for ease of use. All staff believed it could help prepare children for an awake MRI, thus avoiding GA. A successful awake MRI was achieved in 4 of the 5 children for whom routine care would have resulted in an MRI under GA. Conclusions: Our VR resource has the potential to relieve anxieties and better prepare patients for an awake MRI. The resource has potential to avoid GA through educating the child about the MRI process. © Jonathan Ashmore, Jerome Di Pietro, Kelly Williams, Euan Stokes, Anna Symons, Martina Smith, Louise Clegg, Cormac McGrath.","Anxiety; MRI; Virtual reality","","JMIR Publications Inc.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85097141282"
"Zhou K.; Cai R.; Ma Y.; Tan Q.; Wang X.; Li J.; Shum H.P.H.; Li F.W.B.; Jin S.; Liang X.","Zhou, Kanglei (57205674291); Cai, Ruizhi (58128062700); Ma, Yue (57218566782); Tan, Qingqing (58123647200); Wang, Xinning (57193015804); Li, Jianguo (56540149100); Shum, Hubert P. H. (25032239300); Li, Frederick W. B. (7406057098); Jin, Song (58127881700); Liang, Xiaohui (7401735847)","57205674291; 58128062700; 57218566782; 58123647200; 57193015804; 56540149100; 25032239300; 7406057098; 58127881700; 7401735847","A Video-Based Augmented Reality System for Human-in-the-Loop Muscle Strength Assessment of Juvenile Dermatomyositis","2023","IEEE Transactions on Visualization and Computer Graphics","29","5","","2456","2466","10","3","10.1109/TVCG.2023.3247092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149403925&doi=10.1109%2fTVCG.2023.3247092&partnerID=40&md5=19cb8a0049131064850052fe985ec74f","Beihang University, State Key Laboratory of Virtual Reality Technology and Systems, Beijing, China; Zhongguancun Laboratory, Beijing, China; Beihang University, Beijing, China; Children's Hospital of Capital Institute of Pediatrics, Beijing, China; Durham University, Durham, United Kingdom; Beijing Diannaite Medical Technology Co., Ltd., China","Zhou K., Beihang University, Beijing, China; Cai R., Beihang University, Beijing, China; Ma Y., Beihang University, Beijing, China; Tan Q., Children's Hospital of Capital Institute of Pediatrics, Beijing, China; Wang X., Children's Hospital of Capital Institute of Pediatrics, Beijing, China; Li J., Children's Hospital of Capital Institute of Pediatrics, Beijing, China; Shum H.P.H., Durham University, Durham, United Kingdom; Li F.W.B., Durham University, Durham, United Kingdom; Jin S., Beijing Diannaite Medical Technology Co., Ltd., China; Liang X., Beihang University, State Key Laboratory of Virtual Reality Technology and Systems, Beijing, China, Zhongguancun Laboratory, Beijing, China","As the most common idiopathic inflammatory myopathy in children, juvenile dermatomyositis (JDM) is characterized by skin rashes and muscle weakness. The childhood myositis assessment scale (CMAS) is commonly used to measure the degree of muscle involvement for diagnosis or rehabilitation monitoring. On the one hand, human diagnosis is not scalable and may be subject to personal bias. On the other hand, automatic action quality assessment (AQA) algorithms cannot guarantee 100% accuracy, making them not suitable for biomedical applications. As a solution, we propose a video-based augmented reality system for human-in-the-loop muscle strength assessment of children with JDM. We first propose an AQA algorithm for muscle strength assessment of JDM using contrastive regression trained by a JDM dataset. Our core insight is to visualize the AQA results as a virtual character facilitated by a 3D animation dataset, so that users can compare the real-world patient and the virtual character to understand and verify the AQA results. To allow effective comparisons, we propose a video-based augmented reality system. Given a feed, we adapt computer vision algorithms for scene understanding, evaluate the optimal way of augmenting the virtual character into the scene, and highlight important parts for effective human verification. The experimental results confirm the effectiveness of our AQA algorithm, and the results of the user study demonstrate that humans can more accurately and quickly assess the muscle strength of children using our system.  © 1995-2012 IEEE.","Action Quality Assessment; Augmented Reality; Human-in-the-Loop System; Juvenile Dermatomyositis","","IEEE Computer Society","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85149403925"
"Li M.; Wu Z.; Zhao C.-G.; Yuan H.; Wang T.; Xie J.; Xu G.; Luo S.","Li, Min (55268532700); Wu, Zonglin (57670871600); Zhao, Chen-Guang (57194507695); Yuan, Hua (7402446661); Wang, Tianci (57768874100); Xie, Jun (57037472500); Xu, Guanghua (55632209100); Luo, Shan (56028986000)","55268532700; 57670871600; 57194507695; 7402446661; 57768874100; 57037472500; 55632209100; 56028986000","Facial Expressions-Controlled Flight Game With Haptic Feedback for Stroke Rehabilitation: A Proof-of-Concept Study","2022","IEEE Robotics and Automation Letters","7","3","","6351","6358","7","2","10.1109/LRA.2022.3170214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129678379&doi=10.1109%2fLRA.2022.3170214&partnerID=40&md5=87be05634b47d4452238aea9b1ee8473","Xi'an Jiaotong University, Department of Mechanical Engineering, Xi'an, 710049, China; Fourth Military Medical University, Department of Rehabilitation, Xijing Hospital, Xi'an, 710032, China; King's College London, Department of Engineering, London, WC2R 2LS, United Kingdom","Li M., Xi'an Jiaotong University, Department of Mechanical Engineering, Xi'an, 710049, China; Wu Z., Xi'an Jiaotong University, Department of Mechanical Engineering, Xi'an, 710049, China; Zhao C.-G., Fourth Military Medical University, Department of Rehabilitation, Xijing Hospital, Xi'an, 710032, China; Yuan H., Fourth Military Medical University, Department of Rehabilitation, Xijing Hospital, Xi'an, 710032, China; Wang T., Xi'an Jiaotong University, Department of Mechanical Engineering, Xi'an, 710049, China; Xie J., Xi'an Jiaotong University, Department of Mechanical Engineering, Xi'an, 710049, China; Xu G., Xi'an Jiaotong University, Department of Mechanical Engineering, Xi'an, 710049, China; Luo S., King's College London, Department of Engineering, London, WC2R 2LS, United Kingdom","Most stroke patients suffer from a combination of motor and sensory dysfunction and central facial paralysis. Specific rehabilitation training is required to restore those functions. Current research focuses on developing stimulating and straightforward rehabilitation training processes so that patients adhere to the training at home after hospital release. This study proposes enhancing patients' enthusiasm to participate in facial muscle exercises and improving their postural perception and balance by controlling virtual objects to complete assigned tasks in virtual reality games using different facial expressions with the assistance of haptic feedback. The different rehabilitation exercises for motor, sensory, and facial dysfunctions were combined in one virtual reality game for the first time. The proposed haptic feedback device was modeled, simulated, and characterized. A user study was conducted to validate the proposed system. The experiment result shows that all the designed functions of the comprehensive stroke rehabilitation virtual reality game can be achieved. The added haptic feedback enhances the performance of the aircraft control with facial expressions by lowering the trajectory deviation by 22.57%. This implies that the proposed game may improve users' performance, thus attracting them to conduct more training.  © 2016 IEEE.","Haptic feedback; stroke rehabilitation; virtual reality rehabilitation game","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85129678379"
"İncetan K.; Celik I.O.; Obeid A.; Gokceler G.I.; Ozyoruk K.B.; Almalioglu Y.; Chen R.J.; Mahmood F.; Gilbert H.; Durr N.J.; Turan M.","İncetan, Kağan (57214363192); Celik, Ibrahim Omer (57219789225); Obeid, Abdulhamid (57219786011); Gokceler, Guliz Irem (57219760594); Ozyoruk, Kutsev Bengisu (57219768168); Almalioglu, Yasin (57197764273); Chen, Richard J. (57202356119); Mahmood, Faisal (56647751100); Gilbert, Hunter (36975766200); Durr, Nicholas J. (16303771500); Turan, Mehmet (56585517200)","57214363192; 57219789225; 57219786011; 57219760594; 57219768168; 57197764273; 57202356119; 56647751100; 36975766200; 16303771500; 56585517200","VR-Caps: A Virtual Environment for Capsule Endoscopy","2021","Medical Image Analysis","70","","101990","","","","47","10.1016/j.media.2021.101990","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101407908&doi=10.1016%2fj.media.2021.101990&partnerID=40&md5=469066b46865642f95b0eed3832dbab1","Institute of Biomedical Engineering, Bogazici University, Istanbul, Turkey; Department of Computer Engineering, Bogazici University, Istanbul, Turkey; Computer Science Department, University of Oxford, Oxford, United Kingdom; Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States; Cancer Data Science, Dana Farber Cancer Institute, Boston, MA, United States; Cancer Program, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States; Deparment of Mechanical and Industrial Engineering, Louisiana State University, Baton Rouge, LA, United States; Department of Biomedical Engineering, Johns Hopkins University (JHU), Baltimore, MD, United States","İncetan K., Institute of Biomedical Engineering, Bogazici University, Istanbul, Turkey; Celik I.O., Department of Computer Engineering, Bogazici University, Istanbul, Turkey; Obeid A., Institute of Biomedical Engineering, Bogazici University, Istanbul, Turkey; Gokceler G.I., Institute of Biomedical Engineering, Bogazici University, Istanbul, Turkey; Ozyoruk K.B., Institute of Biomedical Engineering, Bogazici University, Istanbul, Turkey; Almalioglu Y., Computer Science Department, University of Oxford, Oxford, United Kingdom; Chen R.J., Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States, Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States; Mahmood F., Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States, Cancer Data Science, Dana Farber Cancer Institute, Boston, MA, United States, Cancer Program, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Gilbert H., Deparment of Mechanical and Industrial Engineering, Louisiana State University, Baton Rouge, LA, United States; Durr N.J., Department of Biomedical Engineering, Johns Hopkins University (JHU), Baltimore, MD, United States; Turan M., Institute of Biomedical Engineering, Bogazici University, Istanbul, Turkey","Current capsule endoscopes and next-generation robotic capsules for diagnosis and treatment of gastrointestinal diseases are complex cyber-physical platforms that must orchestrate complex software and hardware functions. The desired tasks for these systems include visual localization, depth estimation, 3D mapping, disease detection and segmentation, automated navigation, active control, path realization and optional therapeutic modules such as targeted drug delivery and biopsy sampling. Data-driven algorithms promise to enable many advanced functionalities for capsule endoscopes, but real-world data is challenging to obtain. Physically-realistic simulations providing synthetic data have emerged as a solution to the development of data-driven algorithms. In this work, we present a comprehensive simulation platform for capsule endoscopy operations and introduce VR-Caps, a virtual active capsule environment that simulates a range of normal and abnormal tissue conditions (e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope designs (e.g., mono, stereo, dual and 360∘ camera), and the type, number, strength, and placement of internal and external magnetic sources that enable active locomotion. VR-Caps makes it possible to both independently or jointly develop, optimize, and test medical imaging and analysis software for the current and next-generation endoscopic capsule systems. To validate this approach, we train state-of-the-art deep neural networks to accomplish various medical image analysis tasks using simulated data from VR-Caps and evaluate the performance of these models on real medical data. Results demonstrate the usefulness and effectiveness of the proposed virtual platform in developing algorithms that quantify fractional coverage, camera trajectory, 3D map reconstruction, and disease classification. All of the code, pre-trained weights and created 3D organ models of the virtual environment with detailed instructions how to setup and use the environment are made publicly available at https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy and a video demonstration can be seen in the supplementary videos (Video-I). © 2021 Elsevier B.V.","Area coverage; Capsule endoscopy; Deep reinforcement learning; Disease classification; Synthetic data generation","","Elsevier B.V.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85101407908"
"Howgate D.; Oliver M.; Stebbins J.; Roberts P.G.; Kendrick B.; Rees J.; Taylor S.","Howgate, Daniel (35310602200); Oliver, Michael (58000613600); Stebbins, Julie (9242974700); Roberts, Patrick Garfjeld (58165269500); Kendrick, Ben (14064679200); Rees, Jonathan (55597569300); Taylor, Stephen (58002135600)","35310602200; 58000613600; 9242974700; 58165269500; 14064679200; 55597569300; 58002135600","Validating the accuracy of a novel virtual reality platform for determining implant orientation in simulated primary total hip replacement","2022","Digital Health","8","","","","","","0","10.1177/20552076221141215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143754194&doi=10.1177%2f20552076221141215&partnerID=40&md5=e631eda7145f0c879b3c056bc6a88d96","Nuffield Department of Orthopaedics Rheumatology and Musculoskeletal Sciences, The Botnar Research Centre, University of Oxford, Oxford, United Kingdom; NIHR Oxford Biomedical Research Centre, The Joint Research Office, Oxford, United Kingdom; Oxford University Hospitals NHS Foundation Trust Nuffield Orthopaedic Centre, Oxfordshire, Oxford, United Kingdom; Dinwoodie Charitable Company, Royal College of Surgeons of England Research, London, United Kingdom; The MRC Weatherall Institute of Molecular Medicine, Oxford, United Kingdom; London, United Kingdom","Howgate D., Nuffield Department of Orthopaedics Rheumatology and Musculoskeletal Sciences, The Botnar Research Centre, University of Oxford, Oxford, United Kingdom, NIHR Oxford Biomedical Research Centre, The Joint Research Office, Oxford, United Kingdom, Oxford University Hospitals NHS Foundation Trust Nuffield Orthopaedic Centre, Oxfordshire, Oxford, United Kingdom, Dinwoodie Charitable Company, Royal College of Surgeons of England Research, London, United Kingdom, London, United Kingdom; Oliver M., The MRC Weatherall Institute of Molecular Medicine, Oxford, United Kingdom; Stebbins J., Nuffield Department of Orthopaedics Rheumatology and Musculoskeletal Sciences, The Botnar Research Centre, University of Oxford, Oxford, United Kingdom, NIHR Oxford Biomedical Research Centre, The Joint Research Office, Oxford, United Kingdom, Oxford University Hospitals NHS Foundation Trust Nuffield Orthopaedic Centre, Oxfordshire, Oxford, United Kingdom, London, United Kingdom; Roberts P.G., Nuffield Department of Orthopaedics Rheumatology and Musculoskeletal Sciences, The Botnar Research Centre, University of Oxford, Oxford, United Kingdom, NIHR Oxford Biomedical Research Centre, The Joint Research Office, Oxford, United Kingdom, Oxford University Hospitals NHS Foundation Trust Nuffield Orthopaedic Centre, Oxfordshire, Oxford, United Kingdom, London, United Kingdom; Kendrick B., Nuffield Department of Orthopaedics Rheumatology and Musculoskeletal Sciences, The Botnar Research Centre, University of Oxford, Oxford, United Kingdom, Oxford University Hospitals NHS Foundation Trust Nuffield Orthopaedic Centre, Oxfordshire, Oxford, United Kingdom, London, United Kingdom; Rees J., Nuffield Department of Orthopaedics Rheumatology and Musculoskeletal Sciences, The Botnar Research Centre, University of Oxford, Oxford, United Kingdom, NIHR Oxford Biomedical Research Centre, The Joint Research Office, Oxford, United Kingdom, Oxford University Hospitals NHS Foundation Trust Nuffield Orthopaedic Centre, Oxfordshire, Oxford, United Kingdom, London, United Kingdom; Taylor S., The MRC Weatherall Institute of Molecular Medicine, Oxford, United Kingdom","Introduction: Accurate acetabular cup and femoral stem component orientation are critical for optimising patient outcomes, reducing complications and increasing component longevity following total hip replacement (THR). This study aimed to determine the accuracy of a novel virtual reality (VR) platform in assessing component orientation in a simulated THR model. Methods: The VR platform (HTC Vive Pro® system hardware) was compared against the validated Vicon® optical motion capture (MoCap) system. An acetabular cup and femoral stem were manually implanted across a range of orientations into pelvic and femur sawbones, respectively. Simultaneous readings of the acetabular cup operative anteversion (OA) and inclination (OI) and femoral stem alignment (FSA) and neck anteversion (FNA) were obtained from the VR and MoCap systems. Statistical analysis was performed using Pearson product-moment correlation coefficient (PPMCC) (Pearson’s r) and linear regression (R2). Results: A total of 55 readings were obtained for the acetabular cup and 68 for the femoral stem model. The mean average differences in OA, OI, FSA and FNA between the systems were 3.44°, −0.01°, 0.01° and −0.04°, respectively. Strong positive correlations were demonstrated between both systems in OA, OI, FSA and FNA, with Pearson’s r = 0.92, 0.94, 0.99 and 0.99, and adjusted R2 = 0.82, 0.9, 0.98 and 0.98, respectively. Conclusion: The novel VR platform is highly accurate and reliable in determining both acetabular cup and femoral stem component orientations in simulated THR models. This adaptable and cost-effective digital tracking platform may be modified for use in a range of simulated surgical training and educational purposes, particularly in orthopaedic surgery. © The Author(s) 2022.","implant positioning; medical education; surgical simulation; surgical training; Total hip replacement; virtual reality","","SAGE Publications Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85143754194"
"O'Sullivan K.K.; Wilde K.J.","O'Sullivan, Katherine K. (58502622600); Wilde, Katie J. (54974805200)","58502622600; 54974805200","A profile of the Grampian Data Safe Haven, a regional Scottish safe haven for health and population data research","2019","International journal of population data science","4","2","","1817","","","1","10.23889/ijpds.v4i2.1817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169758875&doi=10.23889%2fijpds.v4i2.1817&partnerID=40&md5=44dca8da9231585e9de0e6ef50b7fae5","University of Aberdeen, Polwarth Building ,Foresterhill, Aberdeen, AB25 2ZD, United Kingdom","O'Sullivan K.K., University of Aberdeen, Polwarth Building ,Foresterhill, Aberdeen, AB25 2ZD, United Kingdom; Wilde K.J., University of Aberdeen, Polwarth Building ,Foresterhill, Aberdeen, AB25 2ZD, United Kingdom","There has been a recent emphasis to establish and codify large-scale or national Trusted Research Environments (TREs) in the United Kingdom, with a view to limit smaller, local TREs. The basis for this argument is that it avoids duplication of infrastructure, information governance, privacy risks, monopolies and will promote innovation, particularly with commercial partners. However, the work around establishing TREs in the UK largely ignores the long-established local TRE landscape in Scotland, and the way in which local TREs can actually improve data quality, solve technical architecture challenges, promote information governance and risk minimisation, and encourage innovation and collaboration (both academic and commercial). This data centre profile focuses on the Grampian Data Safe Haven (DaSH), a secure, virtual healthcare data analysis and storage centre located in Aberdeen, Scotland. DaSH was co-established by the NHS Grampian Health Board and University of Aberdeen to allow for the secure processing and linking of health data for the Grampian and Scottish population when it is not practicable to obtain consent from individual patients. As an established trusted research environment now in its 10th operating year, DaSH technology ensures healthcare, social care data and other types of sensitive data, routinely collected and used without individual patient consent, are made accessible for both academic research and clinical service evaluation and improvements whilst protecting individuals' privacy at the local, national and international levels. DaSH has registered almost 600 projects and facilitated over 200 distinct research projects with data hosting, extraction, and novel linkages to completion. Ongoing innovation and collaboration between DaSH and the NHS Grampian Health Board continues to expand researcher access to new types of data and data linkages, introduce new technologies for advanced statistical research methods, and supports interdisciplinary research using population health and social care data for research, clinical and commercial advancements, and real-world practitioner applications. The purpose of this paper is to present DaSH's data population, operating model, architecture and information technology, governance, legislation and management, privacy-by-design principles and data access, data linkage methods, data sources, noteworthy research outputs, and further developments in order to demonstrate the value of local TREs within the data management and access debate.","data centre; data extraction; data linkage; health informatics; population data; safe haven; Trusted Research Environment","","NLM (Medline)","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85169758875"
"Vidal F.P.; Villard P.-F.","Vidal, Franck P. (56277522500); Villard, Pierre-Frédéric (7003995041)","56277522500; 7003995041","Development and validation of real-time simulation of X-ray imaging with respiratory motion","2016","Computerized Medical Imaging and Graphics","49","","","1","15","14","30","10.1016/j.compmedimag.2015.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994654481&doi=10.1016%2fj.compmedimag.2015.12.002&partnerID=40&md5=ff221d2c5bb293c79b40ca0728484f3e","School of Computer Science, Bangor University, LL57 1UT, United Kingdom; Research Institute of Visual Computing, RIVIC, United Kingdom; Université de Lorraine, LORIA, UMR 7503, Vandoeuvre-lès-Nancy, F-54506, France; Inria, Villers-lès-Nancy, F-54600, France; CNRS, LORIA, UMR 7503, Vandoeuvre-lès-Nancy, F-54506, France","Vidal F.P., School of Computer Science, Bangor University, LL57 1UT, United Kingdom, Research Institute of Visual Computing, RIVIC, United Kingdom; Villard P.-F., Université de Lorraine, LORIA, UMR 7503, Vandoeuvre-lès-Nancy, F-54506, France, Inria, Villers-lès-Nancy, F-54600, France, CNRS, LORIA, UMR 7503, Vandoeuvre-lès-Nancy, F-54506, France","We present a framework that combines evolutionary optimisation, soft tissue modelling and ray tracing on GPU to simultaneously compute the respiratory motion and X-ray imaging in real-time. Our aim is to provide validated building blocks with high fidelity to closely match both the human physiology and the physics of X-rays. A CPU-based set of algorithms is presented to model organ behaviours during respiration. Soft tissue deformation is computed with an extension of the Chain Mail method. Rigid elements move according to kinematic laws. A GPU-based surface rendering method is proposed to compute the X-ray image using the Beer–Lambert law. It is provided as an open-source library. A quantitative validation study is provided to objectively assess the accuracy of both components: (i) the respiration against anatomical data, and (ii) the X-ray against the Beer–Lambert law and the results of Monte Carlo simulations. Our implementation can be used in various applications, such as interactive medical virtual environment to train percutaneous transhepatic cholangiography in interventional radiology, 2D/3D registration, computation of digitally reconstructed radiograph, simulation of 4D sinograms to test tomography reconstruction tools. © 2015 Elsevier Ltd","Deterministic simulation (ray-tracing); Digitally reconstructed radiograph; Imaging guidance; Interventional radiology training; Medical virtual environment; Respiration simulation; X-ray simulation","","Elsevier Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84994654481"
"Pernod E.; Sermesant M.; Konukoglu E.; Relan J.; Delingette H.; Ayache N.","Pernod, E. (37067780300); Sermesant, M. (6506746084); Konukoglu, E. (23397396100); Relan, J. (24333059600); Delingette, H. (7004183160); Ayache, N. (7006015230)","37067780300; 6506746084; 23397396100; 24333059600; 7004183160; 7006015230","A multi-front eikonal model of cardiac electrophysiology for interactive simulation of radio-frequency ablation","2011","Computers and Graphics (Pergamon)","35","2","","431","440","9","24","10.1016/j.cag.2011.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952751727&doi=10.1016%2fj.cag.2011.01.008&partnerID=40&md5=29b341f896afccd446a6adb8c55eaa14","INRIA, 06902 Sophia-Antipolis, 2004 route des Lucioles, France; Microsoft Research, Cambridge, United Kingdom; King's College London, St Thomas Hospital, United Kingdom","Pernod E., INRIA, 06902 Sophia-Antipolis, 2004 route des Lucioles, France; Sermesant M., INRIA, 06902 Sophia-Antipolis, 2004 route des Lucioles, France, King's College London, St Thomas Hospital, United Kingdom; Konukoglu E., Microsoft Research, Cambridge, United Kingdom; Relan J., INRIA, 06902 Sophia-Antipolis, 2004 route des Lucioles, France; Delingette H., INRIA, 06902 Sophia-Antipolis, 2004 route des Lucioles, France; Ayache N., INRIA, 06902 Sophia-Antipolis, 2004 route des Lucioles, France","Virtual reality-based therapy simulation meets a growing interest from the medical community due to its potential impact for the training of medical residents and the planning of therapies. However, computer models of the human anatomy are often very computationally demanding, thus incompatible with the constraints of such interactive simulations. In this paper, we propose a fast model of the cardiac electrophysiology based on an eikonal formulation implemented with an anisotropic fast marching method. We demonstrate the use of this model in the context of a simulator of radio-frequency ablation of cardiac arrhythmia from patient-specific medical imaging data. Indeed, this therapy can be very effective for patients but still suffers from a rather low success rate. Being able to test different ablation strategies on a patient-specific model can have a great clinical impact. In our setting, thanks to a haptic 3D user interface, the user can interactively measure the local extracellular potential, pace locally the myocardium or simulate the burning of cardiac tissue as done in radio-frequency ablation interventions. © 2011 Elsevier Ltd. All rights reserved.","Haptic device; Medical interactive simulation; Modelling of the heart","","Elsevier Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-79952751727"
"Condie D.N.; Cochrane P.","Condie, David N. (6701642157); Cochrane, Paul (7005857966)","6701642157; 7005857966","The ISPO System for Cerebral Palsy Treatment Recording (SCePTRe)","2002","Journal of Prosthetics and Orthotics","14","4","","136","142","6","0","10.1097/00008526-200212000-00003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036444943&doi=10.1097%2f00008526-200212000-00003&partnerID=40&md5=1fb664678004fe6ac2c8eb678689f8b1","Dept. of Orthoped. and Trauma Surg., University of Dundee, Ninewells Hosp. and Medical School, Dundee, United Kingdom; Tayside Rehab. Technology Services, Tayside University Hospitals, Ninewells Hosp. and Medical School, Dundee, United Kingdom; Dept. of Orthoped. and Trauma Surg., University of Dundee, Ninewells Hosp. and Medical School, Dundee DD19SY, United Kingdom","Condie D.N., Dept. of Orthoped. and Trauma Surg., University of Dundee, Ninewells Hosp. and Medical School, Dundee, United Kingdom, Dept. of Orthoped. and Trauma Surg., University of Dundee, Ninewells Hosp. and Medical School, Dundee DD19SY, United Kingdom; Cochrane P., Tayside Rehab. Technology Services, Tayside University Hospitals, Ninewells Hosp. and Medical School, Dundee, United Kingdom","The System for Cerebral Palsy Treatment Recording (SCePTRe) Database has been designed to provide clinicians treating children with cerebral palsy with an easy to use but comprehensive method of recording in a standardized manner information regarding both the status of their patients and the nature of the treatment they receive. The current version of the system, which is available on CD-ROM, is designed to be run on virtually any computer on the market today and may also be used as a multi-user system. The system is currently undergoing clinical evaluation and a SCePTRe user mailing list has also been established. Work is in progress to permit users of the system to transfer data to the SCePTRe website using the Internet and a shared database of patient records is planned.","Cerebral palsy; Clinical records; Computerized database; Team management","","Lippincott Williams and Wilkins","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-0036444943"
"Van Gorp P.; Comuzzi M.; Jahnen A.; Kaymak U.; Middleton B.","Van Gorp, P. (8227708000); Comuzzi, M. (23007964200); Jahnen, A. (25632201700); Kaymak, U. (7004385524); Middleton, B. (57203069375)","8227708000; 23007964200; 25632201700; 7004385524; 57203069375","An open platform for personal health record apps with platform-level privacy protection","2014","Computers in Biology and Medicine","51","","","14","23","9","13","10.1016/j.compbiomed.2014.04.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901427849&doi=10.1016%2fj.compbiomed.2014.04.019&partnerID=40&md5=479e85b130b145eda067bfd7a861dd5f","Eindhoven University of Technology, Netherlands; City University London, United Kingdom; Partners HealthCare and Harvard Medical School, MA, United States; Public Research Center Henri Tudor, Luxembourg","Van Gorp P., Eindhoven University of Technology, Netherlands; Comuzzi M., City University London, United Kingdom; Jahnen A., Public Research Center Henri Tudor, Luxembourg; Kaymak U., Eindhoven University of Technology, Netherlands; Middleton B., Partners HealthCare and Harvard Medical School, MA, United States","One of the main barriers to the adoption of Personal Health Records (PHR) systems is their closed nature. It has been argued in the literature that this barrier can be overcome by introducing an open market of substitutable PHR apps. The requirements introduced by such an open market on the underlying platform have also been derived. In this paper, we argue that MyPHRMachines, a cloud-based PHR platform recently developed by the authors, satisfies these requirements better than its alternatives. The MyPHRMachines platform leverages Virtual Machines as flexible and secure execution sandboxes for health apps. MyPHRMachines does not prevent pushing hospital- or patient-generated data to one of its instances, nor does it prevent patients from sharing data with their trusted caregivers. External software developers have minimal barriers to contribute innovative apps to the platform, since apps are only required to avoid pushing patient data outside a MyPHRMachines cloud. We demonstrate the potential of MyPHRMachines by presenting two externally contributed apps. Both apps provide functionality going beyond the state-of-the-art in their application domain, while they did not require any specific MyPHRMachines platform extension. © 2014 Elsevier Ltd.","Apps; Architecture; Personal health records; Privacy; Trust","","Elsevier Ltd","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84901427849"
"Munir K.; Ahmad K.H.; McClatchey R.","Munir, Kamran (24477551700); Ahmad, Khawar Hasham (56996796600); McClatchey, Richard (7003921382)","24477551700; 56996796600; 7003921382","Development of a large-scale neuroimages and clinical variables data atlas in the neuGRID4You (N4U) project","2015","Journal of Biomedical Informatics","57","","","245","262","17","9","10.1016/j.jbi.2015.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949485464&doi=10.1016%2fj.jbi.2015.08.004&partnerID=40&md5=e2db197d7efadefd8819298bdb20076e","Centre for Complex Cooperative Systems (CCCS), Department of Computer Science and Creative Technologies (CSCT), University of the West of England (UWE), Frenchay Campus, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom","Munir K., Centre for Complex Cooperative Systems (CCCS), Department of Computer Science and Creative Technologies (CSCT), University of the West of England (UWE), Frenchay Campus, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom; Ahmad K.H., Centre for Complex Cooperative Systems (CCCS), Department of Computer Science and Creative Technologies (CSCT), University of the West of England (UWE), Frenchay Campus, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom; McClatchey R., Centre for Complex Cooperative Systems (CCCS), Department of Computer Science and Creative Technologies (CSCT), University of the West of England (UWE), Frenchay Campus, Coldharbour Lane, Bristol, BS16 1QY, United Kingdom","Exceptional growth in the availability of large-scale clinical imaging datasets has led to the development of computational infrastructures that offer scientists access to image repositories and associated clinical variables data. The EU FP7 neuGRID and its follow on neuGRID4You (N4U) projects provide a leading e-Infrastructure where neuroscientists can find core services and resources for brain image analysis. The core component of this e-Infrastructure is the N4U Virtual Laboratory, which offers easy access for neuroscientists to a wide range of datasets and algorithms, pipelines, computational resources, services, and associated support services. The foundation of this virtual laboratory is a massive data store plus a set of Information Services collectively called the 'Data Atlas'. This data atlas stores datasets, clinical study data, data dictionaries, algorithm/pipeline definitions, and provides interfaces for parameterised querying so that neuroscientists can perform analyses on required datasets. This paper presents the overall design and development of the Data Atlas, its associated dataset indexing and retrieval services that originated from the development of the N4U Virtual Laboratory in the EU FP7 N4U project in the light of detailed user requirements. © 2015 Elsevier Inc..","Data analysis; Data atlas; Data integration; Information retrieval; Neuroscience","","Academic Press Inc.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84949485464"
"Luboz V.; Hughes C.; Gould D.; John N.; Bello F.","Luboz, Vincent (22433444000); Hughes, Chris (59028770700); Gould, Derek (7201621787); John, Nigel (7005876140); Bello, Fernando (24329025000)","22433444000; 59028770700; 7201621787; 7005876140; 24329025000","Real-time seldinger technique simulation in complex vascular models","2009","International Journal of Computer Assisted Radiology and Surgery","4","6","","589","596","7","16","10.1007/s11548-009-0376-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350728538&doi=10.1007%2fs11548-009-0376-0&partnerID=40&md5=5d25614e6519362da7c5f2bebb6d8afb","Biosurgery and Surgical Technology Department, Imperial College London, St Mary's Hospital, London W2 1NY, United Kingdom; Bangor University, Bangor, United Kingdom; Royal Liverpool Hospital, Liverpool, United Kingdom","Luboz V., Biosurgery and Surgical Technology Department, Imperial College London, St Mary's Hospital, London W2 1NY, United Kingdom; Hughes C., Bangor University, Bangor, United Kingdom; Gould D., Royal Liverpool Hospital, Liverpool, United Kingdom; John N., Bangor University, Bangor, United Kingdom; Bello F., Biosurgery and Surgical Technology Department, Imperial College London, St Mary's Hospital, London W2 1NY, United Kingdom","Purpose: Commercial interventional radiology vascular simulators emulate instrument navigation and device deployment, though none supports the Seldinger technique, which provides initial access to the vascular tree. This paper presents a novel virtual environment for teaching this core skill. Methods: Our simulator combines two haptic devices: vessel puncture with a virtual needle and catheter and guidewire manipulation. The simulation software displays the instrument interactions with the vessels. Instruments are modelled using a mass-spring approximation, while efficient collision detection and collision response allow real time interactions. Results: Experienced interventional radiologists evaluated the haptic components of our simulator as realistic and accurate. The vessel puncture haptic device proposes a first prototype to simulate the Seldinger technique. Our simulator presents realistic instrument behaviour when compared to real instruments in a vascular phantom. Conclusion: This paper presents the first simulator to train the Seldinger technique. The preliminary results confirm its utility for interventional radiology training. © CARS 2009.","Haptic devices; Interventional radiology; Mass spring model; Simulation; Training; Vascular","","Springer Verlag","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-70350728538"
"Alimohammadi M.; Bhattacharya-Ghosh B.; Seshadhri S.; Penrose J.; Agu O.; Balabani S.; Díaz-Zuccarini V.","Alimohammadi, Mona (55935595100); Bhattacharya-Ghosh, Benjamin (55339729500); Seshadhri, Santhosh (24484077900); Penrose, Justin (7004414878); Agu, Obiekezie (35075797600); Balabani, Stavroula (6602671760); Díaz-Zuccarini, Vanessa (23984658900)","55935595100; 55339729500; 24484077900; 7004414878; 35075797600; 6602671760; 23984658900","Evaluation of the hemodynamic effectiveness of aortic dissection treatments via virtual stenting","2014","International Journal of Artificial Organs","37","10","","753","762","9","16","10.5301/ijao.5000310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908502616&doi=10.5301%2fijao.5000310&partnerID=40&md5=1ecc5e7ccfba455d7620b72c07bc6603","Department of Mechanical Engineering, University College London, London, United Kingdom; Sheffield Business Park, Sheffield, United Kingdom; Consultant General Vascular and Endovascular Surgeon, University College London Hospitals, London, United Kingdom","Alimohammadi M., Department of Mechanical Engineering, University College London, London, United Kingdom; Bhattacharya-Ghosh B., Department of Mechanical Engineering, University College London, London, United Kingdom; Seshadhri S., Sheffield Business Park, Sheffield, United Kingdom; Penrose J., Sheffield Business Park, Sheffield, United Kingdom; Agu O., Consultant General Vascular and Endovascular Surgeon, University College London Hospitals, London, United Kingdom; Balabani S., Department of Mechanical Engineering, University College London, London, United Kingdom; Díaz-Zuccarini V., Department of Mechanical Engineering, University College London, London, United Kingdom","Aortic dissection treatment varies for each patient and stenting is one of a number of approaches that are utilized to Stabilize the condition. Information regarding the hemodynamic forces in the aorta in dissected and virtually stented cases could support clinicians in their choices of treatment prior to medical intervention. Computational fluid dynamics coupled with lumped parameter models have shown promise in providing detailed information that could be used in the clinic; for this, it is necessary to develop personalized workflows in order to produce patient-specific simulations. In the present study, a case of pre- and post-stenting (virtual stent-graft) of an aortic dissection is investigated with a particular focus on the role of personalized boundary conditions. For each virtual case, velocity, pressure, energy loss, and wall shear stress values are evaluated and compared. The simulated single stent-graft only marginally reduced the pulse pressure and systemic energy loss. The double stent-graft results showed a larger reduction in pulse pressure and a 40% reduction in energy loss as well as a more physiological wall shear stress distribution. Regions of potential risk were highlighted. The methodology applied in the present study revealed detailed information about two possible surgical outcome cases and shows promise as both a diagnostic and an interventional tool. © 2014 Wichtig Publishing.","Aortic dissection; Computational fluid dynamics; Patient-specific; Stent-graft; Virtual treatment","","Wichtig Publishing Srl","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84908502616"
"Moreton G.; Meydan T.; Williams P.","Moreton, G. (57189310673); Meydan, T. (7004854102); Williams, P. (7404956467)","57189310673; 7004854102; 7404956467","A Novel Magnetostrictive Curvature Sensor Employing Flexible, Figure-of-Eight Sensing Coils","2016","IEEE Transactions on Magnetics","52","5","7390087","","","","6","10.1109/TMAG.2016.2520828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968813952&doi=10.1109%2fTMAG.2016.2520828&partnerID=40&md5=8bc2641952b1029a1459f88c485dfd1c","Wolfson Centre for Magnetics, School of Engineering, Cardiff University, Cardiff, CF243AA, United Kingdom","Moreton G., Wolfson Centre for Magnetics, School of Engineering, Cardiff University, Cardiff, CF243AA, United Kingdom; Meydan T., Wolfson Centre for Magnetics, School of Engineering, Cardiff University, Cardiff, CF243AA, United Kingdom; Williams P., Wolfson Centre for Magnetics, School of Engineering, Cardiff University, Cardiff, CF243AA, United Kingdom","The demand for accurate angle measurements in a form that is robust and small is high, due to the advances in virtual reality applications, primarily the virtual reality headsets. The peripheral devices are required to completely immerse the user in a virtual reality setting, and for this purpose, a robust sensor has been developed. The angle measurements can also be used in motion sensing applications for medical purposes, allowing monitoring of a patient's condition. This paper presents the development of a planar figure-of-eight coil sensor, which has been designed for the purpose of curvature sensing. The copper-plated polyimide material, FR4 FLEX, was used for the fabrication of the planar figure-of-eight coil. A curvature sensor was designed and consists of the figure-of-eight coil along with the magnetostrictive material Metglas 2605SA1. The sensor was incorporated in an oscillator circuit, where curvature-induced stress within the material changes the amplitude and the frequency of the output signal of the circuit. © 2016 IEEE.","curvature sensor; Magnetostrictive; planar coils","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84968813952"
"Nava A.; Mazza E.; Kleinermann F.; Avis N.J.; McClure J.","Nava, Alessandro (7101734694); Mazza, Edoardo (55397367400); Kleinermann, Frederic (6603554273); Avis, Nick J. (7005330117); McClure, John (7201992563)","7101734694; 55397367400; 6603554273; 7005330117; 7201992563","Determination of the mechanical properties of soft human tissues through aspiration experiments","2003","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","2878","","","222","229","7","45","10.1007/978-3-540-39899-8_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-11244283421&doi=10.1007%2f978-3-540-39899-8_28&partnerID=40&md5=2c3a09a74394d29924c670f615fd0eb7","Centre of Mechanics, ETH Zurich, 8092 Zurich, Switzerland; Centre for Virtual Environment, Univeristy of Salford, Salford, M5 4WT, United Kingdom; Department of Computer Science, Cardiff University, Queen's Buildings, Cardiff, United Kingdom; Directorate of Laboratory Medicine, Manchester Royal Infirmary, Manchester, M13 9WL, Oxford Road, United Kingdom","Nava A., Centre of Mechanics, ETH Zurich, 8092 Zurich, Switzerland; Mazza E., Centre of Mechanics, ETH Zurich, 8092 Zurich, Switzerland; Kleinermann F., Centre for Virtual Environment, Univeristy of Salford, Salford, M5 4WT, United Kingdom; Avis N.J., Department of Computer Science, Cardiff University, Queen's Buildings, Cardiff, United Kingdom; McClure J., Directorate of Laboratory Medicine, Manchester Royal Infirmary, Manchester, M13 9WL, Oxford Road, United Kingdom","Mechanical models for soft human organs are necessary for a variety of medical applications, such as surgical planning, virtual reality surgery simulators, and for diagnostic purposes. An adequate quantitative description of the mechanical behaviour of human organs requires high quality experimental data to be acquired and analyzed. We present a novel technique for the acquisition of such data from soft tissues and its post processing to determine some parameters of the tissue's mechanical properties. A small tube is applied to the target organ and a weak vacuum is generated inside the tube according to a predefined pressure history. A video camera grabs images of the deformation profile of the aspirated tissue, and a pressure sensor measures the correspondent vacuum level. The images are processed and used to inform the fitting of uniaxial and continuum mechanics models. Whilst the aspiration test device has been designed to fulfill the requirements for in-vivo applications, for measurements obtained during open surgery, initial experiments performed on human cadaveric tissues demonstrate the ability to both differentiate between different organs and also between normal and diseased organs on the basis of the derived mechanical properties. © Springer-Verlag Berlin Heidelberg 2003.","","","Springer Verlag","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-11244283421"
"Spirka T.A.; Erdemir A.; Ewers Spaulding S.; Yamane A.; Telfer S.; Cavanagh P.R.","Spirka, Thomas A. (8719189200); Erdemir, Ahmet (7006275388); Ewers Spaulding, Susan (56317976900); Yamane, Ann (56318094600); Telfer, Scott (36247838500); Cavanagh, Peter R. (54790507900)","8719189200; 7006275388; 56317976900; 56318094600; 36247838500; 54790507900","Simple finite element models for use in the design of therapeutic footwear","2014","Journal of Biomechanics","47","12","","2948","2955","7","21","10.1016/j.jbiomech.2014.07.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908066198&doi=10.1016%2fj.jbiomech.2014.07.020&partnerID=40&md5=6739050ed360d8a132e767f198e7558b","Department of Orthopaedics and Sports Medicine, University of Washington, Seattle, WA, United States; Computational Biomodeling (CoBi) Core and Department of Biomedical Engineering, Lerner Research Institute, Cleveland Clinic, Cleveland, OH, United States; Institute of Applied Health Research, Glasgow Caledonian University, Glasgow, United Kingdom","Spirka T.A., Department of Orthopaedics and Sports Medicine, University of Washington, Seattle, WA, United States; Erdemir A., Computational Biomodeling (CoBi) Core and Department of Biomedical Engineering, Lerner Research Institute, Cleveland Clinic, Cleveland, OH, United States; Ewers Spaulding S., Department of Orthopaedics and Sports Medicine, University of Washington, Seattle, WA, United States; Yamane A., Department of Orthopaedics and Sports Medicine, University of Washington, Seattle, WA, United States; Telfer S., Department of Orthopaedics and Sports Medicine, University of Washington, Seattle, WA, United States, Institute of Applied Health Research, Glasgow Caledonian University, Glasgow, United Kingdom; Cavanagh P.R., Department of Orthopaedics and Sports Medicine, University of Washington, Seattle, WA, United States","Therapeutic footwear is frequently prescribed in cases of rheumatoid arthritis and diabetes to relieve or redistribute high plantar pressures in the region of the metatarsal heads. Few guidelines exist as to how these interventions should be designed and what effect such interventions actually have on the plantar pressure distribution. Finite element analysis has the potential to assist in the design process by refining a given intervention or identifying an optimal intervention without having to actually build and test each condition. However, complete and detailed foot models based on medical image segmentation have proven time consuming to build and computationally expensive to solve, hindering their utility in practice. Therefore, the goal of the current work was to determine if a simplified patient-specific model could be used to assist in the design of foot orthoses to reduce the plantar pressure in the metatarsal head region. The approach is illustrated by a case study of a diabetic patient experiencing high pressures and pain over the fifth metatarsal head. The simple foot model was initially calibrated by adjusting the individual loads on the metatarsals to approximate measured peak plantar pressure distributions in the barefoot condition to within 3%. This loading was used in various shod conditions to identify an effective orthosis. Model results for metatarsal pads were considerably higher than measured values but predictions for uniform surfaces were generally within 16% of measured values. The approach enabled virtual prototyping of the orthoses, identifying the most favorable approach to redistribute the patient's plantar pressures. © 2014 Elsevier Ltd.","Diabetes; Finite element method; Foot; Footwear; Model","","Elsevier Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84908066198"
"Tresadern P.A.; Thies S.B.; Kenney L.P.J.; Howard D.; Smith C.; Rigby J.; Goulermas J.Y.","Tresadern, Philip A. (16644321100); Thies, Sibylle B. (16643823400); Kenney, Laurence P. J. (7003488666); Howard, David (35233305500); Smith, Christine (7501652493); Rigby, Julie (16643728300); Goulermas, John Y. (8972539400)","16644321100; 16643823400; 7003488666; 35233305500; 7501652493; 16643728300; 8972539400","Simulating acceleration from stereophotogrammetry for medical device design","2009","Journal of Biomechanical Engineering","131","6","","","","","3","10.1115/1.3118771","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68149180591&doi=10.1115%2f1.3118771&partnerID=40&md5=4a82d1d09f0f6e831176605edc046872","Centre for Rehabilitation and Human Performance Research (CRHPR), Salford University, Salford M6 6PU, United Kingdom; Salford Primary Care Trust, St. James's House, Salford M6 5FW, Pendleton Way, United Kingdom; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool L69 3GJ, Brownlow Hill, United Kingdom","Tresadern P.A., Centre for Rehabilitation and Human Performance Research (CRHPR), Salford University, Salford M6 6PU, United Kingdom; Thies S.B., Centre for Rehabilitation and Human Performance Research (CRHPR), Salford University, Salford M6 6PU, United Kingdom; Kenney L.P.J., Centre for Rehabilitation and Human Performance Research (CRHPR), Salford University, Salford M6 6PU, United Kingdom; Howard D., Centre for Rehabilitation and Human Performance Research (CRHPR), Salford University, Salford M6 6PU, United Kingdom; Smith C., Centre for Rehabilitation and Human Performance Research (CRHPR), Salford University, Salford M6 6PU, United Kingdom; Rigby J., Salford Primary Care Trust, St. James's House, Salford M6 5FW, Pendleton Way, United Kingdom; Goulermas J.Y., Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool L69 3GJ, Brownlow Hill, United Kingdom","When designing a medical device based on lightweight accelerometers, the designer is faced with a number of questions in order to maximize performance while minimizing cost and complexity: Where should the inertial unit be located? How many units are required? How is performance affected if the unit is not correctly located during donning? One way to answer these questions is to use position data from a single trial, captured with a nonportable measurement system (e.g., stereophotogrammetry) to simulate measurements from multiple accelerometers at different locations on the body. In this paper, we undertake a thorough investigation into the applicability of these simulated acceleration signals via a series of interdependent experiments of increasing generality. We measured the dynamics of a reference coordinate frame using stereophotogrammetry over a number of trials. These dynamics were then used to simulate several ""virtual"" accelerometers at different points on the body segment. We then compared the simulated signals with those directly measured to evaluate the error under a number of conditions. Finally, we demonstrated an example of how simulated signals can be employed in a system design application. In the best case, we may expect an error of 0.028 m/s2 between a derived virtual signal and that directly measured by an accelerometer. In practice, however, using centripetal and tangential acceleration terms (that are poorly estimated) results in an error that is an order of magnitude greater than the baseline. Furthermore, nonrigidity of the limb can increase error dramatically, although the effects can be reduced considerably via careful modeling. We conclude that using simulated signals has definite benefits when an appropriate model of the body segment is applied. Copyright © 2009 by ASME.","Acceleration; Simulation; Virtual sensor","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-68149180591"
"Oikonomou A.; Amin S.; Naguib R.N.G.; Todman A.; Al-Omishy H.","Oikonomou, Andreas (6701354402); Amin, Saad (7201845035); Naguib, Raouf N.G. (7005966890); Todman, Alison (6602238562); Al-Omishy, Hassanein (6603070658)","6701354402; 7201845035; 7005966890; 6602238562; 6603070658","Interactive Reality System (IRiS): Interactive 3D Video Playback in Multimedia Applications","2006","Journal of Advanced Computational Intelligence and Intelligent Informatics","10","2","","145","149","4","0","10.20965/jaciii.2006.p0145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167457080&doi=10.20965%2fjaciii.2006.p0145&partnerID=40&md5=5b632ad27d0b0847c3bf38d46170dc7d","Biomedical Computing Research Group (BIOCORE), Faculty of Engineering and Computing, Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom; University Hospitals Coventry and Warwickshire, Clifford Bridge Road, Coventry, CV2 2DX, United Kingdom","Oikonomou A., Biomedical Computing Research Group (BIOCORE), Faculty of Engineering and Computing, Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom; Amin S., Biomedical Computing Research Group (BIOCORE), Faculty of Engineering and Computing, Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom; Naguib R.N.G., Biomedical Computing Research Group (BIOCORE), Faculty of Engineering and Computing, Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom; Todman A., Biomedical Computing Research Group (BIOCORE), Faculty of Engineering and Computing, Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom; Al-Omishy H., University Hospitals Coventry and Warwickshire, Clifford Bridge Road, Coventry, CV2 2DX, United Kingdom","We developed a novel interactive video recording and playback technique for biomedical multimedia training but also applicable to other areas of multimedia. The Interactive Reality System (IRiS) improves on video playback used in most multimedia applications by controlling not only time, as in conventional video playback, but also space. A prototype is being tested and evaluated for multimedia training in breast selfexamination (BSE).We discuss the advantages of IRiS and compare it to other similar approaches, such as QuickTime and iPIX. We detail the design of IRiS, its development, refinement, final implementation, evaluation, some projected plans and its uses in other biomedical and multimedia training scenarios.  © Fuji Technology Press Ltd.","biomedical applications; breast cancer; breast selfexamination; interactive video; Virtual reality","","Fuji Technology Press","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85167457080"
"Freudenthal A.; Stüdeli T.; Lamata P.; Samset E.","Freudenthal, Adinda (19635074600); Stüdeli, Thomas (35333063600); Lamata, Pablo (12806240900); Samset, Eigil (55932190400)","19635074600; 35333063600; 12806240900; 55932190400","Collaborative co-design of emerging multi-technologies for surgery","2011","Journal of Biomedical Informatics","44","2","","198","215","17","19","10.1016/j.jbi.2010.11.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952749139&doi=10.1016%2fj.jbi.2010.11.006&partnerID=40&md5=fd2ed62d273771858f714e71b3f22aea","Delft University of Technology, Faculty of Industrial Design Engineering, 2628 CE Delft, Landbergstraat 15, Netherlands; Siemens Molecular Imaging, Oxford OX1 3QR, South Parks Road, United Kingdom; University of Oslo, Centre of Mathematics for Applications, 1072, Oslo N-0316, Problemveien 7, Norway","Freudenthal A., Delft University of Technology, Faculty of Industrial Design Engineering, 2628 CE Delft, Landbergstraat 15, Netherlands; Stüdeli T., Delft University of Technology, Faculty of Industrial Design Engineering, 2628 CE Delft, Landbergstraat 15, Netherlands; Lamata P., Siemens Molecular Imaging, Oxford OX1 3QR, South Parks Road, United Kingdom; Samset E., University of Oslo, Centre of Mathematics for Applications, 1072, Oslo N-0316, Problemveien 7, Norway","The EU Research Training Network on Augmented Reality in Surgery (ARIS*ER) was established with two aims: (1) to develop next-generation novel image guidance (augmented reality based on medical images) and cross-linked robotic systems (automatic control loops guided by information sensed from the patient) and (2) to educate young researchers in the user-centred, multidisciplinary design of emerging technologies for minimally invasive surgery (MIS) and intervention radiology. Collaborations between engineers, Human Factors specialists, industrial designers and medical end users were foreseen, but actual methodologies had to be developed. Three applications were used as development vehicles and as demonstrators. The resulting teamwork and process of indentifying requirements, finding solutions (in technology and workflow), and shifting between these to optimize and speed development towards quality of care were studied. The ARIS*ER approach solves current problems in collaborative teams, taking a systems approach, and manages the overview of requirements and solutions, which is too complex to manage centrally. © 2010 Elsevier Inc.","Augmented reality; Co-design; Collaborative design; Design team training; Human Factors; Innovation team; Medical workflow; Minimally invasive therapies; System design; User interface","","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-79952749139"
"Woodbridge M.; Fagiolo G.; O'Regan D.P.","Woodbridge, Mark (23669681300); Fagiolo, Gianlorenzo (23975687500); O'Regan, Declan P. (57337412200)","23669681300; 23975687500; 57337412200","MRIdb: Medical image management for biobank research","2013","Journal of Digital Imaging","26","5","","886","890","4","19","10.1007/s10278-013-9604-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885423917&doi=10.1007%2fs10278-013-9604-9&partnerID=40&md5=8e3383f7f6d4daa06b08dd4f244f7695","Centre for Integrative Systems Biology and Bioinformatics, Imperial College London, London SW7 2AZ, United Kingdom; Robert Steiner MRI Unit, MRC Clinical Sciences Centre, Imperial College London, London W12 0NN, United Kingdom","Woodbridge M., Centre for Integrative Systems Biology and Bioinformatics, Imperial College London, London SW7 2AZ, United Kingdom; Fagiolo G., Robert Steiner MRI Unit, MRC Clinical Sciences Centre, Imperial College London, London W12 0NN, United Kingdom; O'Regan D.P., Robert Steiner MRI Unit, MRC Clinical Sciences Centre, Imperial College London, London W12 0NN, United Kingdom","Clinical picture archiving and communications systems provide convenient, efficient access to digital medical images from multiple modalities but can prove challenging to deploy, configure and use. MRIdb is a self-contained image database, particularly suited to the storage and management of magnetic resonance imaging data sets for population phenotyping. It integrates a mature image archival system with an intuitive web-based user interface that provides visualisation and export functionality. In addition, utilities for auditing, data migration and system monitoring are included in a virtual machine image that is easily deployed with minimal configuration. The result is a freely available turnkey solution, designed to support epidemiological and imaging genetics research. It allows the management of patient data sets in a secure, scalable manner without requiring the installation of any bespoke software on end users' workstations. MRIdb is an open-source software, available for download at http://www3.imperial.ac.uk/bioinfsupport/resources/software/mridb. © 2013 The Author(s).","Digital imaging and communications in medicine (DICOM); MR imaging; PACS","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84885423917"
"Gelenbe E.; Hussain K.; Kaptan V.","Gelenbe, Erol (7006026729); Hussain, Khaled (7005077804); Kaptan, Varol (6506881172)","7006026729; 7005077804; 6506881172","Simulating autonomous agents in augmented reality","2005","Journal of Systems and Software","74","3","","255","268","13","72","10.1016/j.jss.2004.01.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344283557&doi=10.1016%2fj.jss.2004.01.016&partnerID=40&md5=b7147c1c8ed872ea8f7e1031649ad195","Department of Electrical Engineering, Imperial College, London SW7 2AZ, Exhibition Road, United Kingdom; School of Computer Science, University of Central Florida, Orlando, FL 32816, United States","Gelenbe E., Department of Electrical Engineering, Imperial College, London SW7 2AZ, Exhibition Road, United Kingdom; Hussain K., School of Computer Science, University of Central Florida, Orlando, FL 32816, United States; Kaptan V., Department of Electrical Engineering, Imperial College, London SW7 2AZ, Exhibition Road, United Kingdom","In many critical applications such as airport operations (for capacity planning), military simulations (for tactical training and planning), and medical simulations (for the planning of medical treatment and surgical operations), it is very useful to conduct simulations within physically accurate and visually realistic settings that are represented by real video imaging sequences. Furthermore, it is important that the simulated entities conduct autonomous actions which are realistic and which follow plans of action or intelligent behavior in reaction to current situations. We describe the research we have conducted to incorporate synthetic objects in a visually realistic manner in video sequences representing a real scene. We also discuss how the synthetic objects can be designed to conduct intelligent behavior within an augmented reality setting. The paper discusses both the computer vision aspects that we have addressed and solved, and the issues related to the insertion of intelligent autonomous objects within an augmented reality simulation. © 2004 Elsevier Inc. All rights reserved.","Augmented reality; Simulation","","Elsevier Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-8344283557"
"Peach T.W.; Spranger K.; Ventikos Y.","Peach, T.W. (56305052900); Spranger, K. (56226719600); Ventikos, Y. (6603704133)","56305052900; 56226719600; 6603704133","Towards Predicting Patient-Specific Flow-Diverter Treatment Outcomes for Bifurcation Aneurysms: From Implantation Rehearsal to Virtual Angiograms","2016","Annals of Biomedical Engineering","44","1","","99","111","12","13","10.1007/s10439-015-1395-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952870988&doi=10.1007%2fs10439-015-1395-3&partnerID=40&md5=c1428096825008c86fb403fc683bc2dc","Department of Mechanical Engineering, University College London, London, United Kingdom; Department of Engineering Science, University of Oxford, Oxford, United Kingdom","Peach T.W., Department of Mechanical Engineering, University College London, London, United Kingdom, Department of Engineering Science, University of Oxford, Oxford, United Kingdom; Spranger K., Department of Mechanical Engineering, University College London, London, United Kingdom; Ventikos Y., Department of Mechanical Engineering, University College London, London, United Kingdom","Despite accounting for the majority of all cerebral aneurysm cases, bifurcation aneurysms present many challenges to standard endovascular treatment techniques. This study examines the treatment of bifurcation aneurysms endovascularly with flow-diverting stents and presents an integrative computational modeling suite allowing for rehearsing all aspects of the treatment. Six bifurcation aneurysms are virtually treated with 70% porosity flow-diverters. Substantial reduction (>50%) in aneurysm inflow due to device deployment is predicted in addition to reductions in peak and average aneurysm wall shear stress to values considered physiologically normal. The subsequent impact of flow-diverter deployment on daughter vessels that are jailed by the device is investigated further, with a number of simulations conducted with increased outlet pressure conditions at jailed vessels. Increased outlet pressures at jailed daughter vessels are found to have little effect on device-induced aneurysm inflow reduction, but large variation (13–86%) is seen in the resulting reduction in daughter vessel flow rate. Finally, we propose a potentially powerful approach for validation of such models, by introducing an angiographic contrast model, with contrast transport modeled both before and after virtual treatment. Virtual angiograms and contrast residence curves are created, which offer unique clinical relevance and the potential for future in vivo verification of simulated results. © 2015, The Author(s).","Bifurcation aneurysm; Computational fluid dynamics; Flow-diverter; Stent; Virtual contrast; Virtual deployment","","Springer New York LLC","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84952870988"
"Ragkousis G.E.; Curzen N.; Bressloff N.W.","Ragkousis, Georgios E. (56050727800); Curzen, Nick (7006653922); Bressloff, Neil W. (6603425591)","56050727800; 7006653922; 6603425591","Computational Modelling of Multi-folded Balloon Delivery Systems for Coronary Artery Stenting: Insights into Patient-Specific Stent Malapposition","2015","Annals of Biomedical Engineering","43","8","","1786","1802","16","19","10.1007/s10439-014-1237-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937857749&doi=10.1007%2fs10439-014-1237-8&partnerID=40&md5=83575dae0c2928052ebd944259d69fa4","Computational Engineering & Design Group, Engineering & the Environment, University of Southampton, Boldrewood Campus, Southampton, SO16 7QF, United Kingdom; Wessex Cardiothoracic and Vascular Care Group, University Hospital Southampton, NHS Foundation Trust, Southampton, United Kingdom; University of Southampton, Southampton, United Kingdom","Ragkousis G.E., Computational Engineering & Design Group, Engineering & the Environment, University of Southampton, Boldrewood Campus, Southampton, SO16 7QF, United Kingdom; Curzen N., Wessex Cardiothoracic and Vascular Care Group, University Hospital Southampton, NHS Foundation Trust, Southampton, United Kingdom, University of Southampton, Southampton, United Kingdom; Bressloff N.W., Computational Engineering & Design Group, Engineering & the Environment, University of Southampton, Boldrewood Campus, Southampton, SO16 7QF, United Kingdom","Despite the clinical effectiveness of coronary artery stenting, percutaneous coronary intervention or “stenting” is not free of complications. Stent malapposition (SM) is a common feature of “stenting” particularly in challenging anatomy, such as that characterized by long, tortuous and bifurcated segments. SM is an important risk factor for stent thrombosis and recently it has been associated with longitudinal stent deformation. SM is the result of many factors including reference diameter, vessel tapering, the deployment pressure and the eccentric anatomy of the vessel. For the purpose of the present paper, virtual multi-folded balloon models have been developed for simulated deployment in both constant and varying diameter vessels under uniform pressure. The virtual balloons have been compared to available compliance charts to ensure realistic inflation response at nominal pressures. Thereafter, patient-specific simulations of stenting have been conducted aiming to reduce SM. Different scalar indicators, which allow a more global quantitative judgement of the mechanical performance of each delivery system, have been implemented. The results indicate that at constant pressure, the proposed balloon models can increase the minimum stent lumen area and thereby significantly decrease SM. © 2015, Biomedical Engineering Society.","Balloon delivery systems; Coronary stents; Finite element analysis; Patient-specific model; Stent malapposition","","Kluwer Academic Publishers","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84937857749"
"Zhang Z.-Q.","Zhang, Zhi-Qiang (56879548200)","56879548200","Two-step calibration methods for miniature inertial and magnetic sensor units","2015","IEEE Transactions on Industrial Electronics","62","6","6971215","3714","3723","9","36","10.1109/TIE.2014.2375258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929379664&doi=10.1109%2fTIE.2014.2375258&partnerID=40&md5=ed863074b925cbb336006566b4fd3530","Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","Zhang Z.-Q., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","Low-cost inertial/magnetic sensor units have been extensively used to determine sensor attitude information for a wide variety of applications, ranging from virtual reality, underwater vehicles, handheld navigation systems, to biomotion analysis and biomedical applications. In order to achieve precise attitude reconstruction, appropriate sensor calibration procedures must be performed in advance to process sensor readings properly. In this paper, we are aiming to calibrate different error parameters, such as sensor sensitivity/scale factor error, offset/bias error, nonorthogonality error, mounting error, and also soft iron and hard iron errors for magnetometers. Instead of estimating all of these parameters individually, these errors are combined together as the combined bias and transformation matrix. Two-step approaches are proposed to determine the combined bias and transformation matrix separately. For the accelerometer and magnetometer, the combined bias is determined by finding an optimal ellipsoid that can best fit the sensor readings, and the transformation matrix is then derived through a two-step iterative algorithm by exploring the intrinsic relationship among sensor readings. For the gyroscope, the combined bias can be easily determined by placing the sensor node stationary. For the transformation matrix estimation, the intrinsic relationship among gyroscope readings is explored again, and an unscented Kalman filter is employed to determine such matrix. The calibration methods are then applied to our sensor nodes, and the good performance of the orientation estimation has illustrated the effectiveness of the proposed sensor calibration methods. © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.","Calibration; Kalman filter; Miniature sensors; Optimization; Orientation/attitude","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84929379664"
"Connesson N.; Clayton E.H.; Bayly P.V.; Pierron F.","Connesson, N. (36609746900); Clayton, E.H. (36607571100); Bayly, P.V. (7006002626); Pierron, F. (7003575513)","36609746900; 36607571100; 7006002626; 7003575513","Extension of the optimised virtual fields method to estimate viscoelastic material parameters from 3D dynamic displacement fields","2015","Strain","51","2","","110","134","24","16","10.1111/str.12126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924968371&doi=10.1111%2fstr.12126&partnerID=40&md5=aa7e16c5fe503121cb30afb8ed6e6a66","Laboratoire TIMC-IMAG, Université de Grenoble (INPG-UJF), BP 53, Grenoble, 38041, France; Department of Mechanical Engineering and Materials Science, Washington University in St Louis, One Brookings Drive Campus Box 1185, St. Louis, 63130, MO, United States; Engineering and the Environment, University of Southampton, Highfield, Southampton, SO17 1BJ, United Kingdom","Connesson N., Laboratoire TIMC-IMAG, Université de Grenoble (INPG-UJF), BP 53, Grenoble, 38041, France; Clayton E.H., Department of Mechanical Engineering and Materials Science, Washington University in St Louis, One Brookings Drive Campus Box 1185, St. Louis, 63130, MO, United States; Bayly P.V., Department of Mechanical Engineering and Materials Science, Washington University in St Louis, One Brookings Drive Campus Box 1185, St. Louis, 63130, MO, United States; Pierron F., Engineering and the Environment, University of Southampton, Highfield, Southampton, SO17 1BJ, United Kingdom","In vivo measurement of the mechanical properties of soft tissues is essential to provide necessary data in biomechanics and medicine (early cancer diagnosis, study of traumatic brain injuries, etc.). Imaging techniques such as magnetic resonance elastography can provide 3D displacement maps in the bulk and in vivo, from which, using inverse methods, it is then possible to identify some mechanical parameters of the tissues (stiffness, damping, etc.). The main difficulties in these inverse identification procedures consist in dealing with the pressure waves contained in the data and with the experimental noise perturbing the spatial derivatives required during the processing. The optimised virtual fields method (OVFM) (Comput. Mech. 34, 2004, 439), designed to be robust to noise, presents natural and rigorous solution to deal with these problems. The OVFM has been adapted to identify material parameter maps from magnetic resonance elastography data consisting of 3D displacement fields in harmonically loaded soft materials. In this work, the method has been developed to identify elastic and viscoelastic models. The OVFM sensitivity to spatial resolution and to noise has been studied by analysing 3D analytically simulated displacement data. This study evaluates and describes the OVFM identification performances: Different biases on the identified parameters are induced by the spatial resolution and experimental noise. The well-known identification problems in the case of quasi-incompressible materials also find a natural solution in the OVFM. Moreover, an a posteriori criterion to estimate the local identification quality is proposed. The identification results obtained on actual experiments are briefly presented. © 2015 Wiley Publishing Ltd.","elasticity; elasticity reconstruction; inverse problem; MR elastography; noise robustness; noise sensitivity; optimised virtual fields; virtual fields method; viscoelasticity","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84924968371"
"Weerakkody V.; Molnar A.; Irani Z.; El-Haddadeh R.","Weerakkody, Vishanth (16029961500); Molnar, Andreea (34771810700); Irani, Zahir (7003623363); El-Haddadeh, Ramzi (9840619600)","16029961500; 34771810700; 7003623363; 9840619600","A research proposition for using high definition video in emergency medical services","2013","Health Policy and Technology","2","3","","131","138","7","5","10.1016/j.hlpt.2013.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880624136&doi=10.1016%2fj.hlpt.2013.04.001&partnerID=40&md5=d916af0a4c81955f5475a9735f42a899","Business School, Brunel University, Uxbridge, UB8 3PH, Middlesex, Kingston Lane, United Kingdom","Weerakkody V., Business School, Brunel University, Uxbridge, UB8 3PH, Middlesex, Kingston Lane, United Kingdom; Molnar A., Business School, Brunel University, Uxbridge, UB8 3PH, Middlesex, Kingston Lane, United Kingdom; Irani Z., Business School, Brunel University, Uxbridge, UB8 3PH, Middlesex, Kingston Lane, United Kingdom; El-Haddadeh R., Business School, Brunel University, Uxbridge, UB8 3PH, Middlesex, Kingston Lane, United Kingdom","In emergency situations, communication between the ambulance crew and an emergency department in the hospital can be crucial in determining the best decision for a patient's health. Currently, when an ambulance crew reports at an emergency, paramedics use voice communication from scene of emergency to the hospital. In critical life threatening situations, use of high quality visual images and live video streaming can allow paramedics on the scene of an emergency to take better informed decisions by liaising with expert consultants in the hospital emergency department. This paper proposes the relay of high definition video between the ambulance crew and the hospital using public Internet infrastructure through utilising a virtual path slice controller. The paper also proposes a set of criteria for evaluating the use of video in emergency scenarios taking into account technical, user, application and process requirements together with an overview of the benefits, risks and ethical issues. © 2013 Fellowship of Postgraduate Medicine.","Ambulance; E-health; Evaluation criteria; High definition video communication Emergency","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84880624136"
"Reynolds C.R.; Muggleton S.H.; Sternberg M.J.E.","Reynolds, Christopher R. (55252952200); Muggleton, Stephen H. (7003491952); Sternberg, Michael J. E. (7101911184)","55252952200; 7003491952; 7101911184","Incorporating Virtual Reactions into a Logic-based Ligand-based Virtual Screening Method to Discover New Leads","2015","Molecular Informatics","34","9","","615","625","10","2","10.1002/minf.201400162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942194863&doi=10.1002%2fminf.201400162&partnerID=40&md5=5c14f6c5a641d5261e1c7edcdaada75f","Department of Bioinformatics, Imperial College London, South Kensington Campus, London, SW7 2AZ, United Kingdom; Department of Computing, Imperial College London, South Kensington Campus, London, SW7 2AZ, United Kingdom","Reynolds C.R., Department of Bioinformatics, Imperial College London, South Kensington Campus, London, SW7 2AZ, United Kingdom; Muggleton S.H., Department of Computing, Imperial College London, South Kensington Campus, London, SW7 2AZ, United Kingdom; Sternberg M.J.E., Department of Bioinformatics, Imperial College London, South Kensington Campus, London, SW7 2AZ, United Kingdom","The use of virtual screening has become increasingly central to the drug development pipeline, with ligand-based virtual screening used to screen databases of compounds to predict their bioactivity against a target. These databases can only represent a small fraction of chemical space, and this paper describes a method of exploring synthetic space by applying virtual reactions to promising compounds within a database, and generating focussed libraries of predicted derivatives. A ligand-based virtual screening tool Investigational Novel Drug Discovery by Example (INDDEx) is used as the basis for a system of virtual reactions. The use of virtual reactions is estimated to open up a potential space of 1.21×1012 potential molecules. A de novo design algorithm known as Partial Logical-Rule Reactant Selection (PLoRRS) is introduced and incorporated into the INDDEx methodology. PLoRRS uses logical rules from the INDDEx model to select reactants for the de novo generation of potentially active products. The PLoRRS method is found to increase significantly the likelihood of retrieving molecules similar to known actives with a p-value of 0.016. Case studies demonstrate that the virtual reactions produce molecules highly similar to known actives, including known blockbuster drugs. © 2015 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.","Ligand; Machine learning; Reactions; Synthesis; Virtual screening","","Wiley-VCH Verlag","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84942194863"
"Spyridonis F.; Hansen J.; Grønli T.-M.; Ghinea G.","Spyridonis, Fotios (36452600300); Hansen, Jarle (35772402000); Grønli, Tor-Morten (26027922400); Ghinea, Gheorghita (35616295700)","36452600300; 35772402000; 26027922400; 35616295700","PainDroid: An android-based virtual reality application for pain assessment","2014","Multimedia Tools and Applications","72","1","","191","206","15","19","10.1007/s11042-013-1358-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905981763&doi=10.1007%2fs11042-013-1358-3&partnerID=40&md5=4d3682faf0d28920bbc0f4a6e25a52d1","Department of Information Systems and Computing, Brunel University, London UB8 3PH, United Kingdom; Norwegian School of Information Technology, Oslo, Norway","Spyridonis F., Department of Information Systems and Computing, Brunel University, London UB8 3PH, United Kingdom; Hansen J., Department of Information Systems and Computing, Brunel University, London UB8 3PH, United Kingdom; Grønli T.-M., Norwegian School of Information Technology, Oslo, Norway; Ghinea G., Department of Information Systems and Computing, Brunel University, London UB8 3PH, United Kingdom, Norwegian School of Information Technology, Oslo, Norway","Earlier studies in the field of pain research suggest that little efficient intervention currently exists in response to the exponential increase in the prevalence of pain. In this paper, we present an Android application (PainDroid) with multimodal functionality that could be enhanced with Virtual Reality (VR) technology, which has been designed for the purpose of improving the assessment of this notoriously difficult medical concern. Pain- Droid has been evaluated for its usability and acceptability with a pilot group of potential users and clinicians, with initial results suggesting that it can be an effective and usable tool for improving the assessment of pain. Participant experiences indicated that the application was easy to use and the potential of the application was similarly appreciated by the clinicians involved in the evaluation. Our findings may be of considerable interest to healthcare providers, policy makers, and other parties that might be actively involved in the area of pain and VR research. © 2012 Springer Science+Business Media New York.","3-D Modeling; Android; Multimodal Interfaces; Pain assessment; Virtual Reality","","Kluwer Academic Publishers","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84905981763"
"Panëels S.; Roberts J.C.","Panëels, Sabrina (19640648300); Roberts, Jonathan C. (7410320344)","19640648300; 7410320344","Review of designs for haptic data visualization","2010","IEEE Transactions on Haptics","3","2","5255235","119","137","18","87","10.1109/TOH.2009.44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954315749&doi=10.1109%2fTOH.2009.44&partnerID=40&md5=7695e94cb37adf837dab69301ab10fb5","School of Computer Science, Bangor University, Bangor Gwynedd, LL57 1UT, Dean Street, United Kingdom","Panëels S.; Roberts J.C., School of Computer Science, Bangor University, Bangor Gwynedd, LL57 1UT, Dean Street, United Kingdom","There are many different uses for haptics, such as training medical practitioners, teleoperation, or navigation of virtual environments. This review focuses on haptic methods that display data. The hypothesis is that haptic devices can be used to present information, and consequently, the user gains quantitative, qualitative, or holistic knowledge about the presented data. Not only is this useful for users who are blind or partially sighted (who can feel line graphs, for instance), but also the haptic modality can be used alongside other modalities, to increase the amount of variables being presented, or to duplicate some variables to reinforce the presentation. Over the last 20 years, a significant amount of research has been done in haptic data presentation; e.g., researchers have developed force feedback line graphs, bar charts, and other forms of haptic representations. However, previous research is published in different conferences and journals, with different application emphases. This paper gathers and collates these various designs to provide a comprehensive review of designs for haptic data visualization. The designs are classified by their representation: Charts, Maps, Signs, Networks, Diagrams, Images, and Tables. This review provides a comprehensive reference for researchers and learners, and highlights areas for further research. © 2010 IEEE.","Haptic data visualization; haptic design; haptic visualization; haptics; non-visual visualization","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-77954315749"
"Spranger K.; Ventikos Y.","Spranger, Katerina (56226719600); Ventikos, Yiannis (6603704133)","56226719600; 6603704133","Which spring is the best? Comparison of methods for virtual stenting","2014","IEEE Transactions on Biomedical Engineering","61","7","6767090","1998","2010","12","23","10.1109/TBME.2014.2311856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903156988&doi=10.1109%2fTBME.2014.2311856&partnerID=40&md5=8c1f190c6744a85717b36602eaccf23e","Department of Engineering Science, University of Oxford, Oxford OX12JD, United Kingdom; Department of Mechanical Engineering, University College London, London WC1E6BT, United Kingdom","Spranger K., Department of Engineering Science, University of Oxford, Oxford OX12JD, United Kingdom; Ventikos Y., Department of Mechanical Engineering, University College London, London WC1E6BT, United Kingdom","This paper presents a methodology for modeling the deployment of implantable devices used in minimally invasive vascular interventions. Motivated by the clinical need to perform preinterventional rehearsals of a stent deployment, we have developed methods enabling virtual device placement inside arteries, under the constraint of real-time application. This requirement of rapid execution narrowed down the search for a suitable method to the concept of a dynamic mesh. Inspired by the idea of a mesh of springs, we have found a novel way to apply it to stent modeling. The experiments conducted in this paper investigate properties of the stent models based on three different spring types: lineal, semitorsional, and torsional springs. Furthermore, this paper compares the results of various deployment scenarios for two different classes of devices: a stent graft and a flow diverter. The presented results can be of a high-potential clinical value, enabling the predictive evaluation of the outcome of a stent deployment treatment. © 2014 IEEE.","Flow diverter; modeling; stent; virtual stenting","","IEEE Computer Society","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84903156988"
"Bowyer S.A.; Baena F.R.Y.","Bowyer, Stuart A. (48261104600); Baena, Ferdinando Rodriguez Y (15132536100)","48261104600; 15132536100","Dissipative Control for Physical Human-Robot Interaction","2015","IEEE Transactions on Robotics","31","6","7294686","1281","1293","12","48","10.1109/TRO.2015.2477956","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961641038&doi=10.1109%2fTRO.2015.2477956&partnerID=40&md5=98ed0d902b5c09b40e09a3e51b324706","Mechatronics in Medicine Laboratory, Department of Mechanical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom","Bowyer S.A., Mechatronics in Medicine Laboratory, Department of Mechanical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom; Baena F.R.Y., Mechatronics in Medicine Laboratory, Department of Mechanical Engineering, Imperial College London, London, SW7 2AZ, United Kingdom","Physical human-robot interaction is fundamental to exploiting the capabilities of robots in tasks and environments where robots have limited cognition or comprehension and is virtually ubiquitous for robotic manipulation in highly unstructured environments, as are found in surgery. A critical aspect of physical human-robot interaction in these cases is controlling the robot so that the individual human and robot competencies are maximized, while guaranteeing user, task, and environment safety. Dissipative control precludes dangerous forcing of a shared tool by the robot, ensuring safety; however, it typically suffers from poor control fidelity, resulting in reduced task accuracy. In this study, a novel, rigorously formalized, n-dimensional dissipative control strategy is proposed that employs a new technique called 'energy redirection' to generate control forces with increased fidelity while remaining dissipative and safe. Experimental validation of the method, for complete pose control, shows that it achieves a 90% reduction in task error compared with the current state of the art in dissipative control for the tested applications. The findings clearly demonstrate that the method significantly increases the fidelity and efficacy of dissipative control during physical human-robot interaction. This advancement expands the number of tasks and environments into which safe physical human-robot interaction can be employed effectively. © 2004-2012 IEEE.","Haptics and haptic interfaces; impedance control; medical robots and systems; physical human-robot interaction; virtual fixtures","","Institute of Electrical and Electronics Engineers Inc.","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84961641038"
"Hong Q.; Li Q.; Tian J.","Hong, Qingqi (36623542100); Li, Qingde (55975558500); Tian, Jie (7401636162)","36623542100; 55975558500; 7401636162","Implicit reconstruction of vasculatures using bivariate piecewise algebraic splines","2012","IEEE Transactions on Medical Imaging","31","3","6051492","543","553","10","24","10.1109/TMI.2011.2172455","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857950826&doi=10.1109%2fTMI.2011.2172455&partnerID=40&md5=4c83626381e300a122b7be03ed08c866","Department of Computer Science, University of Hull, HU6 7RX Hull, United Kingdom; Medical Image Processing Group, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China","Hong Q., Department of Computer Science, University of Hull, HU6 7RX Hull, United Kingdom; Li Q., Department of Computer Science, University of Hull, HU6 7RX Hull, United Kingdom; Tian J., Medical Image Processing Group, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China","Vasculature geometry reconstruction from volumetric medical data is a crucial task in the development of computer guided minimally invasive vascular surgery systems. In this paper, a technique for reconstructing the geometry of vasculatures using bivariate implicit splines is developed. With the proposed technique, an implicit geometry representation of the vascular tree can be accurately constructed based on the voxels extracted directly from the surface of a certain vascular structure in a given volumetric medical dataset. Experimental results show that the geometric representation built using our method can faithfully represent the morphology and topology of vascular structures. In addition, both the qualitative and the quantitative validations have been performed to show that the reconstructed vessel geometry is of high accuracy and smoothness. An virtual angioscopy system has been implemented to indicate one of the strengths of our proposed method. © 2011 IEEE.","Implicit modeling; vasculature reconstruction; virtual angioscopy","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84857950826"
"Magee D.; Zhu Y.; Ratnalingam R.; Gardner P.; Kessel D.","Magee, D. (7103392277); Zhu, Y. (56172335300); Ratnalingam, R. (55410738000); Gardner, P. (7201658507); Kessel, D. (7102689322)","7103392277; 56172335300; 55410738000; 7201658507; 7102689322","An augmented reality simulator for ultrasound guided needle placement training","2007","Medical and Biological Engineering and Computing","45","10","","957","967","10","79","10.1007/s11517-007-0231-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548718157&doi=10.1007%2fs11517-007-0231-9&partnerID=40&md5=160aeeb187c94bdff10d3da0f5258dff","School of Computing, University of Leeds, Leeds, United Kingdom; Leeds Teaching Hospitals NHS Trust, Leeds, United Kingdom; Institute of Psychological Sciences, University of Leeds, Leeds, United Kingdom","Magee D., School of Computing, University of Leeds, Leeds, United Kingdom; Zhu Y., School of Computing, University of Leeds, Leeds, United Kingdom; Ratnalingam R., Leeds Teaching Hospitals NHS Trust, Leeds, United Kingdom; Gardner P., Institute of Psychological Sciences, University of Leeds, Leeds, United Kingdom; Kessel D., Leeds Teaching Hospitals NHS Trust, Leeds, United Kingdom","Details are presented of a low cost augmented-reality system for the simulation of ultrasound guided needle insertion procedures (tissue biopsy, abscess drainage, nephrostomy etc.) for interventional radiology education and training. The system comprises physical elements; a mannequin, a mock ultrasound probe and a needle, and software elements; generating virtual ultrasound anatomy and allowing data collection. These two elements are linked by a pair of magnetic 3D position sensors. Virtual anatomic images are generated based on anatomic data derived from full body CT scans of live humans. Details of the novel aspects of this system are presented including; image generation, registration and calibration. © International Federation for Medical and Biological Engineering 2007.","Augmented-reality; Needle-placement; Simulation; Ultrasound","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-34548718157"
"Linte C.A.; Davenport K.P.; Cleary K.; Peters C.; Vosburgh K.G.; Navab N.; Edwards P.T.; Jannin P.; Peters T.M.; Holmes D.R.; Robb R.A.","Linte, Cristian A. (57202997616); Davenport, Katherine P. (54683615700); Cleary, Kevin (26643081000); Peters, Craig (7402558645); Vosburgh, Kirby G. (6603750007); Navab, Nassir (7003458998); Edwards, Philip Eddie (7401881894); Jannin, Pierre (57203216789); Peters, Terry M. (7402962614); Holmes, David R. (57324857400); Robb, Richard A. (7101651488)","57202997616; 54683615700; 26643081000; 7402558645; 6603750007; 7003458998; 7401881894; 57203216789; 7402962614; 57324857400; 7101651488","On mixed reality environments for minimally invasive therapy guidance: Systems architecture, successes and challenges in their implementation from laboratory to clinic","2013","Computerized Medical Imaging and Graphics","37","2","","83","97","14","45","10.1016/j.compmedimag.2012.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876998702&doi=10.1016%2fj.compmedimag.2012.12.002&partnerID=40&md5=cc2e6fa605775693467a5dcdcd707ee4","Biomedical Imaging Resource, Mayo Clinic, Rochester, MN, United States; Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Medical Center, Washington, DC, United States; Brigham and Women's Hospital, Harvard University, Boston, MA, United States; Faculty of Informatics and Computer Aided Medical Procedures, Technical University of Munich, Munich, Germany; Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Faculté de Médecine and INSERM, Université de Rennes I, Rennes, France; Imaging Research Laboratories, Robarts Research Institute, London, ON, Canada","Linte C.A., Biomedical Imaging Resource, Mayo Clinic, Rochester, MN, United States; Davenport K.P., Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Medical Center, Washington, DC, United States; Cleary K., Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Medical Center, Washington, DC, United States; Peters C., Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Medical Center, Washington, DC, United States; Vosburgh K.G., Brigham and Women's Hospital, Harvard University, Boston, MA, United States; Navab N., Faculty of Informatics and Computer Aided Medical Procedures, Technical University of Munich, Munich, Germany; Edwards P.T., Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Jannin P., Faculté de Médecine and INSERM, Université de Rennes I, Rennes, France; Peters T.M., Imaging Research Laboratories, Robarts Research Institute, London, ON, Canada; Holmes D.R., Biomedical Imaging Resource, Mayo Clinic, Rochester, MN, United States; Robb R.A., Biomedical Imaging Resource, Mayo Clinic, Rochester, MN, United States","Mixed reality environments for medical applications have been explored and developed over the past three decades in an effort to enhance the clinician's view of anatomy and facilitate the performance of minimally invasive procedures. These environments must faithfully represent the real surgical field and require seamless integration of pre- and intra-operative imaging, surgical instrument tracking, and display technology into a common framework centered around and registered to the patient. However, in spite of their reported benefits, few mixed reality environments have been successfully translated into clinical use. Several challenges that contribute to the difficulty in integrating such environments into clinical practice are presented here and discussed in terms of both technical and clinical limitations. This article should raise awareness among both developers and end-users toward facilitating a greater application of such environments in the surgical practice of the future. © 2013 Elsevier Ltd.","Augmented and mixed reality environments; Clinical translation; Image-guided interventions; Minimally invasive surgery and therapy; Virtual","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84876998702"
"Pan J.J.; Chang J.; Yang X.; Liang H.; Zhang J.J.; Qureshi T.; Howell R.; Hickish T.","Pan, Jun J. (55459051800); Chang, Jian (55514990300); Yang, Xiaosong (55683846400); Liang, Hui (57199818730); Zhang, Jian J. (55912086700); Qureshi, Tahseen (50061751400); Howell, Robert (57196842311); Hickish, Tamas (7003268270)","55459051800; 55514990300; 55683846400; 57199818730; 55912086700; 50061751400; 57196842311; 7003268270","Virtual reality training and assessment in laparoscopic rectum surgery","2015","International Journal of Medical Robotics and Computer Assisted Surgery","11","2","","194","209","15","39","10.1002/rcs.1582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930178534&doi=10.1002%2frcs.1582&partnerID=40&md5=cacaaa3fcb00d3a3553728465ec51f1a","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Poole Hospital, Poole, United Kingdom; The Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom; School of Animation, Communication University of China, Beijing, China","Pan J.J., State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Chang J., National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Yang X., National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Liang H., School of Animation, Communication University of China, Beijing, China; Zhang J.J., National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Qureshi T., Poole Hospital, Poole, United Kingdom; Howell R., The Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom; Hickish T., The Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom","Background: Virtual-reality (VR) based simulation techniques offer an efficient and low cost alternative to conventional surgery training. This article describes a VR training and assessment system in laparoscopic rectum surgery. Methods: To give a realistic visual performance of interaction between membrane tissue and surgery tools, a generalized cylinder based collision detection and a multi-layer mass-spring model are presented. A dynamic assessment model is also designed for hierarchy training evaluation. Results: With this simulator, trainees can operate on the virtual rectum with both visual and haptic sensation feedback simultaneously. The system also offers surgeons instructions in real time when improper manipulation happens. The simulator has been tested and evaluated by ten subjects. Conclusions: This prototype system has been verified by colorectal surgeons through a pilot study. They believe the visual performance and the tactile feedback are realistic. It exhibits the potential to effectively improve the surgical skills of trainee surgeons and significantly shorten their learning curve. © 2014 John Wiley & Sons, Ltd..","Collision detection; Dissection simulation; Dynamic assessment; Evaluation; Laparoscopic rectum surgery","","John Wiley and Sons Ltd","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84930178534"
"Walton N.A.; Brenton J.D.; Caldas C.; Irwin M.J.; Akram A.; Gonzalez-Solares E.; Lewis J.R.; Maccallum P.H.; Morris L.J.; Rixon G.T.","Walton, N.A. (35463408300); Brenton, J.D. (57195224220); Caldas, C. (7006688992); Irwin, M.J. (57203104726); Akram, A. (57210683652); Gonzalez-Solares, E. (6602823047); Lewis, J.R. (8697356800); Maccallum, P.H. (35280414600); Morris, L.J. (35280017900); Rixon, G.T. (6603439546)","35463408300; 57195224220; 7006688992; 57203104726; 57210683652; 6602823047; 8697356800; 35280414600; 35280017900; 6603439546","PathGrid: A service-orientated architecture for microscopy image analysis","2010","Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences","368","1925","","3937","3952","15","4","10.1098/rsta.2010.0158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956490569&doi=10.1098%2frsta.2010.0158&partnerID=40&md5=ce95baa49f3422ac0fe410a3c043281b","Institute of Astronomy, University of Cambridge, Cambridge CB3 0HA, Madingley Road, United Kingdom; Cancer Research UK, Cambridge Research Institute, Li Ka Shing Centre, Cambridge CB2 0RE, Robinson Way, United Kingdom; Department of Oncology, University of Cambridge, Hutchison MRC Research Centre, Cambridge CB2 0XZ, United Kingdom","Walton N.A., Institute of Astronomy, University of Cambridge, Cambridge CB3 0HA, Madingley Road, United Kingdom; Brenton J.D., Cancer Research UK, Cambridge Research Institute, Li Ka Shing Centre, Cambridge CB2 0RE, Robinson Way, United Kingdom, Department of Oncology, University of Cambridge, Hutchison MRC Research Centre, Cambridge CB2 0XZ, United Kingdom; Caldas C., Cancer Research UK, Cambridge Research Institute, Li Ka Shing Centre, Cambridge CB2 0RE, Robinson Way, United Kingdom, Department of Oncology, University of Cambridge, Hutchison MRC Research Centre, Cambridge CB2 0XZ, United Kingdom; Irwin M.J., Institute of Astronomy, University of Cambridge, Cambridge CB3 0HA, Madingley Road, United Kingdom; Akram A., Institute of Astronomy, University of Cambridge, Cambridge CB3 0HA, Madingley Road, United Kingdom; Gonzalez-Solares E., Institute of Astronomy, University of Cambridge, Cambridge CB3 0HA, Madingley Road, United Kingdom; Lewis J.R., Institute of Astronomy, University of Cambridge, Cambridge CB3 0HA, Madingley Road, United Kingdom; Maccallum P.H., Cancer Research UK, Cambridge Research Institute, Li Ka Shing Centre, Cambridge CB2 0RE, Robinson Way, United Kingdom; Morris L.J., Cancer Research UK, Cambridge Research Institute, Li Ka Shing Centre, Cambridge CB2 0RE, Robinson Way, United Kingdom; Rixon G.T., Institute of Astronomy, University of Cambridge, Cambridge CB3 0HA, Madingley Road, United Kingdom","This paper describes 'PathGrid'-an analysis and data integration system, developed initially to meet the demands in the analysis of medical microscopy imaging data. An overview of the current system is given, describing the techniques used in developing the data handling infrastructure and the analysis algorithm development. The use of software created in the context of systems designed for the astronomy domain is noted, specifically infrastructure from the astronomy virtual observatory movement for data discovery, access and workflow management, and astronomical image analysis software adapted for the analysis of high-throughput astronomy imaging surveys. This paper notes the applicability of the techniques from the astronomy domain. The testbed infrastructure deployment is described, emphasizing its speed and ease of use and support. The validity of the analysis techniques is confirmed through the pilot study described here-with the application to a large sample of immunohistochemistry microscopy data obtained in part for assessing the oestrogen receptor status of breast cancers. The analysis showed that the specificity and sensitivity values for the automatic scoring using PathGrid were within the errors of those obtained via a 'gold standard' manual pathologist scoring. This journal is © 2010 The Royal Society.","Astronomy; Image processing; Information extraction; Microscopy","","Royal Society","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-77956490569"
"Hu H.; Correll M.; Kvecher L.; Osmond M.; Clark J.; Bekhash A.; Schwab G.; Gao D.; Gao J.; Kubatin V.; Shriver C.D.; Hooke J.A.; Maxwell L.G.; Kovatich A.J.; Sheldon J.G.; Liebman M.N.; Mural R.J.","Hu, Hai (58455318100); Correll, Mick (57194642775); Kvecher, Leonid (24721309100); Osmond, Michelle (7003624756); Clark, Jim (7407828577); Bekhash, Anthony (49962860200); Schwab, Gwendolyn (49964651700); Gao, De (49963452300); Gao, Jun (49963375100); Kubatin, Vladimir (49963678900); Shriver, Craig D. (7004122081); Hooke, Jeffrey A. (7003851288); Maxwell, Larry G. (7102327440); Kovatich, Albert J. (7004502384); Sheldon, Jonathan G. (7101666079); Liebman, Michael N. (7005787075); Mural, Richard J. (7003349003)","58455318100; 57194642775; 24721309100; 7003624756; 7407828577; 49962860200; 49964651700; 49963452300; 49963375100; 49963678900; 7004122081; 7003851288; 7102327440; 7004502384; 7101666079; 7005787075; 7003349003","DW4TR: A Data Warehouse for Translational Research","2011","Journal of Biomedical Informatics","44","6","","1004","1019","15","36","10.1016/j.jbi.2011.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855951781&doi=10.1016%2fj.jbi.2011.08.003&partnerID=40&md5=412692f87a3f75ef1df541ae643ccbc9","Windber Research Institute, Windber, PA, United States; InforSense LLC., London, United Kingdom; InforSense Ltd., Boston, MA, United States; InforSense Ltd., Shanghai, China; Walter Reed Army Medical Center, Washington, DC, United States; MDR Global, Windber, PA, United States; Dana-Farber Cancer Institute, Boston, MA, United States; IDBS, Burlington, MA, United States; Strategic Medicine, Kennett Square, PA, United States","Hu H., Windber Research Institute, Windber, PA, United States; Correll M., InforSense Ltd., Boston, MA, United States, Dana-Farber Cancer Institute, Boston, MA, United States; Kvecher L., Windber Research Institute, Windber, PA, United States; Osmond M., InforSense LLC., London, United Kingdom, IDBS, Burlington, MA, United States; Clark J., InforSense LLC., London, United Kingdom, IDBS, Burlington, MA, United States; Bekhash A., Windber Research Institute, Windber, PA, United States; Schwab G., Windber Research Institute, Windber, PA, United States; Gao D., InforSense Ltd., Shanghai, China, IDBS, Burlington, MA, United States; Gao J., InforSense Ltd., Shanghai, China, IDBS, Burlington, MA, United States; Kubatin V., InforSense Ltd., Boston, MA, United States, IDBS, Burlington, MA, United States; Shriver C.D., Walter Reed Army Medical Center, Washington, DC, United States; Hooke J.A., Walter Reed Army Medical Center, Washington, DC, United States; Maxwell L.G., Walter Reed Army Medical Center, Washington, DC, United States; Kovatich A.J., MDR Global, Windber, PA, United States; Sheldon J.G., InforSense LLC., London, United Kingdom; Liebman M.N., Windber Research Institute, Windber, PA, United States, Strategic Medicine, Kennett Square, PA, United States; Mural R.J., Windber Research Institute, Windber, PA, United States","The linkage between the clinical and laboratory research domains is a key issue in translational research. Integration of clinicopathologic data alone is a major task given the number of data elements involved. For a translational research environment, it is critical to make these data usable at the point-of-need. Individual systems have been developed to meet the needs of particular projects though the need for a generalizable system has been recognized. Increased use of Electronic Medical Record data in translational research will demand generalizing the system for integrating clinical data to support the study of a broad range of human diseases. To ultimately satisfy these needs, we have developed a system to support multiple translational research projects. This system, the Data Warehouse for Translational Research (DW4TR), is based on a light-weight, patient-centric modularly-structured clinical data model and a specimen-centric molecular data model. The temporal relationships of the data are also part of the model. The data are accessed through an interface composed of an Aggregated Biomedical-Information Browser (ABB) and an Individual Subject Information Viewer (ISIV) which target general users. The system was developed to support a breast cancer translational research program and has been extended to support a gynecological disease program. Further extensions of the DW4TR are underway. We believe that the DW4TR will play an important role in translational research across multiple disease types. © 2011 Elsevier Inc.","Data Warehouse; Ontology; Patient-centric data model; Translational research; User interface","","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84855951781"
"Capelli C.; Taylor A.M.; Migliavacca F.; Bonhoeffer P.; Schievano S.","Capelli, Claudio (24922737800); Taylor, Andrew M. (57195810900); Migliavacca, Francesco (7005337879); Bonhoeffer, Philipp (7007022476); Schievano, Silvia (13410386200)","24922737800; 57195810900; 7005337879; 7007022476; 13410386200","Patient-specific reconstructed anatomies and computer simulations are fundamental for selecting medical device treatment: Application to a new percutaneous pulmonary valve","2010","Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences","368","1921","","3027","3038","11","56","10.1098/rsta.2010.0088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954466047&doi=10.1098%2frsta.2010.0088&partnerID=40&md5=7a788b0605a022e8f7a4793e69b3d6c4","Cardiovascular Unit, UCL Institute of Child Health, London WC1N 3JH, Great Ormond Street, United Kingdom; Great Ormond Street Hospital for Children, London WC1N 3JH, Great Ormond Street, United Kingdom; Laboratory of Biological Structure Mechanics, Structural Engineering Department, Politecnico di Milano, Milan, Italy","Capelli C., Cardiovascular Unit, UCL Institute of Child Health, London WC1N 3JH, Great Ormond Street, United Kingdom, Great Ormond Street Hospital for Children, London WC1N 3JH, Great Ormond Street, United Kingdom; Taylor A.M., Cardiovascular Unit, UCL Institute of Child Health, London WC1N 3JH, Great Ormond Street, United Kingdom, Great Ormond Street Hospital for Children, London WC1N 3JH, Great Ormond Street, United Kingdom; Migliavacca F., Laboratory of Biological Structure Mechanics, Structural Engineering Department, Politecnico di Milano, Milan, Italy; Bonhoeffer P., Cardiovascular Unit, UCL Institute of Child Health, London WC1N 3JH, Great Ormond Street, United Kingdom; Schievano S., Cardiovascular Unit, UCL Institute of Child Health, London WC1N 3JH, Great Ormond Street, United Kingdom, Great Ormond Street Hospital for Children, London WC1N 3JH, Great Ormond Street, United Kingdom","Nowadays, percutaneous pulmonary valve implantation is a successful alternative to surgery for patients requiring treatment of pulmonary valve dysfunction. However, owing to the wide variety of implantation site morphology, size and dynamics, only about 15 per cent of cases are suitable for current devices. In order to increase the number of patients who could benefit from minimally invasive procedures, a new valved stent graft for percutaneous implantation has been designed recently. In this study, patient-specific computational analyses have been applied to investigate the suitability of new device designs, using real data from 62 patients who had undergone surgical pulmonary valve replacement. Magnetic resonance images of these patients before surgery were elaborated using imaging post-processing software to reconstruct the three-dimensional volume of each patient's implantation site. Three stent designs were created and tested in these patient outflow tracts using finite-element simulations: stent graft SG1 resembles the first device tested in animals; stent graft SG2 is a custom device tailored for a specific patient morphology; and stent graft SG3 represents a hypothetical larger device. The three devices showed an implantation success rate of 37 per cent, 42 per cent and 63 per cent, respectively. Using patient-specific simulations, we have shown that a percutaneous approach with these new devices may be possible for many patients who are currently referred for surgery. Furthermore, when the new devices become available, the methodologies described may help clinicians in the decision-making process, by enabling virtual implantation prior to the actual procedure. © 2010 The Royal Society.","Finite element; Patient specific; Percutaneous pulmonary valve implantation; Stent graft","","Royal Society","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-77954466047"
